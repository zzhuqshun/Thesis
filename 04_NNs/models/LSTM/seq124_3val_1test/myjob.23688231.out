Using device: cuda:0

Degradation categories and rates:
    cell_id      rate category
0       01  0.000391   normal
1       03  0.000518   normal
2       05  0.000499   normal
3       07  0.000750   normal
4       09  0.003106   faster
5       11  0.003046   faster
6       13  0.008297   faster
7       15  0.006153   faster
8       17  0.001771     fast
9       19  0.001001     fast
10      21  0.001098     fast
11      23  0.000973     fast
12      25  0.002719     fast
13      27  0.000463   normal
14      29  0.006876   faster 

Train IDs: ['03', '05', '07', '09', '11', '15', '21', '23', '25', '27', '29'], Val IDs: ['01', '19', '13'], Test IDs: ['17']
Shapes -> Train: (205444, 7), Val: (58110, 7), Test: (22846, 7)

Features scaled with StandardScaler
Model architecture:
SOHLSTM(
  (lstm): LSTM(3, 32, num_layers=3, batch_first=True, dropout=0.2)
  (fc_layers): Sequential(
    (0): Linear(in_features=32, out_features=16, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.2, inplace=False)
    (3): Linear(in_features=16, out_features=1, bias=True)
  )
)
Total trainable parameters: 22,177

Start training...
Epoch 1/200 | Train Loss: 6.806e-02 | Val Loss: 3.997e-03 | LR: 1.00e-04
Epoch 2/200 | Train Loss: 1.676e-02 | Val Loss: 1.909e-03 | LR: 1.00e-04
Epoch 3/200 | Train Loss: 9.034e-03 | Val Loss: 2.642e-03 | LR: 1.00e-04
Epoch 4/200 | Train Loss: 5.220e-03 | Val Loss: 1.081e-03 | LR: 1.00e-04
Epoch 5/200 | Train Loss: 3.075e-03 | Val Loss: 8.926e-04 | LR: 1.00e-04
Epoch 6/200 | Train Loss: 1.949e-03 | Val Loss: 1.239e-03 | LR: 1.00e-04
Epoch 7/200 | Train Loss: 1.524e-03 | Val Loss: 8.714e-04 | LR: 1.00e-04
Epoch 8/200 | Train Loss: 1.262e-03 | Val Loss: 7.196e-04 | LR: 1.00e-04
Epoch 9/200 | Train Loss: 1.070e-03 | Val Loss: 8.353e-04 | LR: 1.00e-04
Epoch 10/200 | Train Loss: 9.220e-04 | Val Loss: 5.752e-04 | LR: 1.00e-04
Epoch 11/200 | Train Loss: 8.112e-04 | Val Loss: 5.609e-04 | LR: 1.00e-04
Epoch 12/200 | Train Loss: 7.187e-04 | Val Loss: 5.106e-04 | LR: 1.00e-04
Epoch 13/200 | Train Loss: 6.598e-04 | Val Loss: 5.102e-04 | LR: 1.00e-04
Epoch 14/200 | Train Loss: 6.064e-04 | Val Loss: 4.768e-04 | LR: 1.00e-04
Epoch 15/200 | Train Loss: 5.584e-04 | Val Loss: 4.774e-04 | LR: 1.00e-04
Epoch 16/200 | Train Loss: 5.223e-04 | Val Loss: 6.133e-04 | LR: 1.00e-04
Epoch 17/200 | Train Loss: 4.988e-04 | Val Loss: 4.254e-04 | LR: 1.00e-04
Epoch 18/200 | Train Loss: 4.806e-04 | Val Loss: 5.478e-04 | LR: 1.00e-04
Epoch 19/200 | Train Loss: 4.663e-04 | Val Loss: 4.609e-04 | LR: 1.00e-04
Epoch 20/200 | Train Loss: 4.472e-04 | Val Loss: 4.409e-04 | LR: 1.00e-04
Epoch 21/200 | Train Loss: 4.360e-04 | Val Loss: 6.027e-04 | LR: 1.00e-04
Epoch 22/200 | Train Loss: 4.274e-04 | Val Loss: 3.499e-04 | LR: 1.00e-04
Epoch 23/200 | Train Loss: 4.187e-04 | Val Loss: 3.594e-04 | LR: 1.00e-04
Epoch 24/200 | Train Loss: 4.063e-04 | Val Loss: 3.338e-04 | LR: 1.00e-04
Epoch 25/200 | Train Loss: 3.956e-04 | Val Loss: 3.746e-04 | LR: 1.00e-04
Epoch 26/200 | Train Loss: 3.919e-04 | Val Loss: 5.636e-04 | LR: 1.00e-04
Epoch 27/200 | Train Loss: 3.757e-04 | Val Loss: 3.656e-04 | LR: 1.00e-04
Epoch 28/200 | Train Loss: 3.739e-04 | Val Loss: 3.790e-04 | LR: 1.00e-04
Epoch 29/200 | Train Loss: 3.651e-04 | Val Loss: 3.267e-04 | LR: 1.00e-04
Epoch 30/200 | Train Loss: 3.608e-04 | Val Loss: 2.820e-04 | LR: 1.00e-04
Epoch 31/200 | Train Loss: 3.533e-04 | Val Loss: 2.812e-04 | LR: 1.00e-04
Epoch 32/200 | Train Loss: 3.499e-04 | Val Loss: 3.006e-04 | LR: 1.00e-04
Epoch 33/200 | Train Loss: 3.428e-04 | Val Loss: 2.992e-04 | LR: 1.00e-04
Epoch 34/200 | Train Loss: 3.386e-04 | Val Loss: 3.203e-04 | LR: 1.00e-04
Epoch 35/200 | Train Loss: 3.355e-04 | Val Loss: 2.505e-04 | LR: 1.00e-04
Epoch 36/200 | Train Loss: 3.281e-04 | Val Loss: 3.107e-04 | LR: 1.00e-04
Epoch 37/200 | Train Loss: 3.289e-04 | Val Loss: 2.502e-04 | LR: 1.00e-04
Epoch 38/200 | Train Loss: 3.219e-04 | Val Loss: 2.672e-04 | LR: 1.00e-04
Epoch 39/200 | Train Loss: 3.178e-04 | Val Loss: 3.069e-04 | LR: 1.00e-04
Epoch 40/200 | Train Loss: 3.183e-04 | Val Loss: 2.893e-04 | LR: 1.00e-04
Epoch 41/200 | Train Loss: 3.360e-04 | Val Loss: 3.175e-04 | LR: 1.00e-04
Epoch 42/200 | Train Loss: 3.108e-04 | Val Loss: 2.262e-04 | LR: 1.00e-04
Epoch 43/200 | Train Loss: 3.080e-04 | Val Loss: 2.663e-04 | LR: 1.00e-04
Epoch 44/200 | Train Loss: 3.042e-04 | Val Loss: 2.318e-04 | LR: 1.00e-04
Epoch 45/200 | Train Loss: 2.997e-04 | Val Loss: 2.616e-04 | LR: 1.00e-04
Epoch 46/200 | Train Loss: 2.984e-04 | Val Loss: 2.858e-04 | LR: 1.00e-04
Epoch 47/200 | Train Loss: 2.955e-04 | Val Loss: 2.802e-04 | LR: 1.00e-04
Epoch 48/200 | Train Loss: 2.937e-04 | Val Loss: 2.875e-04 | LR: 5.00e-05
Epoch 49/200 | Train Loss: 2.776e-04 | Val Loss: 2.536e-04 | LR: 5.00e-05
Epoch 50/200 | Train Loss: 2.744e-04 | Val Loss: 2.892e-04 | LR: 5.00e-05
Epoch 51/200 | Train Loss: 2.751e-04 | Val Loss: 2.571e-04 | LR: 5.00e-05
Epoch 52/200 | Train Loss: 2.747e-04 | Val Loss: 2.758e-04 | LR: 5.00e-05
Epoch 53/200 | Train Loss: 2.742e-04 | Val Loss: 2.330e-04 | LR: 5.00e-05
Epoch 54/200 | Train Loss: 2.738e-04 | Val Loss: 2.861e-04 | LR: 2.50e-05
Epoch 55/200 | Train Loss: 2.657e-04 | Val Loss: 3.231e-04 | LR: 2.50e-05
Epoch 56/200 | Train Loss: 2.650e-04 | Val Loss: 3.351e-04 | LR: 2.50e-05
Epoch 57/200 | Train Loss: 2.635e-04 | Val Loss: 3.025e-04 | LR: 2.50e-05
Epoch 58/200 | Train Loss: 2.629e-04 | Val Loss: 3.385e-04 | LR: 2.50e-05
Epoch 59/200 | Train Loss: 2.656e-04 | Val Loss: 3.224e-04 | LR: 2.50e-05
Epoch 60/200 | Train Loss: 2.638e-04 | Val Loss: 2.844e-04 | LR: 1.25e-05
Epoch 61/200 | Train Loss: 2.578e-04 | Val Loss: 3.061e-04 | LR: 1.25e-05
Epoch 62/200 | Train Loss: 2.584e-04 | Val Loss: 3.107e-04 | LR: 1.25e-05
Early stopping at epoch 62

Training complete. Best validation loss: 0.000226

Evaluating the model on the testing set...
RMSE: 0.0215
MAE: 0.0162
RÂ²: 0.9366
Prediction plot saved for cell 17
Prediction scatter plot saved for cell 17
