2025-06-09 16:46:57,148 - ==== Skipping Regular LSTM Training Phase ====
2025-06-09 16:46:57,150 - ==== Incremental EWC Training Phase ====
2025-06-09 16:48:57,671 - Base train IDs: ['01', '03', '05', '21', '27']
2025-06-09 16:48:57,674 - Base train size: 119705
2025-06-09 16:48:57,675 - Base val IDs: ['23']
2025-06-09 16:48:57,676 - Base val size: 24176
2025-06-09 16:48:57,677 - Update1 train IDs: ['07', '09', '11', '19', '23']
2025-06-09 16:48:57,678 - Update1 train size: 102537
2025-06-09 16:48:57,679 - Update1 val IDs: ['25']
2025-06-09 16:48:57,680 - Update1 val size: 18326
2025-06-09 16:48:57,681 - Update2 train IDs: ['15', '25', '29']
2025-06-09 16:48:57,682 - Update2 train size: 35134
2025-06-09 16:48:57,683 - Update2 val IDs: ['13']
2025-06-09 16:48:57,684 - Update2 val size: 6445
2025-06-09 16:49:09,552 - Test cell ID: 17
2025-06-09 16:49:09,553 - Test size: 22872
2025-06-09 16:49:09,554 - Test base size: 11139
2025-06-09 16:49:09,555 - Test update1 size: 6312
2025-06-09 16:49:09,555 - Test update2 size: 5421
2025-06-09 16:49:09,571 - [Scaler after base train] center_=[ 3.33669383  0.09000333 27.25683333]
2025-06-09 16:49:09,575 - [Scaler after base train] scale_ =[0.18560667 1.7796255  0.91083333]
2025-06-09 16:49:09,605 - [Scaler after update1 train] center_=[ 3.3470445  0.180014  27.558    ]
2025-06-09 16:49:09,607 - [Scaler after update1 train] scale_ =[0.17459175 1.7792845  1.55633333]
2025-06-09 16:49:09,640 - [Scaler after update2 train] center_=[ 3.34436858  0.17994317 27.65816667]
2025-06-09 16:49:09,641 - [Scaler after update2 train] scale_ =[0.18038842 1.7793885  1.85120833]
2025-06-09 16:49:09,652 - Data scaling complete with RobustScaler
2025-06-09 16:49:11,576 - [task0] Training...
2025-06-09 16:51:35,105 - Epoch 1, lambda= 0.0000, Train Loss: 3.1347e-02, Val Loss: 2.3828e-03, LR: 1.0000e-04, Time: 104.02s
2025-06-09 16:53:13,157 - Epoch 2, lambda= 0.0000, Train Loss: 6.3702e-03, Val Loss: 1.8118e-03, LR: 1.0000e-04, Time: 97.99s
2025-06-09 16:54:50,707 - Epoch 3, lambda= 0.0000, Train Loss: 4.6680e-03, Val Loss: 1.6219e-03, LR: 1.0000e-04, Time: 97.49s
2025-06-09 16:56:28,044 - Epoch 4, lambda= 0.0000, Train Loss: 3.5371e-03, Val Loss: 2.3336e-03, LR: 1.0000e-04, Time: 97.24s
2025-06-09 16:58:05,385 - Epoch 5, lambda= 0.0000, Train Loss: 2.6030e-03, Val Loss: 2.3887e-03, LR: 1.0000e-04, Time: 97.32s
2025-06-09 16:59:42,666 - Epoch 6, lambda= 0.0000, Train Loss: 1.9095e-03, Val Loss: 2.1545e-03, LR: 1.0000e-04, Time: 97.26s
2025-06-09 17:01:21,099 - Epoch 7, lambda= 0.0000, Train Loss: 1.2182e-03, Val Loss: 1.7460e-03, LR: 1.0000e-04, Time: 98.39s
2025-06-09 17:03:03,031 - Epoch 8, lambda= 0.0000, Train Loss: 8.0594e-04, Val Loss: 2.0248e-03, LR: 1.0000e-04, Time: 97.42s
2025-06-09 17:04:41,294 - Epoch 9, lambda= 0.0000, Train Loss: 5.7613e-04, Val Loss: 2.2358e-03, LR: 5.0000e-05, Time: 98.21s
2025-06-09 17:06:20,106 - Epoch 10, lambda= 0.0000, Train Loss: 4.6919e-04, Val Loss: 2.4636e-03, LR: 5.0000e-05, Time: 98.79s
2025-06-09 17:07:59,233 - Epoch 11, lambda= 0.0000, Train Loss: 4.5600e-04, Val Loss: 2.0533e-03, LR: 5.0000e-05, Time: 99.10s
2025-06-09 17:09:36,613 - Epoch 12, lambda= 0.0000, Train Loss: 4.1812e-04, Val Loss: 4.2127e-03, LR: 5.0000e-05, Time: 97.35s
2025-06-09 17:11:16,872 - Epoch 13, lambda= 0.0000, Train Loss: 3.9617e-04, Val Loss: 4.0382e-03, LR: 5.0000e-05, Time: 100.23s
2025-06-09 17:12:54,117 - Epoch 14, lambda= 0.0000, Train Loss: 4.5612e-04, Val Loss: 2.6186e-03, LR: 5.0000e-05, Time: 97.15s
2025-06-09 17:14:31,970 - Epoch 15, lambda= 0.0000, Train Loss: 4.2326e-04, Val Loss: 2.7501e-03, LR: 2.5000e-05, Time: 97.83s
2025-06-09 17:16:09,511 - Epoch 16, lambda= 0.0000, Train Loss: 3.3301e-04, Val Loss: 2.8857e-03, LR: 2.5000e-05, Time: 97.52s
2025-06-09 17:17:47,091 - Epoch 17, lambda= 0.0000, Train Loss: 2.7950e-04, Val Loss: 4.0537e-03, LR: 2.5000e-05, Time: 97.55s
2025-06-09 17:19:24,278 - Epoch 18, lambda= 0.0000, Train Loss: 2.5156e-04, Val Loss: 3.9620e-03, LR: 2.5000e-05, Time: 97.16s
2025-06-09 17:21:08,221 - Epoch 19, lambda= 0.0000, Train Loss: 2.3091e-04, Val Loss: 4.5726e-03, LR: 2.5000e-05, Time: 103.88s
2025-06-09 17:22:47,820 - Epoch 20, lambda= 0.0000, Train Loss: 2.1714e-04, Val Loss: 4.5720e-03, LR: 2.5000e-05, Time: 99.57s
2025-06-09 17:24:25,304 - Epoch 21, lambda= 0.0000, Train Loss: 2.0773e-04, Val Loss: 4.3247e-03, LR: 1.2500e-05, Time: 97.40s
2025-06-09 17:26:02,804 - Epoch 22, lambda= 0.0000, Train Loss: 1.8723e-04, Val Loss: 4.5362e-03, LR: 1.2500e-05, Time: 97.47s
2025-06-09 17:27:40,456 - Epoch 23, lambda= 0.0000, Train Loss: 1.8014e-04, Val Loss: 4.5079e-03, LR: 1.2500e-05, Time: 97.63s
2025-06-09 17:27:40,480 - Early stopping at epoch 23
2025-06-09 17:27:40,487 - [task0] Training completed.
2025-06-09 17:27:40,489 - [task0] Consolidating EWC...
2025-06-09 17:29:05,997 - [task0] Consolidation done.
2025-06-09 17:29:06,000 - [task0] Evaluating best checkpoint...
2025-06-09 17:29:12,719 - [task0 BEST test_base] RMSE: 0.0344, MAE: 0.0286, R2: -0.8749
2025-06-09 17:29:21,284 - [task0 BEST test_full] RMSE: 0.0999, MAE: 0.0763, R2: -0.4098
2025-06-09 17:29:21,287 - [task0] Evaluating last checkpoint...
2025-06-09 17:29:26,358 - [task0 LAST test_base] RMSE: 0.0367, MAE: 0.0294, R2: -1.1387
2025-06-09 17:29:34,774 - [task0 LAST test_full] RMSE: 0.0717, MAE: 0.0538, R2: 0.2732
2025-06-09 17:29:34,776 - [task0] Finished.
2025-06-09 17:29:34,778 - [task1] Loading best-by-R2 checkpoint from previous task task0...
2025-06-09 17:29:41,299 - [task0_best] RMSE: 0.0999, MAE: 0.0763, R2: -0.4098
2025-06-09 17:29:47,771 - [task0_last] RMSE: 0.0717, MAE: 0.0538, R2: 0.2732
2025-06-09 17:29:47,807 - [task0] Loaded checkpoint task0_last.pt with R2=0.2732
2025-06-09 17:29:48,020 - [task1] Training...
2025-06-09 17:31:12,682 - Epoch 1, lambda= 0.0000, Train Loss: 1.4904e-03, Val Loss: 2.5734e-03, LR: 1.0000e-04, Time: 84.66s
2025-06-09 17:33:03,824 - Epoch 2, lambda= 0.0000, Train Loss: 1.0032e-03, Val Loss: 2.6470e-03, LR: 1.0000e-04, Time: 111.01s
2025-06-09 17:34:29,169 - Epoch 3, lambda= 0.0000, Train Loss: 1.2105e-03, Val Loss: 3.6453e-03, LR: 1.0000e-04, Time: 85.27s
2025-06-09 17:35:54,351 - Epoch 4, lambda= 0.0000, Train Loss: 9.0064e-04, Val Loss: 1.2018e-03, LR: 1.0000e-04, Time: 85.15s
2025-06-09 17:37:19,947 - Epoch 5, lambda= 0.0000, Train Loss: 5.6470e-04, Val Loss: 1.3669e-03, LR: 1.0000e-04, Time: 85.48s
2025-06-09 17:38:45,300 - Epoch 6, lambda= 0.0000, Train Loss: 7.4526e-04, Val Loss: 3.2468e-03, LR: 1.0000e-04, Time: 85.29s
2025-06-09 17:40:09,877 - Epoch 7, lambda= 0.0000, Train Loss: 6.8385e-04, Val Loss: 6.7421e-04, LR: 1.0000e-04, Time: 84.51s
2025-06-09 17:41:35,327 - Epoch 8, lambda= 0.0000, Train Loss: 4.6988e-04, Val Loss: 1.1287e-03, LR: 1.0000e-04, Time: 85.32s
2025-06-09 17:43:00,613 - Epoch 9, lambda= 0.0000, Train Loss: 4.6079e-04, Val Loss: 9.6204e-04, LR: 1.0000e-04, Time: 85.23s
2025-06-09 17:44:25,959 - Epoch 10, lambda= 0.0000, Train Loss: 6.0365e-04, Val Loss: 1.6408e-03, LR: 1.0000e-04, Time: 85.29s
2025-06-09 17:45:51,291 - Epoch 11, lambda= 0.0000, Train Loss: 7.0775e-04, Val Loss: 2.2971e-03, LR: 1.0000e-04, Time: 85.27s
2025-06-09 17:47:16,696 - Epoch 12, lambda= 0.0000, Train Loss: 6.3166e-04, Val Loss: 1.7523e-03, LR: 1.0000e-04, Time: 85.33s
2025-06-09 17:48:42,043 - Epoch 13, lambda= 0.0000, Train Loss: 5.2536e-04, Val Loss: 1.4492e-03, LR: 5.0000e-05, Time: 85.29s
2025-06-09 17:50:07,403 - Epoch 14, lambda= 0.0000, Train Loss: 3.3292e-04, Val Loss: 1.1237e-03, LR: 5.0000e-05, Time: 85.30s
2025-06-09 17:51:32,262 - Epoch 15, lambda= 0.0000, Train Loss: 2.7596e-04, Val Loss: 1.1243e-03, LR: 5.0000e-05, Time: 84.81s
2025-06-09 17:52:57,385 - Epoch 16, lambda= 0.0000, Train Loss: 2.9434e-04, Val Loss: 1.7775e-03, LR: 5.0000e-05, Time: 85.05s
2025-06-09 17:54:22,760 - Epoch 17, lambda= 0.0000, Train Loss: 2.5376e-04, Val Loss: 1.3383e-03, LR: 5.0000e-05, Time: 85.31s
2025-06-09 17:55:48,119 - Epoch 18, lambda= 0.0000, Train Loss: 2.4713e-04, Val Loss: 1.5518e-03, LR: 5.0000e-05, Time: 85.27s
2025-06-09 17:57:13,829 - Epoch 19, lambda= 0.0000, Train Loss: 2.4226e-04, Val Loss: 1.6280e-03, LR: 2.5000e-05, Time: 85.65s
2025-06-09 17:58:39,233 - Epoch 20, lambda= 0.0000, Train Loss: 1.9456e-04, Val Loss: 1.4717e-03, LR: 2.5000e-05, Time: 85.35s
2025-06-09 18:00:04,683 - Epoch 21, lambda= 0.0000, Train Loss: 1.9826e-04, Val Loss: 1.9177e-03, LR: 2.5000e-05, Time: 85.39s
2025-06-09 18:01:30,250 - Epoch 22, lambda= 0.0000, Train Loss: 1.8015e-04, Val Loss: 1.6594e-03, LR: 2.5000e-05, Time: 85.50s
2025-06-09 18:02:55,365 - Epoch 23, lambda= 0.0000, Train Loss: 1.8351e-04, Val Loss: 1.5636e-03, LR: 2.5000e-05, Time: 85.04s
2025-06-09 18:04:20,511 - Epoch 24, lambda= 0.0000, Train Loss: 1.7016e-04, Val Loss: 1.7422e-03, LR: 2.5000e-05, Time: 85.03s
2025-06-09 18:05:45,828 - Epoch 25, lambda= 0.0000, Train Loss: 1.6376e-04, Val Loss: 1.8164e-03, LR: 1.2500e-05, Time: 85.28s
2025-06-09 18:07:11,374 - Epoch 26, lambda= 0.0000, Train Loss: 1.5125e-04, Val Loss: 1.7134e-03, LR: 1.2500e-05, Time: 85.51s
2025-06-09 18:08:36,625 - Epoch 27, lambda= 0.0000, Train Loss: 1.4760e-04, Val Loss: 1.6559e-03, LR: 1.2500e-05, Time: 85.22s
2025-06-09 18:08:36,660 - Early stopping at epoch 27
2025-06-09 18:08:36,668 - [task1] Training completed.
2025-06-09 18:08:36,670 - [task1] Consolidating EWC...
2025-06-09 18:09:49,624 - [task1] Consolidation done.
2025-06-09 18:09:49,626 - [task1] Evaluating best checkpoint...
2025-06-09 18:09:53,614 - [task1 BEST test_update1] RMSE: 0.0246, MAE: 0.0198, R2: 0.0611
2025-06-09 18:10:02,294 - [task1 BEST test_full] RMSE: 0.0511, MAE: 0.0446, R2: 0.6315
2025-06-09 18:10:02,297 - [task1] Evaluating last checkpoint...
2025-06-09 18:10:06,022 - [task1 LAST test_update1] RMSE: 0.0242, MAE: 0.0221, R2: 0.0968
2025-06-09 18:10:14,625 - [task1 LAST test_full] RMSE: 0.0513, MAE: 0.0462, R2: 0.6284
2025-06-09 18:10:14,627 - [task1] Finished.
2025-06-09 18:10:14,629 - [task2] Loading best-by-R2 checkpoint from previous task task1...
2025-06-09 18:10:21,133 - [task1_best] RMSE: 0.0511, MAE: 0.0446, R2: 0.6315
2025-06-09 18:10:27,606 - [task1_last] RMSE: 0.0513, MAE: 0.0462, R2: 0.6284
2025-06-09 18:10:27,648 - [task1] Loaded checkpoint task1_best.pt with R2=0.6315
2025-06-09 18:10:27,878 - [task2] Training...
2025-06-09 18:10:57,280 - Epoch 1, lambda= 0.0000, Train Loss: 1.6146e-03, Val Loss: 1.5302e-03, LR: 1.0000e-04, Time: 29.38s
2025-06-09 18:11:26,947 - Epoch 2, lambda= 0.0000, Train Loss: 1.3563e-03, Val Loss: 2.1289e-03, LR: 1.0000e-04, Time: 29.58s
2025-06-09 18:11:56,634 - Epoch 3, lambda= 0.0000, Train Loss: 1.3115e-03, Val Loss: 1.8713e-03, LR: 1.0000e-04, Time: 29.64s
2025-06-09 18:12:26,241 - Epoch 4, lambda= 0.0000, Train Loss: 9.6778e-04, Val Loss: 1.7958e-03, LR: 1.0000e-04, Time: 29.56s
2025-06-09 18:12:56,520 - Epoch 5, lambda= 0.0000, Train Loss: 7.6741e-04, Val Loss: 2.0105e-03, LR: 1.0000e-04, Time: 30.19s
2025-06-09 18:13:27,156 - Epoch 6, lambda= 0.0000, Train Loss: 8.4273e-04, Val Loss: 1.5398e-03, LR: 1.0000e-04, Time: 30.45s
2025-06-09 18:13:57,167 - Epoch 7, lambda= 0.0000, Train Loss: 8.3388e-04, Val Loss: 2.0070e-03, LR: 5.0000e-05, Time: 29.93s
2025-06-09 18:14:26,908 - Epoch 8, lambda= 0.0000, Train Loss: 6.8015e-04, Val Loss: 1.6241e-03, LR: 5.0000e-05, Time: 29.66s
2025-06-09 18:14:56,718 - Epoch 9, lambda= 0.0000, Train Loss: 6.2125e-04, Val Loss: 2.1365e-03, LR: 5.0000e-05, Time: 29.73s
2025-06-09 18:15:26,234 - Epoch 10, lambda= 0.0000, Train Loss: 5.7672e-04, Val Loss: 1.6754e-03, LR: 5.0000e-05, Time: 29.44s
2025-06-09 18:15:55,592 - Epoch 11, lambda= 0.0000, Train Loss: 5.7974e-04, Val Loss: 1.6307e-03, LR: 5.0000e-05, Time: 29.30s
2025-06-09 18:16:25,192 - Epoch 12, lambda= 0.0000, Train Loss: 5.9821e-04, Val Loss: 2.0391e-03, LR: 5.0000e-05, Time: 29.52s
2025-06-09 18:16:54,720 - Epoch 13, lambda= 0.0000, Train Loss: 4.5626e-04, Val Loss: 1.7342e-03, LR: 2.5000e-05, Time: 29.48s
2025-06-09 18:17:24,396 - Epoch 14, lambda= 0.0000, Train Loss: 3.7238e-04, Val Loss: 1.8849e-03, LR: 2.5000e-05, Time: 29.63s
2025-06-09 18:17:54,036 - Epoch 15, lambda= 0.0000, Train Loss: 3.7461e-04, Val Loss: 2.1830e-03, LR: 2.5000e-05, Time: 29.59s
2025-06-09 18:18:23,676 - Epoch 16, lambda= 0.0000, Train Loss: 3.5643e-04, Val Loss: 2.1014e-03, LR: 2.5000e-05, Time: 29.59s
2025-06-09 18:18:53,438 - Epoch 17, lambda= 0.0000, Train Loss: 3.3414e-04, Val Loss: 2.5280e-03, LR: 2.5000e-05, Time: 29.71s
2025-06-09 18:19:23,126 - Epoch 18, lambda= 0.0000, Train Loss: 3.8660e-04, Val Loss: 1.8396e-03, LR: 2.5000e-05, Time: 29.64s
2025-06-09 18:19:52,923 - Epoch 19, lambda= 0.0000, Train Loss: 3.6752e-04, Val Loss: 1.8815e-03, LR: 1.2500e-05, Time: 29.75s
2025-06-09 18:20:22,626 - Epoch 20, lambda= 0.0000, Train Loss: 4.3744e-04, Val Loss: 2.2808e-03, LR: 1.2500e-05, Time: 29.66s
2025-06-09 18:20:52,192 - Epoch 21, lambda= 0.0000, Train Loss: 3.8852e-04, Val Loss: 2.3214e-03, LR: 1.2500e-05, Time: 29.52s
2025-06-09 18:20:52,236 - Early stopping at epoch 21
2025-06-09 18:20:52,242 - [task2] Training completed.
2025-06-09 18:20:52,244 - [task2] Consolidating EWC...
2025-06-09 18:21:17,169 - [task2] Consolidation done.
2025-06-09 18:21:17,172 - [task2] Evaluating best checkpoint...
2025-06-09 18:21:20,836 - [task2 BEST test_update2] RMSE: 0.0327, MAE: 0.0247, R2: -2.3639
2025-06-09 18:21:29,425 - [task2 BEST test_full] RMSE: 0.0339, MAE: 0.0261, R2: 0.8377
2025-06-09 18:21:29,428 - [task2] Evaluating last checkpoint...
2025-06-09 18:21:33,159 - [task2 LAST test_update2] RMSE: 0.0473, MAE: 0.0450, R2: -6.0517
2025-06-09 18:21:41,637 - [task2 LAST test_full] RMSE: 0.0346, MAE: 0.0279, R2: 0.8304
2025-06-09 18:21:41,639 - [task2] Finished.
2025-06-09 18:21:41,640 - ==== All tasks completed ====
