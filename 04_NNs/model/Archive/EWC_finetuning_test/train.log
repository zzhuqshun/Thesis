2025-06-23 10:44:04,047 - ==== Skipping joint LSTM Training Phase ====
2025-06-23 10:44:04,049 - ==== Incremental EWC Training Phase ====
2025-06-23 10:45:28,195 - Base train IDs: ['03', '05', '07', '27']
2025-06-23 10:45:28,220 - Base train size: 92079
2025-06-23 10:45:28,225 - Base val IDs: ['01']
2025-06-23 10:45:28,232 - Base val size: 28612
2025-06-23 10:45:28,238 - Update1 train IDs: ['21', '23', '25']
2025-06-23 10:45:28,245 - Update1 train size: 65674
2025-06-23 10:45:28,251 - Update1 val IDs: ['19']
2025-06-23 10:45:28,257 - Update1 val size: 23120
2025-06-23 10:45:28,263 - Update2 train IDs: ['09', '11', '15', '29']
2025-06-23 10:45:28,270 - Update2 train size: 47891
2025-06-23 10:45:28,276 - Update2 val IDs: ['13']
2025-06-23 10:45:28,283 - Update2 val size: 6445
2025-06-23 10:45:35,293 - Test cell ID: 17
2025-06-23 10:45:35,300 - Test size: 22872
2025-06-23 10:45:35,306 - Test base size: 11139
2025-06-23 10:45:35,312 - Test update1 size: 6312
2025-06-23 10:45:35,318 - Test update2 size: 5421
2025-06-23 10:45:35,363 - [Scaler after fit] center_=[ 3.31975183  0.         27.55116667]
2025-06-23 10:45:35,390 - [Scaler after fit] scale_ =[0.20016217 1.86108033 1.05333333]
2025-06-23 10:45:35,397 - Resampling and scaling complete with RobustScaler
2025-06-23 10:45:36,740 - [task0] Training...
2025-06-23 10:45:36,747 - [task0] Using ewc_lambda=0
2025-06-23 10:50:40,699 - Epoch 1, Train Loss: 3.8182e-02, Val Loss: 3.7162e-04, LR: 1.0000e-04, Time: 106.79s
2025-06-23 10:52:22,870 - Epoch 2, Train Loss: 7.2867e-03, Val Loss: 1.0398e-03, LR: 1.0000e-04, Time: 101.99s
2025-06-23 10:54:06,541 - Epoch 3, Train Loss: 5.3097e-03, Val Loss: 3.9763e-04, LR: 1.0000e-04, Time: 103.57s
2025-06-23 10:56:04,449 - Epoch 4, Train Loss: 4.3294e-03, Val Loss: 5.3001e-04, LR: 1.0000e-04, Time: 117.73s
2025-06-23 10:57:54,814 - Epoch 5, Train Loss: 3.4420e-03, Val Loss: 4.4389e-04, LR: 1.0000e-04, Time: 110.24s
2025-06-23 10:59:12,406 - Epoch 6, Train Loss: 2.6740e-03, Val Loss: 4.3592e-04, LR: 1.0000e-04, Time: 77.53s
2025-06-23 11:00:30,043 - Epoch 7, Train Loss: 2.0609e-03, Val Loss: 4.5443e-04, LR: 5.0000e-05, Time: 77.57s
2025-06-23 11:01:48,281 - Epoch 8, Train Loss: 1.6517e-03, Val Loss: 4.0441e-04, LR: 5.0000e-05, Time: 78.21s
2025-06-23 11:03:06,612 - Epoch 9, Train Loss: 1.4034e-03, Val Loss: 4.0720e-04, LR: 5.0000e-05, Time: 78.30s
2025-06-23 11:04:25,040 - Epoch 10, Train Loss: 1.1964e-03, Val Loss: 5.0908e-04, LR: 5.0000e-05, Time: 78.37s
2025-06-23 11:05:42,698 - Epoch 11, Train Loss: 1.0292e-03, Val Loss: 4.2328e-04, LR: 5.0000e-05, Time: 77.60s
2025-06-23 11:07:01,539 - Epoch 12, Train Loss: 8.7673e-04, Val Loss: 4.3260e-04, LR: 5.0000e-05, Time: 78.81s
2025-06-23 11:08:19,525 - Epoch 13, Train Loss: 7.6261e-04, Val Loss: 4.6050e-04, LR: 2.5000e-05, Time: 77.96s
2025-06-23 11:09:37,973 - Epoch 14, Train Loss: 6.8891e-04, Val Loss: 4.3581e-04, LR: 2.5000e-05, Time: 78.37s
2025-06-23 11:10:56,424 - Epoch 15, Train Loss: 6.5224e-04, Val Loss: 4.0288e-04, LR: 2.5000e-05, Time: 78.40s
2025-06-23 11:12:14,921 - Epoch 16, Train Loss: 6.1891e-04, Val Loss: 4.0849e-04, LR: 2.5000e-05, Time: 78.47s
2025-06-23 11:13:33,093 - Epoch 17, Train Loss: 5.8846e-04, Val Loss: 4.4307e-04, LR: 2.5000e-05, Time: 78.14s
2025-06-23 11:14:50,752 - Epoch 18, Train Loss: 5.6076e-04, Val Loss: 4.2150e-04, LR: 2.5000e-05, Time: 77.59s
2025-06-23 11:16:07,731 - Epoch 19, Train Loss: 5.3125e-04, Val Loss: 4.3309e-04, LR: 1.2500e-05, Time: 76.91s
2025-06-23 11:17:25,677 - Epoch 20, Train Loss: 5.0491e-04, Val Loss: 3.9249e-04, LR: 1.2500e-05, Time: 77.88s
2025-06-23 11:18:44,080 - Epoch 21, Train Loss: 4.9213e-04, Val Loss: 3.9523e-04, LR: 1.2500e-05, Time: 78.32s
2025-06-23 11:18:44,103 - Early stopping at epoch 21
2025-06-23 11:18:47,303 - [task0] Training completed.
2025-06-23 11:18:47,306 - [task0] Consolidating EWC...
2025-06-23 11:19:51,984 - [task0] Consolidation done.
2025-06-23 11:19:51,986 - [task0] Baseline evaluation on own task task0 ...
2025-06-23 11:19:57,163 - [task0 Baseline on task0] RMSE: 5.1834e-02, MAE: 4.5294e-02
2025-06-23 11:19:57,165 - [task0] Baseline testing completed.
2025-06-23 11:19:57,167 - [task0] ACC (-MAE): -4.5294e-02
2025-06-23 11:19:57,170 - [task0] Evaluating BEST checkpoint...
2025-06-23 11:20:05,580 - [task0 Evaluation on full test set] RMSE: 8.5567e-02, MAE: 6.7164e-02, R2: -0.0342
2025-06-23 11:20:05,582 - [task0] Evaluation completed.
2025-06-23 11:20:05,584 - [task1] Loading best checkpoint from previous task task0...
2025-06-23 11:20:07,407 - [task1 Pre-FWT baseline] RMSE: 5.6626e-02, MAE: 4.3428e-02
2025-06-23 11:20:07,493 - [task1] Training...
2025-06-23 11:20:07,495 - [task1] Using ewc_lambda=0
2025-06-23 11:21:03,190 - Epoch 1, Train Loss: 8.6539e-03, Val Loss: 1.4929e-03, LR: 1.0000e-04, Time: 55.68s
2025-06-23 11:21:58,762 - Epoch 2, Train Loss: 6.9575e-03, Val Loss: 1.9482e-03, LR: 1.0000e-04, Time: 55.49s
2025-06-23 11:22:54,720 - Epoch 3, Train Loss: 6.0598e-03, Val Loss: 1.7421e-03, LR: 1.0000e-04, Time: 55.88s
2025-06-23 11:23:56,627 - Epoch 4, Train Loss: 5.4301e-03, Val Loss: 2.1904e-03, LR: 1.0000e-04, Time: 61.80s
2025-06-23 11:25:15,918 - Epoch 5, Train Loss: 4.7954e-03, Val Loss: 1.9647e-03, LR: 1.0000e-04, Time: 79.16s
2025-06-23 11:26:33,471 - Epoch 6, Train Loss: 4.0399e-03, Val Loss: 1.6198e-03, LR: 1.0000e-04, Time: 77.44s
2025-06-23 11:27:48,150 - Epoch 7, Train Loss: 3.5849e-03, Val Loss: 1.0400e-03, LR: 1.0000e-04, Time: 74.60s
2025-06-23 11:29:09,676 - Epoch 8, Train Loss: 3.0624e-03, Val Loss: 1.8743e-03, LR: 1.0000e-04, Time: 81.31s
2025-06-23 11:30:37,758 - Epoch 9, Train Loss: 2.8341e-03, Val Loss: 1.2170e-03, LR: 1.0000e-04, Time: 87.91s
2025-06-23 11:31:57,655 - Epoch 10, Train Loss: 2.2150e-03, Val Loss: 1.7948e-03, LR: 1.0000e-04, Time: 79.74s
2025-06-23 11:33:31,442 - Epoch 11, Train Loss: 1.8689e-03, Val Loss: 1.4164e-03, LR: 1.0000e-04, Time: 93.62s
2025-06-23 11:34:48,780 - Epoch 12, Train Loss: 1.5526e-03, Val Loss: 8.4154e-04, LR: 1.0000e-04, Time: 77.24s
2025-06-23 11:36:08,887 - Epoch 13, Train Loss: 1.0892e-03, Val Loss: 1.6245e-03, LR: 1.0000e-04, Time: 79.91s
2025-06-23 11:37:36,797 - Epoch 14, Train Loss: 9.8350e-04, Val Loss: 1.6004e-03, LR: 1.0000e-04, Time: 87.70s
2025-06-23 11:38:52,180 - Epoch 15, Train Loss: 8.4239e-04, Val Loss: 2.3336e-03, LR: 1.0000e-04, Time: 75.26s
2025-06-23 11:39:57,295 - Epoch 16, Train Loss: 8.3478e-04, Val Loss: 3.1352e-03, LR: 1.0000e-04, Time: 64.97s
2025-06-23 11:40:53,413 - Epoch 17, Train Loss: 6.2773e-04, Val Loss: 2.6945e-03, LR: 1.0000e-04, Time: 56.07s
2025-06-23 11:41:50,143 - Epoch 18, Train Loss: 6.5683e-04, Val Loss: 2.8230e-03, LR: 5.0000e-05, Time: 56.55s
2025-06-23 11:42:46,563 - Epoch 19, Train Loss: 5.1792e-04, Val Loss: 3.5868e-03, LR: 5.0000e-05, Time: 56.39s
2025-06-23 11:43:43,298 - Epoch 20, Train Loss: 4.9776e-04, Val Loss: 3.8303e-03, LR: 5.0000e-05, Time: 56.68s
2025-06-23 11:44:39,665 - Epoch 21, Train Loss: 4.2743e-04, Val Loss: 3.6783e-03, LR: 5.0000e-05, Time: 56.30s
2025-06-23 11:45:36,727 - Epoch 22, Train Loss: 4.0077e-04, Val Loss: 4.1828e-03, LR: 5.0000e-05, Time: 57.02s
2025-06-23 11:46:33,390 - Epoch 23, Train Loss: 4.4303e-04, Val Loss: 4.0107e-03, LR: 5.0000e-05, Time: 56.61s
2025-06-23 11:47:29,956 - Epoch 24, Train Loss: 3.7735e-04, Val Loss: 4.0778e-03, LR: 2.5000e-05, Time: 56.53s
2025-06-23 11:48:26,997 - Epoch 25, Train Loss: 3.4940e-04, Val Loss: 4.4630e-03, LR: 2.5000e-05, Time: 56.99s
2025-06-23 11:49:24,638 - Epoch 26, Train Loss: 3.2893e-04, Val Loss: 4.4858e-03, LR: 2.5000e-05, Time: 57.60s
2025-06-23 11:50:21,158 - Epoch 27, Train Loss: 3.2450e-04, Val Loss: 4.5128e-03, LR: 2.5000e-05, Time: 56.48s
2025-06-23 11:51:17,736 - Epoch 28, Train Loss: 3.1858e-04, Val Loss: 4.3360e-03, LR: 2.5000e-05, Time: 56.49s
2025-06-23 11:52:14,125 - Epoch 29, Train Loss: 3.2582e-04, Val Loss: 4.4433e-03, LR: 2.5000e-05, Time: 56.29s
2025-06-23 11:53:10,574 - Epoch 30, Train Loss: 2.9082e-04, Val Loss: 4.3998e-03, LR: 1.2500e-05, Time: 56.41s
2025-06-23 11:54:07,101 - Epoch 31, Train Loss: 2.9921e-04, Val Loss: 4.4527e-03, LR: 1.2500e-05, Time: 56.47s
2025-06-23 11:55:03,957 - Epoch 32, Train Loss: 2.8368e-04, Val Loss: 4.2364e-03, LR: 1.2500e-05, Time: 56.80s
2025-06-23 11:55:03,990 - Early stopping at epoch 32
2025-06-23 11:55:04,736 - [task1] Training completed.
2025-06-23 11:55:04,739 - [task1] Consolidating EWC...
2025-06-23 11:55:50,948 - [task1] Consolidation done.
2025-06-23 11:55:50,970 - [task1] Baseline evaluation on own task task1 ...
2025-06-23 11:55:54,650 - [task1 Baseline on task1] RMSE: 5.9958e-02, MAE: 5.4392e-02
2025-06-23 11:55:54,652 - [task1] Baseline testing completed.
2025-06-23 11:55:54,654 - [task1] Backward testing on previous task task0...
2025-06-23 11:55:59,663 - [task1 BACKWARD on task0] RMSE: 2.2820e-02, MAE: 1.9819e-02
2025-06-23 11:55:59,665 - [task1] Î”MAE on task0: -2.5475e-02
2025-06-23 11:55:59,666 - [task1] ACC (-MAE): -3.7105e-02
2025-06-23 11:55:59,668 - [task1] BWT: -2.5475e-02
2025-06-23 11:55:59,669 - [task1] FWT: -1.0964e-02
2025-06-23 11:55:59,673 - [task1] Evaluating BEST checkpoint...
2025-06-23 11:56:08,119 - [task1 Evaluation on full test set] RMSE: 7.2776e-02, MAE: 5.5645e-02, R2: 0.2519
2025-06-23 11:56:08,120 - [task1] Evaluation completed.
2025-06-23 11:56:08,123 - [task2] Loading best checkpoint from previous task task1...
2025-06-23 11:56:09,606 - [task2 Pre-FWT baseline] RMSE: 1.3424e-01, MAE: 1.3323e-01
2025-06-23 11:56:09,612 - [task2] Training...
2025-06-23 11:56:09,613 - [task2] Using ewc_lambda=0
2025-06-23 11:56:47,293 - Epoch 1, Train Loss: 2.6231e-03, Val Loss: 1.8892e-03, LR: 1.0000e-04, Time: 37.67s
2025-06-23 11:57:24,743 - Epoch 2, Train Loss: 1.6567e-03, Val Loss: 2.0401e-03, LR: 1.0000e-04, Time: 37.36s
2025-06-23 11:58:01,802 - Epoch 3, Train Loss: 1.4714e-03, Val Loss: 2.1895e-03, LR: 1.0000e-04, Time: 37.00s
2025-06-23 11:58:39,458 - Epoch 4, Train Loss: 1.3759e-03, Val Loss: 1.5192e-03, LR: 1.0000e-04, Time: 37.61s
2025-06-23 11:59:16,909 - Epoch 5, Train Loss: 1.3270e-03, Val Loss: 2.3437e-03, LR: 1.0000e-04, Time: 37.35s
2025-06-23 11:59:54,273 - Epoch 6, Train Loss: 1.2532e-03, Val Loss: 2.8240e-03, LR: 1.0000e-04, Time: 37.32s
2025-06-23 12:00:31,770 - Epoch 7, Train Loss: 1.1116e-03, Val Loss: 1.2431e-03, LR: 1.0000e-04, Time: 37.45s
2025-06-23 12:01:09,890 - Epoch 8, Train Loss: 1.0317e-03, Val Loss: 1.1985e-03, LR: 1.0000e-04, Time: 38.02s
2025-06-23 12:01:47,311 - Epoch 9, Train Loss: 1.0613e-03, Val Loss: 1.1072e-03, LR: 1.0000e-04, Time: 37.28s
2025-06-23 12:02:24,404 - Epoch 10, Train Loss: 8.7964e-04, Val Loss: 1.1824e-03, LR: 1.0000e-04, Time: 37.01s
2025-06-23 12:03:01,664 - Epoch 11, Train Loss: 1.0123e-03, Val Loss: 1.3733e-03, LR: 1.0000e-04, Time: 37.22s
2025-06-23 12:03:39,306 - Epoch 12, Train Loss: 8.4440e-04, Val Loss: 1.1269e-03, LR: 1.0000e-04, Time: 37.60s
2025-06-23 12:04:17,321 - Epoch 13, Train Loss: 8.2591e-04, Val Loss: 1.8877e-03, LR: 1.0000e-04, Time: 37.97s
2025-06-23 12:04:56,414 - Epoch 14, Train Loss: 1.0114e-03, Val Loss: 8.5482e-04, LR: 1.0000e-04, Time: 39.03s
2025-06-23 12:05:37,296 - Epoch 15, Train Loss: 8.8381e-04, Val Loss: 8.5777e-04, LR: 1.0000e-04, Time: 40.73s
2025-06-23 12:06:27,230 - Epoch 16, Train Loss: 7.4930e-04, Val Loss: 8.6357e-04, LR: 1.0000e-04, Time: 49.87s
2025-06-23 12:07:13,759 - Epoch 17, Train Loss: 6.8915e-04, Val Loss: 1.1974e-03, LR: 1.0000e-04, Time: 46.41s
2025-06-23 12:08:09,918 - Epoch 18, Train Loss: 6.5304e-04, Val Loss: 6.9207e-04, LR: 1.0000e-04, Time: 56.08s
2025-06-23 12:09:01,262 - Epoch 19, Train Loss: 6.9796e-04, Val Loss: 9.7569e-04, LR: 1.0000e-04, Time: 51.06s
2025-06-23 12:09:48,540 - Epoch 20, Train Loss: 6.0594e-04, Val Loss: 7.4816e-04, LR: 1.0000e-04, Time: 47.15s
2025-06-23 12:10:37,361 - Epoch 21, Train Loss: 5.4850e-04, Val Loss: 7.2984e-04, LR: 1.0000e-04, Time: 48.72s
2025-06-23 12:11:36,435 - Epoch 22, Train Loss: 5.2641e-04, Val Loss: 5.7319e-04, LR: 1.0000e-04, Time: 58.94s
2025-06-23 12:12:24,656 - Epoch 23, Train Loss: 6.5451e-04, Val Loss: 7.8549e-04, LR: 1.0000e-04, Time: 47.90s
2025-06-23 12:13:11,830 - Epoch 24, Train Loss: 5.5450e-04, Val Loss: 4.2797e-04, LR: 1.0000e-04, Time: 47.06s
2025-06-23 12:14:02,604 - Epoch 25, Train Loss: 4.3884e-04, Val Loss: 5.0663e-04, LR: 1.0000e-04, Time: 50.53s
2025-06-23 12:14:56,401 - Epoch 26, Train Loss: 6.7077e-04, Val Loss: 6.4428e-04, LR: 1.0000e-04, Time: 53.69s
2025-06-23 12:15:39,705 - Epoch 27, Train Loss: 6.2894e-04, Val Loss: 5.2455e-04, LR: 1.0000e-04, Time: 43.18s
2025-06-23 12:16:18,860 - Epoch 28, Train Loss: 6.0610e-04, Val Loss: 5.6150e-04, LR: 1.0000e-04, Time: 39.10s
2025-06-23 12:16:56,687 - Epoch 29, Train Loss: 5.5870e-04, Val Loss: 8.2062e-04, LR: 1.0000e-04, Time: 37.78s
2025-06-23 12:17:34,830 - Epoch 30, Train Loss: 4.7378e-04, Val Loss: 7.4893e-04, LR: 5.0000e-05, Time: 38.09s
2025-06-23 12:18:14,892 - Epoch 31, Train Loss: 3.8855e-04, Val Loss: 4.1315e-04, LR: 5.0000e-05, Time: 40.01s
2025-06-23 12:18:52,892 - Epoch 32, Train Loss: 3.6695e-04, Val Loss: 4.5654e-04, LR: 5.0000e-05, Time: 37.87s
2025-06-23 12:19:30,725 - Epoch 33, Train Loss: 3.5049e-04, Val Loss: 4.6085e-04, LR: 5.0000e-05, Time: 37.79s
2025-06-23 12:20:08,693 - Epoch 34, Train Loss: 3.2629e-04, Val Loss: 5.0550e-04, LR: 5.0000e-05, Time: 37.92s
2025-06-23 12:20:46,843 - Epoch 35, Train Loss: 3.2337e-04, Val Loss: 5.0609e-04, LR: 5.0000e-05, Time: 38.10s
2025-06-23 12:21:25,155 - Epoch 36, Train Loss: 3.0845e-04, Val Loss: 5.6572e-04, LR: 5.0000e-05, Time: 38.26s
2025-06-23 12:22:03,651 - Epoch 37, Train Loss: 2.8478e-04, Val Loss: 5.0103e-04, LR: 2.5000e-05, Time: 38.44s
2025-06-23 12:22:42,203 - Epoch 38, Train Loss: 2.6345e-04, Val Loss: 5.2491e-04, LR: 2.5000e-05, Time: 38.50s
2025-06-23 12:23:20,648 - Epoch 39, Train Loss: 2.5969e-04, Val Loss: 3.7747e-04, LR: 2.5000e-05, Time: 38.39s
2025-06-23 12:23:59,246 - Epoch 40, Train Loss: 2.5267e-04, Val Loss: 5.5753e-04, LR: 2.5000e-05, Time: 38.42s
2025-06-23 12:24:37,429 - Epoch 41, Train Loss: 2.4311e-04, Val Loss: 4.0545e-04, LR: 2.5000e-05, Time: 38.11s
2025-06-23 12:25:15,768 - Epoch 42, Train Loss: 2.3732e-04, Val Loss: 4.4316e-04, LR: 2.5000e-05, Time: 38.29s
2025-06-23 12:25:53,933 - Epoch 43, Train Loss: 2.3480e-04, Val Loss: 5.1081e-04, LR: 2.5000e-05, Time: 38.09s
2025-06-23 12:26:31,985 - Epoch 44, Train Loss: 2.3067e-04, Val Loss: 3.6498e-04, LR: 2.5000e-05, Time: 38.00s
2025-06-23 12:27:10,069 - Epoch 45, Train Loss: 2.2730e-04, Val Loss: 4.5523e-04, LR: 2.5000e-05, Time: 37.95s
2025-06-23 12:27:48,518 - Epoch 46, Train Loss: 2.2571e-04, Val Loss: 4.3588e-04, LR: 2.5000e-05, Time: 38.40s
2025-06-23 12:28:26,769 - Epoch 47, Train Loss: 2.2649e-04, Val Loss: 4.8226e-04, LR: 2.5000e-05, Time: 38.18s
2025-06-23 12:29:04,672 - Epoch 48, Train Loss: 2.1621e-04, Val Loss: 3.5448e-04, LR: 2.5000e-05, Time: 37.84s
2025-06-23 12:29:42,687 - Epoch 49, Train Loss: 2.1395e-04, Val Loss: 4.1460e-04, LR: 2.5000e-05, Time: 37.89s
2025-06-23 12:30:20,682 - Epoch 50, Train Loss: 2.1165e-04, Val Loss: 4.7224e-04, LR: 2.5000e-05, Time: 37.93s
2025-06-23 12:30:59,002 - Epoch 51, Train Loss: 2.1002e-04, Val Loss: 4.9356e-04, LR: 2.5000e-05, Time: 38.25s
2025-06-23 12:31:37,244 - Epoch 52, Train Loss: 2.0616e-04, Val Loss: 4.6199e-04, LR: 2.5000e-05, Time: 38.19s
2025-06-23 12:32:15,471 - Epoch 53, Train Loss: 2.0891e-04, Val Loss: 5.1252e-04, LR: 2.5000e-05, Time: 38.17s
2025-06-23 12:32:53,506 - Epoch 54, Train Loss: 1.9987e-04, Val Loss: 4.7902e-04, LR: 1.2500e-05, Time: 37.96s
2025-06-23 12:33:31,561 - Epoch 55, Train Loss: 1.9114e-04, Val Loss: 4.3722e-04, LR: 1.2500e-05, Time: 37.98s
2025-06-23 12:34:09,191 - Epoch 56, Train Loss: 1.8970e-04, Val Loss: 4.0970e-04, LR: 1.2500e-05, Time: 37.56s
2025-06-23 12:34:46,739 - Epoch 57, Train Loss: 1.8756e-04, Val Loss: 4.7929e-04, LR: 1.2500e-05, Time: 37.50s
2025-06-23 12:35:24,656 - Epoch 58, Train Loss: 1.8834e-04, Val Loss: 4.0713e-04, LR: 1.2500e-05, Time: 37.85s
2025-06-23 12:36:03,502 - Epoch 59, Train Loss: 1.8563e-04, Val Loss: 4.2408e-04, LR: 1.2500e-05, Time: 38.06s
2025-06-23 12:36:47,016 - Epoch 60, Train Loss: 1.8577e-04, Val Loss: 3.7910e-04, LR: 6.2500e-06, Time: 43.46s
2025-06-23 12:37:34,550 - Epoch 61, Train Loss: 1.7859e-04, Val Loss: 4.7907e-04, LR: 6.2500e-06, Time: 47.44s
2025-06-23 12:38:12,521 - Epoch 62, Train Loss: 1.7840e-04, Val Loss: 3.8755e-04, LR: 6.2500e-06, Time: 37.90s
2025-06-23 12:38:50,364 - Epoch 63, Train Loss: 1.7935e-04, Val Loss: 3.7572e-04, LR: 6.2500e-06, Time: 37.78s
2025-06-23 12:39:27,662 - Epoch 64, Train Loss: 1.7389e-04, Val Loss: 4.1197e-04, LR: 6.2500e-06, Time: 37.25s
2025-06-23 12:40:05,907 - Epoch 65, Train Loss: 1.7651e-04, Val Loss: 4.4472e-04, LR: 6.2500e-06, Time: 38.19s
2025-06-23 12:40:43,291 - Epoch 66, Train Loss: 1.7399e-04, Val Loss: 4.4421e-04, LR: 3.1250e-06, Time: 37.34s
2025-06-23 12:41:21,399 - Epoch 67, Train Loss: 1.7365e-04, Val Loss: 4.7581e-04, LR: 3.1250e-06, Time: 38.06s
2025-06-23 12:42:02,566 - Epoch 68, Train Loss: 1.7350e-04, Val Loss: 4.2199e-04, LR: 3.1250e-06, Time: 41.09s
2025-06-23 12:42:02,655 - Early stopping at epoch 68
2025-06-23 12:42:03,478 - [task2] Training completed.
2025-06-23 12:42:03,497 - [task2] Consolidating EWC...
2025-06-23 12:42:37,223 - [task2] Consolidation done.
2025-06-23 12:42:37,227 - [task2] Baseline evaluation on own task task2 ...
2025-06-23 12:42:41,206 - [task2 Baseline on task2] RMSE: 3.0758e-02, MAE: 2.5571e-02
2025-06-23 12:42:41,209 - [task2] Baseline testing completed.
2025-06-23 12:42:41,217 - [task2] Backward testing on previous task task0...
2025-06-23 12:42:46,589 - [task2 BACKWARD on task0] RMSE: 5.0629e-02, MAE: 4.7440e-02
2025-06-23 12:42:46,600 - [task2] Backward testing on previous task task1...
2025-06-23 12:42:50,157 - [task2 BACKWARD on task1] RMSE: 1.8989e-02, MAE: 1.6703e-02
2025-06-23 12:42:50,160 - [task2] Î”MAE on task0: +2.1451e-03
2025-06-23 12:42:50,161 - [task2] Î”MAE on task1: -3.7689e-02
2025-06-23 12:42:50,162 - [task2] ACC (-MAE): -2.9905e-02
2025-06-23 12:42:50,164 - [task2] BWT: -1.7772e-02
2025-06-23 12:42:50,165 - [task2] FWT: +1.0765e-01
2025-06-23 12:42:50,172 - [task2] Evaluating BEST checkpoint...
2025-06-23 12:42:59,358 - [task2 Evaluation on full test set] RMSE: 3.9037e-02, MAE: 3.2967e-02, R2: 0.7847
2025-06-23 12:42:59,362 - [task2] Evaluation completed.
2025-06-23 12:42:59,444 - Saved ACC/BWT/FWT history to /beegfs/home/users/z/zzhuqshun/Thesis/04_NNs/model/EWC_finetuning/incremental/continual_metrics.csv
2025-06-23 12:43:00,172 - ==== All tasks completed ====
