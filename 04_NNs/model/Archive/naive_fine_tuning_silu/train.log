2025-06-17 15:58:44,134 - ==== Regular LSTM Training Phase ====
2025-06-17 16:00:05,881 - Base train IDs: ['03', '05', '07', '09', '11', '15', '21', '23', '25', '27', '29']
2025-06-17 16:00:05,883 - Base train size: 205644
2025-06-17 16:00:05,885 - Base val IDs: ['01', '19', '13']
2025-06-17 16:00:05,886 - Base val size: 58177
2025-06-17 16:00:05,888 - Update1 train IDs: []
2025-06-17 16:00:05,890 - Update1 train size: 0
2025-06-17 16:00:05,891 - Update1 val IDs: []
2025-06-17 16:00:05,892 - Update1 val size: 0
2025-06-17 16:00:05,894 - Update2 train IDs: []
2025-06-17 16:00:05,895 - Update2 train size: 0
2025-06-17 16:00:05,896 - Update2 val IDs: []
2025-06-17 16:00:05,897 - Update2 val size: 0
2025-06-17 16:00:12,647 - Test cell ID: 17
2025-06-17 16:00:12,648 - Test size: 22872
2025-06-17 16:00:12,649 - Test base size: 11139
2025-06-17 16:00:12,650 - Test update1 size: 6312
2025-06-17 16:00:12,651 - Test update2 size: 5421
2025-06-17 16:00:12,689 - [Scaler after fit] center_=[ 3.342422    0.17992967 27.75      ]
2025-06-17 16:00:12,695 - [Scaler after fit] scale_ =[0.18428363 1.77955483 1.81783333]
2025-06-17 16:00:12,696 - Resampling and scaling complete with RobustScaler
2025-06-17 16:03:42,794 - Epoch 1, Train Loss: 1.7949e-02, Val Loss: 2.5120e-03, LR: 1.0000e-04, Time: 175.96s
2025-06-17 16:06:35,972 - Epoch 2, Train Loss: 6.5982e-03, Val Loss: 1.6559e-03, LR: 1.0000e-04, Time: 173.02s
2025-06-17 16:09:27,873 - Epoch 3, Train Loss: 4.2046e-03, Val Loss: 2.1427e-03, LR: 1.0000e-04, Time: 171.82s
2025-06-17 16:12:19,325 - Epoch 4, Train Loss: 2.5837e-03, Val Loss: 1.1665e-03, LR: 1.0000e-04, Time: 171.39s
2025-06-17 16:15:11,677 - Epoch 5, Train Loss: 1.6416e-03, Val Loss: 7.4783e-04, LR: 1.0000e-04, Time: 172.24s
2025-06-17 16:18:04,721 - Epoch 6, Train Loss: 1.0313e-03, Val Loss: 6.6285e-04, LR: 1.0000e-04, Time: 172.94s
2025-06-17 16:20:55,466 - Epoch 7, Train Loss: 7.4494e-04, Val Loss: 5.7249e-04, LR: 1.0000e-04, Time: 170.61s
2025-06-17 16:24:20,138 - Epoch 8, Train Loss: 4.3454e-04, Val Loss: 1.3513e-03, LR: 1.0000e-04, Time: 204.63s
2025-06-17 16:29:22,061 - Epoch 9, Train Loss: 2.8853e-04, Val Loss: 6.5939e-04, LR: 1.0000e-04, Time: 301.77s
2025-06-17 16:34:17,904 - Epoch 10, Train Loss: 2.0612e-04, Val Loss: 4.5780e-04, LR: 1.0000e-04, Time: 295.62s
2025-06-17 16:38:12,971 - Epoch 11, Train Loss: 1.7974e-04, Val Loss: 4.9040e-04, LR: 1.0000e-04, Time: 234.76s
2025-06-17 16:41:06,918 - Epoch 12, Train Loss: 1.3610e-04, Val Loss: 5.0822e-04, LR: 1.0000e-04, Time: 173.89s
2025-06-17 16:44:00,556 - Epoch 13, Train Loss: 1.1598e-04, Val Loss: 7.4476e-04, LR: 1.0000e-04, Time: 173.58s
2025-06-17 16:46:53,278 - Epoch 14, Train Loss: 1.0737e-04, Val Loss: 9.3879e-04, LR: 1.0000e-04, Time: 172.64s
2025-06-17 16:49:44,902 - Epoch 15, Train Loss: 1.0303e-04, Val Loss: 8.2136e-04, LR: 1.0000e-04, Time: 171.55s
2025-06-17 16:52:37,431 - Epoch 16, Train Loss: 9.9025e-05, Val Loss: 7.0266e-04, LR: 5.0000e-05, Time: 172.36s
2025-06-17 16:55:29,971 - Epoch 17, Train Loss: 8.0732e-05, Val Loss: 7.4719e-04, LR: 5.0000e-05, Time: 172.46s
2025-06-17 16:58:22,724 - Epoch 18, Train Loss: 8.1181e-05, Val Loss: 7.9510e-04, LR: 5.0000e-05, Time: 172.66s
2025-06-17 17:01:28,636 - Epoch 19, Train Loss: 8.0706e-05, Val Loss: 6.5364e-04, LR: 5.0000e-05, Time: 185.83s
2025-06-17 17:05:36,854 - Epoch 20, Train Loss: 7.8654e-05, Val Loss: 7.4294e-04, LR: 5.0000e-05, Time: 248.03s
2025-06-17 17:10:14,882 - Epoch 21, Train Loss: 7.9538e-05, Val Loss: 6.9276e-04, LR: 5.0000e-05, Time: 277.78s
2025-06-17 17:14:02,503 - Epoch 22, Train Loss: 7.6866e-05, Val Loss: 6.3988e-04, LR: 2.5000e-05, Time: 227.40s
2025-06-17 17:16:54,341 - Epoch 23, Train Loss: 7.0670e-05, Val Loss: 6.9753e-04, LR: 2.5000e-05, Time: 171.81s
2025-06-17 17:19:48,190 - Epoch 24, Train Loss: 6.9899e-05, Val Loss: 7.2098e-04, LR: 2.5000e-05, Time: 173.77s
2025-06-17 17:22:41,898 - Epoch 25, Train Loss: 6.9969e-05, Val Loss: 6.5738e-04, LR: 2.5000e-05, Time: 173.66s
2025-06-17 17:25:35,150 - Epoch 26, Train Loss: 6.9215e-05, Val Loss: 6.5217e-04, LR: 2.5000e-05, Time: 173.19s
2025-06-17 17:28:29,351 - Epoch 27, Train Loss: 6.8898e-05, Val Loss: 6.1805e-04, LR: 2.5000e-05, Time: 174.16s
2025-06-17 17:31:22,269 - Epoch 28, Train Loss: 6.8426e-05, Val Loss: 6.2539e-04, LR: 1.2500e-05, Time: 172.78s
2025-06-17 17:34:15,734 - Epoch 29, Train Loss: 6.4378e-05, Val Loss: 6.1934e-04, LR: 1.2500e-05, Time: 173.38s
2025-06-17 17:37:06,874 - Epoch 30, Train Loss: 6.3955e-05, Val Loss: 5.9967e-04, LR: 1.2500e-05, Time: 171.06s
2025-06-17 17:37:06,910 - Early stopping at epoch 30
2025-06-17 17:37:20,462 - [Joint training best model predictions] RMSE: 1.9217e-02, MAE: 1.3227e-02, R2: 0.9478
2025-06-17 17:37:20,464 - ==== Incremental EWC Training Phase ====
2025-06-17 17:39:21,399 - Base train IDs: ['03', '05', '07', '27']
2025-06-17 17:39:21,502 - Base train size: 92079
2025-06-17 17:39:21,512 - Base val IDs: ['01']
2025-06-17 17:39:21,518 - Base val size: 28612
2025-06-17 17:39:21,524 - Update1 train IDs: ['21', '23', '25']
2025-06-17 17:39:21,532 - Update1 train size: 65674
2025-06-17 17:39:21,540 - Update1 val IDs: ['19']
2025-06-17 17:39:21,548 - Update1 val size: 23120
2025-06-17 17:39:21,558 - Update2 train IDs: ['09', '11', '15', '29']
2025-06-17 17:39:21,567 - Update2 train size: 47891
2025-06-17 17:39:21,577 - Update2 val IDs: ['13']
2025-06-17 17:39:21,586 - Update2 val size: 6445
2025-06-17 17:39:47,616 - Test cell ID: 17
2025-06-17 17:39:47,622 - Test size: 22872
2025-06-17 17:39:47,633 - Test base size: 11139
2025-06-17 17:39:47,642 - Test update1 size: 6312
2025-06-17 17:39:47,648 - Test update2 size: 5421
2025-06-17 17:39:47,693 - [Scaler after fit] center_=[ 3.31975183  0.         27.55116667]
2025-06-17 17:39:47,699 - [Scaler after fit] scale_ =[0.20016217 1.86108033 1.05333333]
2025-06-17 17:39:47,707 - Resampling and scaling complete with RobustScaler
2025-06-17 17:39:48,007 - [task0] Training...
2025-06-17 17:39:48,013 - [task0] Using ewc_lambda=0
2025-06-17 17:41:58,302 - Epoch 1, Train Loss: 2.6545e-02, Val Loss: 1.8294e-03, LR: 1.0000e-04, Time: 130.19s
2025-06-17 17:44:07,983 - Epoch 2, Train Loss: 6.8713e-03, Val Loss: 4.5667e-04, LR: 1.0000e-04, Time: 129.42s
2025-06-17 17:46:20,494 - Epoch 3, Train Loss: 5.7660e-03, Val Loss: 5.4110e-04, LR: 1.0000e-04, Time: 132.17s
2025-06-17 17:48:32,369 - Epoch 4, Train Loss: 4.6616e-03, Val Loss: 3.9575e-04, LR: 1.0000e-04, Time: 131.62s
2025-06-17 17:50:27,889 - Epoch 5, Train Loss: 3.7258e-03, Val Loss: 4.7192e-04, LR: 1.0000e-04, Time: 115.20s
2025-06-17 17:51:54,003 - Epoch 6, Train Loss: 2.9184e-03, Val Loss: 5.1868e-04, LR: 1.0000e-04, Time: 85.98s
2025-06-17 17:53:10,720 - Epoch 7, Train Loss: 2.2400e-03, Val Loss: 4.8894e-04, LR: 1.0000e-04, Time: 76.69s
2025-06-17 17:54:27,227 - Epoch 8, Train Loss: 1.6859e-03, Val Loss: 4.9659e-04, LR: 1.0000e-04, Time: 76.46s
2025-06-17 17:55:43,748 - Epoch 9, Train Loss: 1.2576e-03, Val Loss: 4.3192e-04, LR: 1.0000e-04, Time: 76.42s
2025-06-17 17:57:01,011 - Epoch 10, Train Loss: 9.4770e-04, Val Loss: 4.0434e-04, LR: 5.0000e-05, Time: 77.20s
2025-06-17 17:58:18,978 - Epoch 11, Train Loss: 7.6964e-04, Val Loss: 4.3737e-04, LR: 5.0000e-05, Time: 77.91s
2025-06-17 17:59:35,873 - Epoch 12, Train Loss: 6.8209e-04, Val Loss: 4.3369e-04, LR: 5.0000e-05, Time: 76.81s
2025-06-17 18:00:53,457 - Epoch 13, Train Loss: 6.1739e-04, Val Loss: 4.0053e-04, LR: 5.0000e-05, Time: 77.45s
2025-06-17 18:02:11,158 - Epoch 14, Train Loss: 5.6570e-04, Val Loss: 4.1914e-04, LR: 5.0000e-05, Time: 77.66s
2025-06-17 18:03:27,966 - Epoch 15, Train Loss: 5.2964e-04, Val Loss: 4.2553e-04, LR: 5.0000e-05, Time: 76.73s
2025-06-17 18:04:44,268 - Epoch 16, Train Loss: 5.0598e-04, Val Loss: 4.1067e-04, LR: 2.5000e-05, Time: 76.25s
2025-06-17 18:06:01,029 - Epoch 17, Train Loss: 4.8701e-04, Val Loss: 3.9850e-04, LR: 2.5000e-05, Time: 76.70s
2025-06-17 18:07:17,432 - Epoch 18, Train Loss: 4.7172e-04, Val Loss: 4.2661e-04, LR: 2.5000e-05, Time: 76.32s
2025-06-17 18:08:33,438 - Epoch 19, Train Loss: 4.5785e-04, Val Loss: 4.4392e-04, LR: 2.5000e-05, Time: 75.94s
2025-06-17 18:09:49,497 - Epoch 20, Train Loss: 4.4661e-04, Val Loss: 4.1027e-04, LR: 2.5000e-05, Time: 75.98s
2025-06-17 18:11:06,239 - Epoch 21, Train Loss: 4.3508e-04, Val Loss: 4.1809e-04, LR: 2.5000e-05, Time: 76.68s
2025-06-17 18:12:46,144 - Epoch 22, Train Loss: 4.2270e-04, Val Loss: 4.0922e-04, LR: 1.2500e-05, Time: 99.80s
2025-06-17 18:14:46,756 - Epoch 23, Train Loss: 3.7506e-04, Val Loss: 4.0174e-04, LR: 1.2500e-05, Time: 120.43s
2025-06-17 18:16:56,890 - Epoch 24, Train Loss: 3.1492e-04, Val Loss: 4.1202e-04, LR: 1.2500e-05, Time: 129.91s
2025-06-17 18:16:57,102 - Early stopping at epoch 24
2025-06-17 18:16:58,937 - [task0] Training completed.
2025-06-17 18:16:58,963 - [task0] Consolidating EWC...
2025-06-17 18:18:03,928 - [task0] Consolidation done.
2025-06-17 18:18:03,965 - [task0] Baseline evaluation on own task task0 ...
2025-06-17 18:18:09,552 - [task0 Baseline on task0] RMSE: 5.4908e-02, MAE: 4.7887e-02
2025-06-17 18:18:09,564 - [task0] Baseline testing completed.
2025-06-17 18:18:09,572 - [task0] ACC (-MAE): -4.7887e-02
2025-06-17 18:18:09,599 - [task0] Evaluating BEST checkpoint...
2025-06-17 18:18:18,791 - [task0 FORWARD on test] RMSE: 9.2666e-02, MAE: 7.4080e-02, R2: -0.2130
2025-06-17 18:18:18,802 - [task0] Forward testing completed.
2025-06-17 18:18:18,830 - [task1] Loading best checkpoint from previous task task0...
2025-06-17 18:18:20,756 - [task1 Pre-FWT baseline] RMSE: 6.2385e-02, MAE: 5.1527e-02
2025-06-17 18:18:20,806 - [task1] Training...
2025-06-17 18:18:20,812 - [task1] Using ewc_lambda=0
2025-06-17 18:19:32,684 - Epoch 1, Train Loss: 5.3734e-03, Val Loss: 1.8981e-03, LR: 1.0000e-04, Time: 71.81s
2025-06-17 18:20:59,159 - Epoch 2, Train Loss: 4.5387e-03, Val Loss: 2.2400e-03, LR: 1.0000e-04, Time: 86.25s
2025-06-17 18:22:28,693 - Epoch 3, Train Loss: 3.9049e-03, Val Loss: 1.0168e-03, LR: 1.0000e-04, Time: 89.31s
2025-06-17 18:23:59,405 - Epoch 4, Train Loss: 3.4020e-03, Val Loss: 1.0727e-03, LR: 1.0000e-04, Time: 90.41s
2025-06-17 18:24:55,768 - Epoch 5, Train Loss: 2.6527e-03, Val Loss: 1.7139e-03, LR: 1.0000e-04, Time: 56.11s
2025-06-17 18:25:51,442 - Epoch 6, Train Loss: 2.2020e-03, Val Loss: 2.2527e-03, LR: 1.0000e-04, Time: 55.59s
2025-06-17 18:26:47,198 - Epoch 7, Train Loss: 1.7173e-03, Val Loss: 2.2495e-03, LR: 1.0000e-04, Time: 55.68s
2025-06-17 18:27:42,855 - Epoch 8, Train Loss: 1.7599e-03, Val Loss: 4.6907e-03, LR: 1.0000e-04, Time: 55.59s
2025-06-17 18:28:38,568 - Epoch 9, Train Loss: 1.2779e-03, Val Loss: 1.8868e-03, LR: 5.0000e-05, Time: 55.48s
2025-06-17 18:29:34,250 - Epoch 10, Train Loss: 9.0692e-04, Val Loss: 3.2131e-03, LR: 5.0000e-05, Time: 55.59s
2025-06-17 18:30:29,682 - Epoch 11, Train Loss: 7.5245e-04, Val Loss: 2.5852e-03, LR: 5.0000e-05, Time: 55.35s
2025-06-17 18:31:25,442 - Epoch 12, Train Loss: 6.7801e-04, Val Loss: 4.8273e-03, LR: 5.0000e-05, Time: 55.48s
2025-06-17 18:32:21,687 - Epoch 13, Train Loss: 6.4095e-04, Val Loss: 3.1323e-03, LR: 5.0000e-05, Time: 56.16s
2025-06-17 18:33:17,162 - Epoch 14, Train Loss: 5.1501e-04, Val Loss: 4.2362e-03, LR: 5.0000e-05, Time: 55.38s
2025-06-17 18:34:12,803 - Epoch 15, Train Loss: 4.2959e-04, Val Loss: 5.1376e-03, LR: 2.5000e-05, Time: 55.60s
2025-06-17 18:35:08,256 - Epoch 16, Train Loss: 3.3344e-04, Val Loss: 6.2829e-03, LR: 2.5000e-05, Time: 55.41s
2025-06-17 18:36:03,666 - Epoch 17, Train Loss: 3.0772e-04, Val Loss: 6.6887e-03, LR: 2.5000e-05, Time: 55.32s
2025-06-17 18:36:59,071 - Epoch 18, Train Loss: 2.8310e-04, Val Loss: 6.2329e-03, LR: 2.5000e-05, Time: 55.32s
2025-06-17 18:37:54,467 - Epoch 19, Train Loss: 2.5634e-04, Val Loss: 6.8112e-03, LR: 2.5000e-05, Time: 55.32s
2025-06-17 18:38:49,782 - Epoch 20, Train Loss: 2.3843e-04, Val Loss: 5.9761e-03, LR: 2.5000e-05, Time: 55.26s
2025-06-17 18:39:45,045 - Epoch 21, Train Loss: 2.2400e-04, Val Loss: 6.3327e-03, LR: 1.2500e-05, Time: 55.21s
2025-06-17 18:40:40,251 - Epoch 22, Train Loss: 2.0012e-04, Val Loss: 6.5259e-03, LR: 1.2500e-05, Time: 55.13s
2025-06-17 18:41:35,741 - Epoch 23, Train Loss: 1.9363e-04, Val Loss: 6.1856e-03, LR: 1.2500e-05, Time: 55.38s
2025-06-17 18:41:35,788 - Early stopping at epoch 23
2025-06-17 18:41:36,202 - [task1] Training completed.
2025-06-17 18:41:36,204 - [task1] Consolidating EWC...
2025-06-17 18:42:22,303 - [task1] Consolidation done.
2025-06-17 18:42:22,305 - [task1] Baseline evaluation on own task task1 ...
2025-06-17 18:42:26,011 - [task1 Baseline on task1] RMSE: 7.3452e-02, MAE: 6.6742e-02
2025-06-17 18:42:26,013 - [task1] Baseline testing completed.
2025-06-17 18:42:26,015 - [task1] Backward testing on previous task task0...
2025-06-17 18:42:30,979 - [task1 BACKWARD on task0] RMSE: 2.5539e-02, MAE: 2.2009e-02
2025-06-17 18:42:30,981 - [task1] ΔMAE on task0: -2.5878e-02
2025-06-17 18:42:30,982 - [task1] ACC (-MAE): -4.4376e-02
2025-06-17 18:42:30,983 - [task1] BWT: -2.5878e-02
2025-06-17 18:42:30,984 - [task1] FWT: -1.5215e-02
2025-06-17 18:42:30,986 - [task1] Evaluating BEST checkpoint...
2025-06-17 18:42:39,315 - [task1 FORWARD on test] RMSE: 7.9622e-02, MAE: 6.0845e-02, R2: 0.1045
2025-06-17 18:42:39,316 - [task1] Forward testing completed.
2025-06-17 18:42:39,318 - [task2] Loading best checkpoint from previous task task1...
2025-06-17 18:42:40,820 - [task2 Pre-FWT baseline] RMSE: 1.4330e-01, MAE: 1.4009e-01
2025-06-17 18:42:40,823 - [task2] Training...
2025-06-17 18:42:40,823 - [task2] Using ewc_lambda=0
2025-06-17 18:43:21,825 - Epoch 1, Train Loss: 5.6749e-03, Val Loss: 2.1936e-03, LR: 1.0000e-04, Time: 41.00s
2025-06-17 18:44:16,459 - Epoch 2, Train Loss: 3.2086e-03, Val Loss: 1.8948e-03, LR: 1.0000e-04, Time: 54.39s
2025-06-17 18:45:13,727 - Epoch 3, Train Loss: 3.0003e-03, Val Loss: 2.1013e-03, LR: 1.0000e-04, Time: 57.01s
2025-06-17 18:46:15,129 - Epoch 4, Train Loss: 2.7844e-03, Val Loss: 1.9066e-03, LR: 1.0000e-04, Time: 61.20s
2025-06-17 18:47:15,844 - Epoch 5, Train Loss: 2.2855e-03, Val Loss: 1.2928e-03, LR: 1.0000e-04, Time: 60.55s
2025-06-17 18:48:19,588 - Epoch 6, Train Loss: 2.0780e-03, Val Loss: 1.9391e-03, LR: 1.0000e-04, Time: 63.35s
2025-06-17 18:49:26,701 - Epoch 7, Train Loss: 1.7746e-03, Val Loss: 1.4215e-03, LR: 1.0000e-04, Time: 66.93s
2025-06-17 18:50:34,424 - Epoch 8, Train Loss: 1.5955e-03, Val Loss: 1.9745e-03, LR: 1.0000e-04, Time: 67.45s
2025-06-17 18:51:42,487 - Epoch 9, Train Loss: 1.5330e-03, Val Loss: 1.7668e-03, LR: 1.0000e-04, Time: 67.77s
2025-06-17 18:52:43,466 - Epoch 10, Train Loss: 1.4146e-03, Val Loss: 3.3853e-03, LR: 1.0000e-04, Time: 60.74s
2025-06-17 18:53:46,280 - Epoch 11, Train Loss: 1.2086e-03, Val Loss: 1.0673e-03, LR: 1.0000e-04, Time: 62.65s
2025-06-17 18:54:47,463 - Epoch 12, Train Loss: 1.1281e-03, Val Loss: 8.6670e-04, LR: 1.0000e-04, Time: 60.86s
2025-06-17 18:55:45,403 - Epoch 13, Train Loss: 1.0870e-03, Val Loss: 1.2546e-03, LR: 1.0000e-04, Time: 57.63s
2025-06-17 18:56:25,794 - Epoch 14, Train Loss: 1.0009e-03, Val Loss: 2.3927e-03, LR: 1.0000e-04, Time: 40.29s
2025-06-17 18:57:03,355 - Epoch 15, Train Loss: 8.6524e-04, Val Loss: 1.4103e-03, LR: 1.0000e-04, Time: 37.51s
2025-06-17 18:57:42,529 - Epoch 16, Train Loss: 8.4087e-04, Val Loss: 1.3150e-03, LR: 1.0000e-04, Time: 39.10s
2025-06-17 18:58:21,537 - Epoch 17, Train Loss: 6.6959e-04, Val Loss: 1.1239e-03, LR: 1.0000e-04, Time: 38.93s
2025-06-17 18:58:59,472 - Epoch 18, Train Loss: 6.2018e-04, Val Loss: 9.7432e-04, LR: 5.0000e-05, Time: 37.87s
2025-06-17 18:59:37,426 - Epoch 19, Train Loss: 4.9887e-04, Val Loss: 8.5287e-04, LR: 5.0000e-05, Time: 37.88s
2025-06-17 19:00:22,157 - Epoch 20, Train Loss: 4.7995e-04, Val Loss: 9.4010e-04, LR: 5.0000e-05, Time: 41.02s
2025-06-17 19:01:01,195 - Epoch 21, Train Loss: 4.5020e-04, Val Loss: 9.7756e-04, LR: 5.0000e-05, Time: 38.94s
2025-06-17 19:01:38,957 - Epoch 22, Train Loss: 4.3044e-04, Val Loss: 8.9246e-04, LR: 5.0000e-05, Time: 37.68s
2025-06-17 19:02:16,699 - Epoch 23, Train Loss: 4.1762e-04, Val Loss: 7.9821e-04, LR: 5.0000e-05, Time: 37.62s
2025-06-17 19:02:53,969 - Epoch 24, Train Loss: 4.2750e-04, Val Loss: 9.7243e-04, LR: 5.0000e-05, Time: 37.14s
2025-06-17 19:03:31,228 - Epoch 25, Train Loss: 3.9927e-04, Val Loss: 8.3732e-04, LR: 5.0000e-05, Time: 37.18s
2025-06-17 19:04:08,466 - Epoch 26, Train Loss: 3.8393e-04, Val Loss: 1.0626e-03, LR: 5.0000e-05, Time: 37.16s
2025-06-17 19:04:45,851 - Epoch 27, Train Loss: 3.6444e-04, Val Loss: 1.1532e-03, LR: 5.0000e-05, Time: 37.30s
2025-06-17 19:05:23,588 - Epoch 28, Train Loss: 3.5162e-04, Val Loss: 9.7839e-04, LR: 5.0000e-05, Time: 37.66s
2025-06-17 19:06:01,267 - Epoch 29, Train Loss: 3.5281e-04, Val Loss: 8.7602e-04, LR: 2.5000e-05, Time: 37.58s
2025-06-17 19:06:39,193 - Epoch 30, Train Loss: 3.0542e-04, Val Loss: 1.0787e-03, LR: 2.5000e-05, Time: 37.87s
2025-06-17 19:07:17,003 - Epoch 31, Train Loss: 3.0395e-04, Val Loss: 1.0619e-03, LR: 2.5000e-05, Time: 37.76s
2025-06-17 19:07:54,758 - Epoch 32, Train Loss: 2.9714e-04, Val Loss: 1.2790e-03, LR: 2.5000e-05, Time: 37.70s
2025-06-17 19:08:31,956 - Epoch 33, Train Loss: 2.8909e-04, Val Loss: 1.1519e-03, LR: 2.5000e-05, Time: 37.15s
2025-06-17 19:09:09,223 - Epoch 34, Train Loss: 2.8245e-04, Val Loss: 1.1870e-03, LR: 2.5000e-05, Time: 37.21s
2025-06-17 19:09:46,353 - Epoch 35, Train Loss: 2.7866e-04, Val Loss: 1.3256e-03, LR: 1.2500e-05, Time: 37.08s
2025-06-17 19:10:26,749 - Epoch 36, Train Loss: 2.5885e-04, Val Loss: 1.1495e-03, LR: 1.2500e-05, Time: 40.32s
2025-06-17 19:11:13,405 - Epoch 37, Train Loss: 2.5600e-04, Val Loss: 1.2393e-03, LR: 1.2500e-05, Time: 46.59s
2025-06-17 19:12:01,075 - Epoch 38, Train Loss: 2.5579e-04, Val Loss: 1.2557e-03, LR: 1.2500e-05, Time: 47.62s
2025-06-17 19:12:40,548 - Epoch 39, Train Loss: 2.4942e-04, Val Loss: 1.3159e-03, LR: 1.2500e-05, Time: 39.43s
2025-06-17 19:13:20,921 - Epoch 40, Train Loss: 2.4288e-04, Val Loss: 1.3513e-03, LR: 1.2500e-05, Time: 40.32s
2025-06-17 19:13:58,691 - Epoch 41, Train Loss: 2.4551e-04, Val Loss: 1.3470e-03, LR: 6.2500e-06, Time: 37.73s
2025-06-17 19:14:36,313 - Epoch 42, Train Loss: 2.3593e-04, Val Loss: 1.3569e-03, LR: 6.2500e-06, Time: 37.57s
2025-06-17 19:15:14,349 - Epoch 43, Train Loss: 2.3402e-04, Val Loss: 1.2711e-03, LR: 6.2500e-06, Time: 37.98s
2025-06-17 19:15:14,424 - Early stopping at epoch 43
2025-06-17 19:15:14,987 - [task2] Training completed.
2025-06-17 19:15:14,990 - [task2] Consolidating EWC...
2025-06-17 19:15:48,647 - [task2] Consolidation done.
2025-06-17 19:15:48,686 - [task2] Baseline evaluation on own task task2 ...
2025-06-17 19:15:51,699 - [task2 Baseline on task2] RMSE: 6.5619e-02, MAE: 6.0292e-02
2025-06-17 19:15:51,700 - [task2] Baseline testing completed.
2025-06-17 19:15:51,702 - [task2] Backward testing on previous task task0...
2025-06-17 19:15:56,758 - [task2 BACKWARD on task0] RMSE: 3.2008e-02, MAE: 2.7004e-02
2025-06-17 19:15:56,761 - [task2] Backward testing on previous task task1...
2025-06-17 19:16:00,424 - [task2 BACKWARD on task1] RMSE: 3.5804e-02, MAE: 3.0007e-02
2025-06-17 19:16:00,425 - [task2] ΔMAE on task0: -2.0883e-02
2025-06-17 19:16:00,426 - [task2] ΔMAE on task1: -3.6735e-02
2025-06-17 19:16:00,428 - [task2] ACC (-MAE): -3.9101e-02
2025-06-17 19:16:00,429 - [task2] BWT: -2.8809e-02
2025-06-17 19:16:00,430 - [task2] FWT: +7.9795e-02
2025-06-17 19:16:00,432 - [task2] Evaluating BEST checkpoint...
2025-06-17 19:16:09,010 - [task2 FORWARD on test] RMSE: 4.2183e-02, MAE: 3.4552e-02, R2: 0.7486
2025-06-17 19:16:09,012 - [task2] Forward testing completed.
2025-06-17 19:16:09,022 - Saved ACC/BWT/FWT history to /beegfs/home/users/z/zzhuqshun/Thesis/04_NNs/model/naive_fine_tuning_silu/incremental/continual_metrics.csv
2025-06-17 19:16:09,451 - ==== All tasks completed ====
