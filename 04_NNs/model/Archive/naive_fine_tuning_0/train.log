2025-06-21 17:08:36,641 - ==== Regular LSTM Training Phase ====
2025-06-21 17:10:07,474 - Base train IDs: ['03', '05', '07', '09', '11', '15', '21', '23', '25', '27', '29']
2025-06-21 17:10:07,475 - Base train size: 205644
2025-06-21 17:10:07,476 - Base val IDs: ['01', '19', '13']
2025-06-21 17:10:07,477 - Base val size: 58177
2025-06-21 17:10:07,478 - Update1 train IDs: []
2025-06-21 17:10:07,479 - Update1 train size: 0
2025-06-21 17:10:07,480 - Update1 val IDs: []
2025-06-21 17:10:07,481 - Update1 val size: 0
2025-06-21 17:10:07,481 - Update2 train IDs: []
2025-06-21 17:10:07,482 - Update2 train size: 0
2025-06-21 17:10:07,483 - Update2 val IDs: []
2025-06-21 17:10:07,484 - Update2 val size: 0
2025-06-21 17:10:15,496 - Test cell ID: 17
2025-06-21 17:10:15,497 - Test size: 22872
2025-06-21 17:10:15,498 - Test base size: 11139
2025-06-21 17:10:15,499 - Test update1 size: 6312
2025-06-21 17:10:15,499 - Test update2 size: 5421
2025-06-21 17:10:15,540 - [Scaler after fit] center_=[ 3.342422    0.17992967 27.75      ]
2025-06-21 17:10:15,566 - [Scaler after fit] scale_ =[0.18428363 1.77955483 1.81783333]
2025-06-21 17:10:15,567 - Resampling and scaling complete with RobustScaler
2025-06-21 17:13:49,175 - Epoch 1, Train Loss: 2.2723e-02, Val Loss: 2.2427e-03, LR: 1.0000e-04, Time: 175.49s
2025-06-21 17:16:40,548 - Epoch 2, Train Loss: 6.2867e-03, Val Loss: 1.1379e-03, LR: 1.0000e-04, Time: 171.20s
2025-06-21 17:19:31,118 - Epoch 3, Train Loss: 3.6614e-03, Val Loss: 1.2391e-03, LR: 1.0000e-04, Time: 170.52s
2025-06-21 17:22:21,873 - Epoch 4, Train Loss: 2.0000e-03, Val Loss: 1.2032e-03, LR: 1.0000e-04, Time: 170.71s
2025-06-21 17:25:12,585 - Epoch 5, Train Loss: 1.1192e-03, Val Loss: 5.6654e-04, LR: 1.0000e-04, Time: 170.67s
2025-06-21 17:28:04,497 - Epoch 6, Train Loss: 5.9559e-04, Val Loss: 8.9163e-04, LR: 1.0000e-04, Time: 171.84s
2025-06-21 17:30:55,729 - Epoch 7, Train Loss: 4.0951e-04, Val Loss: 5.7827e-04, LR: 1.0000e-04, Time: 171.18s
2025-06-21 17:33:51,118 - Epoch 8, Train Loss: 3.1060e-04, Val Loss: 3.5550e-04, LR: 1.0000e-04, Time: 175.30s
2025-06-21 17:36:42,684 - Epoch 9, Train Loss: 2.3761e-04, Val Loss: 4.8509e-04, LR: 1.0000e-04, Time: 171.38s
2025-06-21 17:39:33,495 - Epoch 10, Train Loss: 2.0217e-04, Val Loss: 3.0042e-04, LR: 1.0000e-04, Time: 170.76s
2025-06-21 17:42:24,406 - Epoch 11, Train Loss: 1.8876e-04, Val Loss: 3.5375e-04, LR: 1.0000e-04, Time: 170.85s
2025-06-21 17:45:14,919 - Epoch 12, Train Loss: 1.6527e-04, Val Loss: 2.6464e-04, LR: 1.0000e-04, Time: 170.44s
2025-06-21 17:48:15,803 - Epoch 13, Train Loss: 1.4900e-04, Val Loss: 2.8292e-04, LR: 1.0000e-04, Time: 180.65s
2025-06-21 17:51:07,719 - Epoch 14, Train Loss: 2.1938e-04, Val Loss: 3.0634e-04, LR: 1.0000e-04, Time: 171.86s
2025-06-21 17:53:58,442 - Epoch 15, Train Loss: 1.3704e-04, Val Loss: 3.6347e-04, LR: 1.0000e-04, Time: 170.68s
2025-06-21 17:56:48,812 - Epoch 16, Train Loss: 1.3580e-04, Val Loss: 3.0101e-04, LR: 1.0000e-04, Time: 170.27s
2025-06-21 17:59:39,324 - Epoch 17, Train Loss: 1.3260e-04, Val Loss: 3.0864e-04, LR: 1.0000e-04, Time: 170.39s
2025-06-21 18:02:29,692 - Epoch 18, Train Loss: 1.2779e-04, Val Loss: 2.7150e-04, LR: 5.0000e-05, Time: 170.27s
2025-06-21 18:05:20,043 - Epoch 19, Train Loss: 1.0744e-04, Val Loss: 3.5201e-04, LR: 5.0000e-05, Time: 170.23s
2025-06-21 18:08:10,826 - Epoch 20, Train Loss: 1.0336e-04, Val Loss: 3.4272e-04, LR: 5.0000e-05, Time: 170.71s
2025-06-21 18:11:01,553 - Epoch 21, Train Loss: 1.0237e-04, Val Loss: 3.9322e-04, LR: 5.0000e-05, Time: 170.65s
2025-06-21 18:13:52,307 - Epoch 22, Train Loss: 1.0328e-04, Val Loss: 3.8363e-04, LR: 5.0000e-05, Time: 170.60s
2025-06-21 18:16:43,385 - Epoch 23, Train Loss: 9.9646e-05, Val Loss: 4.8348e-04, LR: 5.0000e-05, Time: 170.60s
2025-06-21 18:20:28,849 - Epoch 24, Train Loss: 9.8422e-05, Val Loss: 4.9786e-04, LR: 2.5000e-05, Time: 225.29s
2025-06-21 18:24:10,179 - Epoch 25, Train Loss: 9.1085e-05, Val Loss: 4.0165e-04, LR: 2.5000e-05, Time: 221.20s
2025-06-21 18:27:00,131 - Epoch 26, Train Loss: 9.0751e-05, Val Loss: 4.5738e-04, LR: 2.5000e-05, Time: 169.83s
2025-06-21 18:29:50,819 - Epoch 27, Train Loss: 8.9891e-05, Val Loss: 4.5964e-04, LR: 2.5000e-05, Time: 169.93s
2025-06-21 18:32:41,363 - Epoch 28, Train Loss: 9.0781e-05, Val Loss: 4.7109e-04, LR: 2.5000e-05, Time: 170.45s
2025-06-21 18:35:32,298 - Epoch 29, Train Loss: 8.7675e-05, Val Loss: 5.2180e-04, LR: 2.5000e-05, Time: 170.83s
2025-06-21 18:38:24,072 - Epoch 30, Train Loss: 8.7188e-05, Val Loss: 4.4292e-04, LR: 1.2500e-05, Time: 171.63s
2025-06-21 18:41:15,872 - Epoch 31, Train Loss: 8.4346e-05, Val Loss: 5.1190e-04, LR: 1.2500e-05, Time: 171.63s
2025-06-21 18:44:08,055 - Epoch 32, Train Loss: 8.3343e-05, Val Loss: 4.7098e-04, LR: 1.2500e-05, Time: 172.02s
2025-06-21 18:44:08,186 - Early stopping at epoch 32
2025-06-21 18:44:22,416 - [Joint training best model predictions] RMSE: 7.2272e-03, MAE: 5.6535e-03, R2: 0.9926
2025-06-21 18:44:22,418 - ==== Incremental EWC Training Phase ====
2025-06-21 18:46:08,452 - Base train IDs: ['03', '05', '07', '27']
2025-06-21 18:46:08,477 - Base train size: 92079
2025-06-21 18:46:08,478 - Base val IDs: ['01']
2025-06-21 18:46:08,479 - Base val size: 28612
2025-06-21 18:46:08,480 - Update1 train IDs: ['21', '23', '25']
2025-06-21 18:46:08,481 - Update1 train size: 65674
2025-06-21 18:46:08,482 - Update1 val IDs: ['19']
2025-06-21 18:46:08,483 - Update1 val size: 23120
2025-06-21 18:46:08,484 - Update2 train IDs: ['09', '11', '15', '29']
2025-06-21 18:46:08,485 - Update2 train size: 47891
2025-06-21 18:46:08,487 - Update2 val IDs: ['13']
2025-06-21 18:46:08,489 - Update2 val size: 6445
2025-06-21 18:46:16,836 - Test cell ID: 17
2025-06-21 18:46:16,837 - Test size: 22872
2025-06-21 18:46:16,838 - Test base size: 11139
2025-06-21 18:46:16,839 - Test update1 size: 6312
2025-06-21 18:46:16,840 - Test update2 size: 5421
2025-06-21 18:46:16,874 - [Scaler after fit] center_=[ 3.31975183  0.         27.55116667]
2025-06-21 18:46:16,875 - [Scaler after fit] scale_ =[0.20016217 1.86108033 1.05333333]
2025-06-21 18:46:16,876 - Resampling and scaling complete with RobustScaler
2025-06-21 18:46:16,920 - [task0] Training...
2025-06-21 18:46:16,920 - [task0] Using ewc_lambda=0
2025-06-21 18:47:33,673 - Epoch 1, Train Loss: 2.6923e-02, Val Loss: 1.8134e-03, LR: 1.0000e-04, Time: 76.64s
2025-06-21 18:48:50,315 - Epoch 2, Train Loss: 6.7456e-03, Val Loss: 4.9343e-04, LR: 1.0000e-04, Time: 76.50s
2025-06-21 18:50:07,059 - Epoch 3, Train Loss: 4.9874e-03, Val Loss: 7.6930e-04, LR: 1.0000e-04, Time: 76.65s
2025-06-21 18:51:23,993 - Epoch 4, Train Loss: 3.8337e-03, Val Loss: 4.5653e-04, LR: 1.0000e-04, Time: 76.87s
2025-06-21 18:52:41,058 - Epoch 5, Train Loss: 3.0282e-03, Val Loss: 6.7126e-04, LR: 1.0000e-04, Time: 76.97s
2025-06-21 18:53:58,096 - Epoch 6, Train Loss: 2.3395e-03, Val Loss: 4.3767e-04, LR: 1.0000e-04, Time: 76.98s
2025-06-21 18:55:15,184 - Epoch 7, Train Loss: 1.7663e-03, Val Loss: 4.6077e-04, LR: 1.0000e-04, Time: 76.95s
2025-06-21 18:56:32,888 - Epoch 8, Train Loss: 1.3287e-03, Val Loss: 4.1030e-04, LR: 1.0000e-04, Time: 77.62s
2025-06-21 18:57:49,965 - Epoch 9, Train Loss: 9.9532e-04, Val Loss: 4.8352e-04, LR: 1.0000e-04, Time: 76.80s
2025-06-21 18:59:06,893 - Epoch 10, Train Loss: 7.6634e-04, Val Loss: 3.9356e-04, LR: 1.0000e-04, Time: 76.87s
2025-06-21 19:00:23,959 - Epoch 11, Train Loss: 6.2421e-04, Val Loss: 4.0848e-04, LR: 1.0000e-04, Time: 76.67s
2025-06-21 19:01:40,405 - Epoch 12, Train Loss: 5.3758e-04, Val Loss: 4.0822e-04, LR: 1.0000e-04, Time: 76.38s
2025-06-21 19:02:57,025 - Epoch 13, Train Loss: 4.8355e-04, Val Loss: 4.4784e-04, LR: 1.0000e-04, Time: 76.53s
2025-06-21 19:04:12,899 - Epoch 14, Train Loss: 4.2101e-04, Val Loss: 5.0703e-04, LR: 1.0000e-04, Time: 75.83s
2025-06-21 19:05:29,595 - Epoch 15, Train Loss: 3.0734e-04, Val Loss: 4.3616e-04, LR: 1.0000e-04, Time: 76.61s
2025-06-21 19:06:46,297 - Epoch 16, Train Loss: 2.8668e-04, Val Loss: 5.3713e-04, LR: 5.0000e-05, Time: 76.51s
2025-06-21 19:08:02,763 - Epoch 17, Train Loss: 2.6253e-04, Val Loss: 7.8095e-04, LR: 5.0000e-05, Time: 76.38s
2025-06-21 19:09:19,188 - Epoch 18, Train Loss: 2.2969e-04, Val Loss: 4.4997e-04, LR: 5.0000e-05, Time: 76.37s
2025-06-21 19:10:35,706 - Epoch 19, Train Loss: 2.4196e-04, Val Loss: 4.5846e-04, LR: 5.0000e-05, Time: 76.48s
2025-06-21 19:11:54,147 - Epoch 20, Train Loss: 2.4104e-04, Val Loss: 4.4583e-04, LR: 5.0000e-05, Time: 78.40s
2025-06-21 19:13:14,694 - Epoch 21, Train Loss: 2.0318e-04, Val Loss: 7.2263e-04, LR: 5.0000e-05, Time: 80.49s
2025-06-21 19:14:36,295 - Epoch 22, Train Loss: 2.1394e-04, Val Loss: 6.8846e-04, LR: 2.5000e-05, Time: 81.52s
2025-06-21 19:16:15,696 - Epoch 23, Train Loss: 1.6277e-04, Val Loss: 6.3528e-04, LR: 2.5000e-05, Time: 99.34s
2025-06-21 19:17:39,829 - Epoch 24, Train Loss: 1.6946e-04, Val Loss: 5.6013e-04, LR: 2.5000e-05, Time: 84.06s
2025-06-21 19:18:56,836 - Epoch 25, Train Loss: 1.5314e-04, Val Loss: 4.5976e-04, LR: 2.5000e-05, Time: 76.93s
2025-06-21 19:20:12,542 - Epoch 26, Train Loss: 1.4391e-04, Val Loss: 4.2177e-04, LR: 2.5000e-05, Time: 75.65s
2025-06-21 19:21:28,269 - Epoch 27, Train Loss: 1.2797e-04, Val Loss: 5.7491e-04, LR: 2.5000e-05, Time: 75.68s
2025-06-21 19:22:44,183 - Epoch 28, Train Loss: 1.1275e-04, Val Loss: 6.5942e-04, LR: 1.2500e-05, Time: 75.87s
2025-06-21 19:23:59,932 - Epoch 29, Train Loss: 9.8165e-05, Val Loss: 7.3816e-04, LR: 1.2500e-05, Time: 75.71s
2025-06-21 19:25:15,411 - Epoch 30, Train Loss: 9.2717e-05, Val Loss: 8.4293e-04, LR: 1.2500e-05, Time: 75.41s
2025-06-21 19:25:15,434 - Early stopping at epoch 30
2025-06-21 19:25:16,935 - [task0] Training completed.
2025-06-21 19:25:16,937 - [task0] Consolidating EWC...
2025-06-21 19:26:21,441 - [task0] Consolidation done.
2025-06-21 19:26:21,443 - [task0] Baseline evaluation on own task task0 ...
2025-06-21 19:26:26,431 - [task0 Baseline on task0] RMSE: 5.2017e-02, MAE: 4.5087e-02
2025-06-21 19:26:26,433 - [task0] Baseline testing completed.
2025-06-21 19:26:26,434 - [task0] ACC (-MAE): -4.5087e-02
2025-06-21 19:26:26,436 - [task0] Evaluating BEST checkpoint...
2025-06-21 19:26:34,985 - [task0 FORWARD on test] RMSE: 9.3065e-02, MAE: 7.3973e-02, R2: -0.2235
2025-06-21 19:26:34,987 - [task0] Forward testing completed.
2025-06-21 19:26:34,989 - [task1] Loading best checkpoint from previous task task0...
2025-06-21 19:26:36,700 - [task1 Pre-FWT baseline] RMSE: 6.3995e-02, MAE: 5.4068e-02
2025-06-21 19:26:36,704 - [task1] Training...
2025-06-21 19:26:36,705 - [task1] Using ewc_lambda=0
2025-06-21 19:27:31,926 - Epoch 1, Train Loss: 2.4909e-03, Val Loss: 1.9268e-03, LR: 1.0000e-04, Time: 55.20s
2025-06-21 19:28:26,926 - Epoch 2, Train Loss: 1.6612e-03, Val Loss: 1.2146e-03, LR: 1.0000e-04, Time: 54.92s
2025-06-21 19:29:27,103 - Epoch 3, Train Loss: 1.2690e-03, Val Loss: 1.6242e-03, LR: 1.0000e-04, Time: 60.03s
2025-06-21 19:30:22,509 - Epoch 4, Train Loss: 9.9880e-04, Val Loss: 2.0012e-03, LR: 1.0000e-04, Time: 55.33s
2025-06-21 19:31:18,497 - Epoch 5, Train Loss: 9.5317e-04, Val Loss: 2.2539e-03, LR: 1.0000e-04, Time: 55.87s
2025-06-21 19:32:13,683 - Epoch 6, Train Loss: 9.5487e-04, Val Loss: 2.0564e-03, LR: 1.0000e-04, Time: 55.15s
2025-06-21 19:33:08,896 - Epoch 7, Train Loss: 8.1234e-04, Val Loss: 2.3569e-03, LR: 1.0000e-04, Time: 55.18s
2025-06-21 19:34:04,163 - Epoch 8, Train Loss: 9.0409e-04, Val Loss: 4.2960e-03, LR: 5.0000e-05, Time: 55.23s
2025-06-21 19:34:59,505 - Epoch 9, Train Loss: 6.3108e-04, Val Loss: 4.2201e-03, LR: 5.0000e-05, Time: 55.31s
2025-06-21 19:35:54,777 - Epoch 10, Train Loss: 5.5108e-04, Val Loss: 3.7739e-03, LR: 5.0000e-05, Time: 55.24s
2025-06-21 19:36:50,408 - Epoch 11, Train Loss: 5.6436e-04, Val Loss: 3.3782e-03, LR: 5.0000e-05, Time: 55.57s
2025-06-21 19:37:45,711 - Epoch 12, Train Loss: 5.0591e-04, Val Loss: 3.6997e-03, LR: 5.0000e-05, Time: 55.24s
2025-06-21 19:38:41,142 - Epoch 13, Train Loss: 5.2796e-04, Val Loss: 3.1144e-03, LR: 5.0000e-05, Time: 55.39s
2025-06-21 19:39:36,618 - Epoch 14, Train Loss: 5.2079e-04, Val Loss: 2.7545e-03, LR: 2.5000e-05, Time: 55.38s
2025-06-21 19:40:32,232 - Epoch 15, Train Loss: 4.9627e-04, Val Loss: 4.2656e-03, LR: 2.5000e-05, Time: 55.55s
2025-06-21 19:41:27,443 - Epoch 16, Train Loss: 4.4244e-04, Val Loss: 5.0071e-03, LR: 2.5000e-05, Time: 55.17s
2025-06-21 19:42:22,774 - Epoch 17, Train Loss: 4.1665e-04, Val Loss: 4.6773e-03, LR: 2.5000e-05, Time: 55.30s
2025-06-21 19:43:18,095 - Epoch 18, Train Loss: 3.8471e-04, Val Loss: 4.9828e-03, LR: 2.5000e-05, Time: 55.26s
2025-06-21 19:44:13,184 - Epoch 19, Train Loss: 3.7082e-04, Val Loss: 3.9002e-03, LR: 2.5000e-05, Time: 55.06s
2025-06-21 19:45:08,605 - Epoch 20, Train Loss: 3.8611e-04, Val Loss: 3.5406e-03, LR: 1.2500e-05, Time: 55.38s
2025-06-21 19:46:03,740 - Epoch 21, Train Loss: 3.1897e-04, Val Loss: 3.9152e-03, LR: 1.2500e-05, Time: 55.06s
2025-06-21 19:46:58,804 - Epoch 22, Train Loss: 3.0544e-04, Val Loss: 4.1454e-03, LR: 1.2500e-05, Time: 55.01s
2025-06-21 19:46:58,878 - Early stopping at epoch 22
2025-06-21 19:46:59,575 - [task1] Training completed.
2025-06-21 19:46:59,577 - [task1] Consolidating EWC...
2025-06-21 19:47:45,561 - [task1] Consolidation done.
2025-06-21 19:47:45,563 - [task1] Baseline evaluation on own task task1 ...
2025-06-21 19:47:49,421 - [task1 Baseline on task1] RMSE: 8.8217e-02, MAE: 8.5339e-02
2025-06-21 19:47:49,422 - [task1] Baseline testing completed.
2025-06-21 19:47:49,425 - [task1] Backward testing on previous task task0...
2025-06-21 19:47:54,438 - [task1 BACKWARD on task0] RMSE: 2.5044e-02, MAE: 2.1561e-02
2025-06-21 19:47:54,440 - [task1] ΔMAE on task0: -2.3526e-02
2025-06-21 19:47:54,441 - [task1] ACC (-MAE): -5.3450e-02
2025-06-21 19:47:54,442 - [task1] BWT: -2.3526e-02
2025-06-21 19:47:54,444 - [task1] FWT: -3.1271e-02
2025-06-21 19:47:54,446 - [task1] Evaluating BEST checkpoint...
2025-06-21 19:48:02,727 - [task1 FORWARD on test] RMSE: 8.8820e-02, MAE: 6.9540e-02, R2: -0.1144
2025-06-21 19:48:02,728 - [task1] Forward testing completed.
2025-06-21 19:48:02,730 - [task2] Loading best checkpoint from previous task task1...
2025-06-21 19:48:04,327 - [task2 Pre-FWT baseline] RMSE: 1.5207e-01, MAE: 1.4968e-01
2025-06-21 19:48:04,330 - [task2] Training...
2025-06-21 19:48:04,331 - [task2] Using ewc_lambda=0
2025-06-21 19:48:41,646 - Epoch 1, Train Loss: 2.9461e-03, Val Loss: 6.0450e-03, LR: 1.0000e-04, Time: 37.31s
2025-06-21 19:49:18,799 - Epoch 2, Train Loss: 2.0981e-03, Val Loss: 2.9665e-03, LR: 1.0000e-04, Time: 37.06s
2025-06-21 19:49:56,131 - Epoch 3, Train Loss: 1.9920e-03, Val Loss: 2.0139e-03, LR: 1.0000e-04, Time: 37.23s
2025-06-21 19:50:33,306 - Epoch 4, Train Loss: 1.8803e-03, Val Loss: 2.7409e-03, LR: 1.0000e-04, Time: 37.06s
2025-06-21 19:51:10,736 - Epoch 5, Train Loss: 1.7031e-03, Val Loss: 4.3372e-03, LR: 1.0000e-04, Time: 37.37s
2025-06-21 19:51:47,939 - Epoch 6, Train Loss: 1.7677e-03, Val Loss: 1.6083e-03, LR: 1.0000e-04, Time: 37.14s
2025-06-21 19:52:25,367 - Epoch 7, Train Loss: 1.5246e-03, Val Loss: 1.5601e-03, LR: 1.0000e-04, Time: 37.29s
2025-06-21 19:53:02,723 - Epoch 8, Train Loss: 1.5989e-03, Val Loss: 1.8546e-03, LR: 1.0000e-04, Time: 37.21s
2025-06-21 19:53:39,809 - Epoch 9, Train Loss: 1.5079e-03, Val Loss: 1.3675e-03, LR: 1.0000e-04, Time: 37.04s
2025-06-21 19:54:17,015 - Epoch 10, Train Loss: 1.0627e-03, Val Loss: 1.0108e-03, LR: 1.0000e-04, Time: 37.08s
2025-06-21 19:54:54,192 - Epoch 11, Train Loss: 1.2406e-03, Val Loss: 1.5694e-03, LR: 1.0000e-04, Time: 37.04s
2025-06-21 19:55:31,471 - Epoch 12, Train Loss: 1.2841e-03, Val Loss: 1.6027e-03, LR: 1.0000e-04, Time: 37.17s
2025-06-21 19:56:09,912 - Epoch 13, Train Loss: 1.2290e-03, Val Loss: 1.1581e-03, LR: 1.0000e-04, Time: 38.37s
2025-06-21 19:56:48,131 - Epoch 14, Train Loss: 1.1784e-03, Val Loss: 1.0233e-03, LR: 1.0000e-04, Time: 38.16s
2025-06-21 19:57:25,245 - Epoch 15, Train Loss: 1.0729e-03, Val Loss: 9.7525e-04, LR: 1.0000e-04, Time: 37.05s
2025-06-21 19:58:02,564 - Epoch 16, Train Loss: 1.2003e-03, Val Loss: 1.6428e-03, LR: 1.0000e-04, Time: 37.18s
2025-06-21 19:58:39,676 - Epoch 17, Train Loss: 1.1809e-03, Val Loss: 1.3892e-03, LR: 1.0000e-04, Time: 37.06s
2025-06-21 19:59:16,826 - Epoch 18, Train Loss: 1.0222e-03, Val Loss: 9.3990e-04, LR: 1.0000e-04, Time: 37.10s
2025-06-21 19:59:53,975 - Epoch 19, Train Loss: 9.8307e-04, Val Loss: 1.5835e-03, LR: 1.0000e-04, Time: 37.06s
2025-06-21 20:00:31,359 - Epoch 20, Train Loss: 1.1921e-03, Val Loss: 1.4393e-03, LR: 1.0000e-04, Time: 37.33s
2025-06-21 20:01:08,502 - Epoch 21, Train Loss: 9.2777e-04, Val Loss: 1.0922e-03, LR: 1.0000e-04, Time: 37.07s
2025-06-21 20:01:45,718 - Epoch 22, Train Loss: 9.7027e-04, Val Loss: 1.7906e-03, LR: 1.0000e-04, Time: 37.15s
2025-06-21 20:02:22,883 - Epoch 23, Train Loss: 1.0874e-03, Val Loss: 1.3453e-03, LR: 1.0000e-04, Time: 37.12s
2025-06-21 20:03:00,390 - Epoch 24, Train Loss: 9.2333e-04, Val Loss: 1.4965e-03, LR: 5.0000e-05, Time: 37.46s
2025-06-21 20:03:37,745 - Epoch 25, Train Loss: 7.5742e-04, Val Loss: 1.1480e-03, LR: 5.0000e-05, Time: 37.30s
2025-06-21 20:04:14,992 - Epoch 26, Train Loss: 7.3573e-04, Val Loss: 9.2793e-04, LR: 5.0000e-05, Time: 37.15s
2025-06-21 20:04:52,472 - Epoch 27, Train Loss: 7.1181e-04, Val Loss: 1.2028e-03, LR: 5.0000e-05, Time: 37.36s
2025-06-21 20:05:33,431 - Epoch 28, Train Loss: 6.9868e-04, Val Loss: 8.4901e-04, LR: 5.0000e-05, Time: 40.91s
2025-06-21 20:06:17,919 - Epoch 29, Train Loss: 6.9056e-04, Val Loss: 9.7843e-04, LR: 5.0000e-05, Time: 44.23s
2025-06-21 20:06:58,609 - Epoch 30, Train Loss: 6.7641e-04, Val Loss: 7.9284e-04, LR: 5.0000e-05, Time: 40.64s
2025-06-21 20:07:39,680 - Epoch 31, Train Loss: 6.5992e-04, Val Loss: 9.2601e-04, LR: 5.0000e-05, Time: 40.99s
2025-06-21 20:08:17,881 - Epoch 32, Train Loss: 6.4868e-04, Val Loss: 9.9773e-04, LR: 5.0000e-05, Time: 37.08s
2025-06-21 20:08:57,355 - Epoch 33, Train Loss: 6.6042e-04, Val Loss: 8.6586e-04, LR: 5.0000e-05, Time: 39.42s
2025-06-21 20:09:34,589 - Epoch 34, Train Loss: 6.0866e-04, Val Loss: 8.5803e-04, LR: 5.0000e-05, Time: 37.19s
2025-06-21 20:10:11,816 - Epoch 35, Train Loss: 6.1500e-04, Val Loss: 8.6922e-04, LR: 5.0000e-05, Time: 37.16s
2025-06-21 20:10:49,274 - Epoch 36, Train Loss: 6.0635e-04, Val Loss: 7.6138e-04, LR: 5.0000e-05, Time: 37.39s
2025-06-21 20:11:26,902 - Epoch 37, Train Loss: 5.8138e-04, Val Loss: 8.2109e-04, LR: 5.0000e-05, Time: 37.52s
2025-06-21 20:12:04,306 - Epoch 38, Train Loss: 5.8175e-04, Val Loss: 1.0991e-03, LR: 5.0000e-05, Time: 37.35s
2025-06-21 20:12:41,444 - Epoch 39, Train Loss: 5.3544e-04, Val Loss: 8.4108e-04, LR: 5.0000e-05, Time: 37.09s
2025-06-21 20:13:18,709 - Epoch 40, Train Loss: 5.2786e-04, Val Loss: 7.5534e-04, LR: 5.0000e-05, Time: 37.22s
2025-06-21 20:13:56,139 - Epoch 41, Train Loss: 5.5924e-04, Val Loss: 7.3340e-04, LR: 5.0000e-05, Time: 37.32s
2025-06-21 20:14:33,411 - Epoch 42, Train Loss: 5.1181e-04, Val Loss: 9.5783e-04, LR: 5.0000e-05, Time: 37.19s
2025-06-21 20:15:10,580 - Epoch 43, Train Loss: 5.0089e-04, Val Loss: 6.6804e-04, LR: 5.0000e-05, Time: 37.13s
2025-06-21 20:15:47,764 - Epoch 44, Train Loss: 4.9307e-04, Val Loss: 6.9918e-04, LR: 5.0000e-05, Time: 37.03s
2025-06-21 20:16:24,952 - Epoch 45, Train Loss: 4.7105e-04, Val Loss: 8.2850e-04, LR: 5.0000e-05, Time: 37.12s
2025-06-21 20:17:02,130 - Epoch 46, Train Loss: 4.7702e-04, Val Loss: 1.2903e-03, LR: 5.0000e-05, Time: 37.13s
2025-06-21 20:17:39,247 - Epoch 47, Train Loss: 4.7702e-04, Val Loss: 7.2965e-04, LR: 5.0000e-05, Time: 37.07s
2025-06-21 20:18:16,321 - Epoch 48, Train Loss: 4.6564e-04, Val Loss: 7.7535e-04, LR: 5.0000e-05, Time: 37.03s
2025-06-21 20:18:53,602 - Epoch 49, Train Loss: 4.2668e-04, Val Loss: 6.9136e-04, LR: 2.5000e-05, Time: 37.23s
2025-06-21 20:19:30,731 - Epoch 50, Train Loss: 3.8894e-04, Val Loss: 6.6880e-04, LR: 2.5000e-05, Time: 37.08s
2025-06-21 20:20:07,825 - Epoch 51, Train Loss: 3.3438e-04, Val Loss: 6.0474e-04, LR: 2.5000e-05, Time: 37.04s
2025-06-21 20:20:45,006 - Epoch 52, Train Loss: 2.9634e-04, Val Loss: 4.9321e-04, LR: 2.5000e-05, Time: 37.08s
2025-06-21 20:21:22,196 - Epoch 53, Train Loss: 2.8278e-04, Val Loss: 4.4778e-04, LR: 2.5000e-05, Time: 37.04s
2025-06-21 20:21:59,360 - Epoch 54, Train Loss: 2.7595e-04, Val Loss: 5.2682e-04, LR: 2.5000e-05, Time: 37.07s
2025-06-21 20:22:36,741 - Epoch 55, Train Loss: 2.7948e-04, Val Loss: 4.9475e-04, LR: 2.5000e-05, Time: 37.33s
2025-06-21 20:23:13,875 - Epoch 56, Train Loss: 2.7336e-04, Val Loss: 4.9336e-04, LR: 2.5000e-05, Time: 37.09s
2025-06-21 20:23:51,052 - Epoch 57, Train Loss: 2.6935e-04, Val Loss: 4.7112e-04, LR: 2.5000e-05, Time: 37.13s
2025-06-21 20:24:28,333 - Epoch 58, Train Loss: 2.5694e-04, Val Loss: 5.9423e-04, LR: 2.5000e-05, Time: 37.24s
2025-06-21 20:25:05,916 - Epoch 59, Train Loss: 2.5597e-04, Val Loss: 4.0204e-04, LR: 2.5000e-05, Time: 37.52s
2025-06-21 20:25:43,183 - Epoch 60, Train Loss: 2.5711e-04, Val Loss: 5.3537e-04, LR: 2.5000e-05, Time: 37.15s
2025-06-21 20:26:20,464 - Epoch 61, Train Loss: 2.4420e-04, Val Loss: 3.9435e-04, LR: 2.5000e-05, Time: 37.24s
2025-06-21 20:26:57,720 - Epoch 62, Train Loss: 2.4855e-04, Val Loss: 4.4444e-04, LR: 2.5000e-05, Time: 37.17s
2025-06-21 20:27:34,952 - Epoch 63, Train Loss: 2.4819e-04, Val Loss: 4.2974e-04, LR: 2.5000e-05, Time: 37.19s
2025-06-21 20:28:12,116 - Epoch 64, Train Loss: 2.4764e-04, Val Loss: 4.2320e-04, LR: 2.5000e-05, Time: 37.12s
2025-06-21 20:28:49,274 - Epoch 65, Train Loss: 2.4170e-04, Val Loss: 4.4794e-04, LR: 2.5000e-05, Time: 37.11s
2025-06-21 20:29:26,511 - Epoch 66, Train Loss: 2.4110e-04, Val Loss: 4.3634e-04, LR: 2.5000e-05, Time: 37.19s
2025-06-21 20:30:03,723 - Epoch 67, Train Loss: 2.3524e-04, Val Loss: 4.5773e-04, LR: 1.2500e-05, Time: 37.16s
2025-06-21 20:30:40,870 - Epoch 68, Train Loss: 2.2051e-04, Val Loss: 4.8519e-04, LR: 1.2500e-05, Time: 37.09s
2025-06-21 20:31:18,106 - Epoch 69, Train Loss: 2.1772e-04, Val Loss: 4.5944e-04, LR: 1.2500e-05, Time: 37.19s
2025-06-21 20:31:55,407 - Epoch 70, Train Loss: 2.1595e-04, Val Loss: 4.3373e-04, LR: 1.2500e-05, Time: 37.24s
2025-06-21 20:32:32,851 - Epoch 71, Train Loss: 2.0978e-04, Val Loss: 4.3405e-04, LR: 1.2500e-05, Time: 37.39s
2025-06-21 20:33:10,210 - Epoch 72, Train Loss: 2.1259e-04, Val Loss: 3.9131e-04, LR: 1.2500e-05, Time: 37.31s
2025-06-21 20:33:47,475 - Epoch 73, Train Loss: 2.1388e-04, Val Loss: 4.4978e-04, LR: 1.2500e-05, Time: 37.13s
2025-06-21 20:34:24,754 - Epoch 74, Train Loss: 2.0859e-04, Val Loss: 4.2310e-04, LR: 1.2500e-05, Time: 37.23s
2025-06-21 20:35:01,923 - Epoch 75, Train Loss: 2.1038e-04, Val Loss: 4.4428e-04, LR: 1.2500e-05, Time: 37.13s
2025-06-21 20:35:39,083 - Epoch 76, Train Loss: 2.0843e-04, Val Loss: 4.2445e-04, LR: 1.2500e-05, Time: 37.11s
2025-06-21 20:36:16,263 - Epoch 77, Train Loss: 2.0721e-04, Val Loss: 4.2289e-04, LR: 1.2500e-05, Time: 37.12s
2025-06-21 20:36:53,421 - Epoch 78, Train Loss: 2.0698e-04, Val Loss: 4.6026e-04, LR: 6.2500e-06, Time: 37.11s
2025-06-21 20:37:30,842 - Epoch 79, Train Loss: 2.0033e-04, Val Loss: 4.6676e-04, LR: 6.2500e-06, Time: 37.31s
2025-06-21 20:38:08,014 - Epoch 80, Train Loss: 1.9995e-04, Val Loss: 4.5419e-04, LR: 6.2500e-06, Time: 37.13s
2025-06-21 20:38:45,173 - Epoch 81, Train Loss: 2.0110e-04, Val Loss: 4.2501e-04, LR: 6.2500e-06, Time: 37.11s
2025-06-21 20:39:22,411 - Epoch 82, Train Loss: 1.9798e-04, Val Loss: 4.5662e-04, LR: 6.2500e-06, Time: 37.19s
2025-06-21 20:39:59,803 - Epoch 83, Train Loss: 1.9921e-04, Val Loss: 4.3675e-04, LR: 6.2500e-06, Time: 37.28s
2025-06-21 20:40:37,101 - Epoch 84, Train Loss: 1.9539e-04, Val Loss: 4.1475e-04, LR: 3.1250e-06, Time: 37.25s
2025-06-21 20:41:14,482 - Epoch 85, Train Loss: 1.9477e-04, Val Loss: 4.4216e-04, LR: 3.1250e-06, Time: 37.29s
2025-06-21 20:41:51,714 - Epoch 86, Train Loss: 1.9379e-04, Val Loss: 4.5678e-04, LR: 3.1250e-06, Time: 37.15s
2025-06-21 20:42:28,928 - Epoch 87, Train Loss: 1.9376e-04, Val Loss: 4.2379e-04, LR: 3.1250e-06, Time: 37.17s
2025-06-21 20:43:06,169 - Epoch 88, Train Loss: 1.9503e-04, Val Loss: 4.2701e-04, LR: 3.1250e-06, Time: 37.19s
2025-06-21 20:43:43,334 - Epoch 89, Train Loss: 1.9358e-04, Val Loss: 4.1445e-04, LR: 3.1250e-06, Time: 37.12s
2025-06-21 20:44:20,543 - Epoch 90, Train Loss: 1.9386e-04, Val Loss: 4.3633e-04, LR: 1.5625e-06, Time: 37.15s
2025-06-21 20:44:57,873 - Epoch 91, Train Loss: 1.9286e-04, Val Loss: 4.2272e-04, LR: 1.5625e-06, Time: 37.29s
2025-06-21 20:45:35,446 - Epoch 92, Train Loss: 1.8962e-04, Val Loss: 4.4266e-04, LR: 1.5625e-06, Time: 37.53s
2025-06-21 20:45:35,490 - Early stopping at epoch 92
2025-06-21 20:45:35,946 - [task2] Training completed.
2025-06-21 20:45:35,949 - [task2] Consolidating EWC...
2025-06-21 20:46:09,460 - [task2] Consolidation done.
2025-06-21 20:46:09,488 - [task2] Baseline evaluation on own task task2 ...
2025-06-21 20:46:13,176 - [task2 Baseline on task2] RMSE: 6.8193e-02, MAE: 5.5711e-02
2025-06-21 20:46:13,178 - [task2] Baseline testing completed.
2025-06-21 20:46:13,182 - [task2] Backward testing on previous task task0...
2025-06-21 20:46:22,378 - [task2 BACKWARD on task0] RMSE: 9.0041e-02, MAE: 6.7605e-02
2025-06-21 20:46:22,381 - [task2] Backward testing on previous task task1...
2025-06-21 20:46:26,393 - [task2 BACKWARD on task1] RMSE: 3.2220e-02, MAE: 2.7566e-02
2025-06-21 20:46:26,395 - [task2] ΔMAE on task0: +2.2517e-02
2025-06-21 20:46:26,396 - [task2] ΔMAE on task1: -5.7773e-02
2025-06-21 20:46:26,398 - [task2] ACC (-MAE): -5.0294e-02
2025-06-21 20:46:26,399 - [task2] BWT: -1.7628e-02
2025-06-21 20:46:26,400 - [task2] FWT: +9.3969e-02
2025-06-21 20:46:26,402 - [task2] Evaluating BEST checkpoint...
2025-06-21 20:46:34,922 - [task2 FORWARD on test] RMSE: 7.2245e-02, MAE: 5.2929e-02, R2: 0.2627
2025-06-21 20:46:34,924 - [task2] Forward testing completed.
2025-06-21 20:46:34,935 - Saved ACC/BWT/FWT history to /beegfs/home/users/z/zzhuqshun/Thesis/04_NNs/model/naive_fine_tuning/incremental/continual_metrics.csv
2025-06-21 20:46:35,582 - ==== All tasks completed ====
