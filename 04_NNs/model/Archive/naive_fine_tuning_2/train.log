2025-06-21 12:30:56,341 - ==== Regular LSTM Training Phase ====
2025-06-21 12:31:56,658 - Base train IDs: ['03', '05', '07', '09', '11', '15', '21', '23', '25', '27', '29']
2025-06-21 12:31:56,658 - Base train size: 205644
2025-06-21 12:31:56,658 - Base val IDs: ['01', '19', '13']
2025-06-21 12:31:56,658 - Base val size: 58177
2025-06-21 12:31:56,658 - Update1 train IDs: []
2025-06-21 12:31:56,658 - Update1 train size: 0
2025-06-21 12:31:56,658 - Update1 val IDs: []
2025-06-21 12:31:56,658 - Update1 val size: 0
2025-06-21 12:31:56,658 - Update2 train IDs: []
2025-06-21 12:31:56,658 - Update2 train size: 0
2025-06-21 12:31:56,658 - Update2 val IDs: []
2025-06-21 12:31:56,658 - Update2 val size: 0
2025-06-21 12:32:01,594 - Test cell ID: 17
2025-06-21 12:32:01,594 - Test size: 22872
2025-06-21 12:32:01,594 - Test base size: 11139
2025-06-21 12:32:01,594 - Test update1 size: 6312
2025-06-21 12:32:01,594 - Test update2 size: 5421
2025-06-21 12:32:01,715 - [Scaler after fit] center_=[ 3.342422    0.17992967 27.75      ]
2025-06-21 12:32:01,731 - [Scaler after fit] scale_ =[0.18428363 1.77955483 1.81783333]
2025-06-21 12:32:01,731 - Resampling and scaling complete with RobustScaler
2025-06-21 12:36:09,351 - Epoch 1, Train Loss: 2.2571e-02, Val Loss: 1.8462e-03, LR: 1.0000e-04, Time: 242.70s
2025-06-21 12:41:29,594 - Epoch 2, Train Loss: 6.4996e-03, Val Loss: 1.5726e-03, LR: 1.0000e-04, Time: 320.15s
2025-06-21 12:46:45,834 - Epoch 3, Train Loss: 3.6553e-03, Val Loss: 1.0078e-03, LR: 1.0000e-04, Time: 316.05s
2025-06-21 12:51:22,418 - Epoch 4, Train Loss: 2.3249e-03, Val Loss: 6.6145e-04, LR: 1.0000e-04, Time: 276.54s
2025-06-21 12:55:25,801 - Epoch 5, Train Loss: 1.4081e-03, Val Loss: 7.0153e-04, LR: 1.0000e-04, Time: 243.34s
2025-06-21 12:59:32,805 - Epoch 6, Train Loss: 9.4946e-04, Val Loss: 1.2023e-03, LR: 1.0000e-04, Time: 246.99s
2025-06-21 13:03:38,473 - Epoch 7, Train Loss: 7.5365e-04, Val Loss: 7.5736e-04, LR: 1.0000e-04, Time: 245.64s
2025-06-21 13:07:41,531 - Epoch 8, Train Loss: 6.4309e-04, Val Loss: 5.9448e-04, LR: 1.0000e-04, Time: 243.03s
2025-06-21 13:11:49,887 - Epoch 9, Train Loss: 5.4966e-04, Val Loss: 5.4051e-04, LR: 1.0000e-04, Time: 248.29s
2025-06-21 13:15:51,247 - Epoch 10, Train Loss: 4.4609e-04, Val Loss: 6.0003e-04, LR: 1.0000e-04, Time: 241.26s
2025-06-21 13:19:59,162 - Epoch 11, Train Loss: 3.4440e-04, Val Loss: 4.5312e-04, LR: 1.0000e-04, Time: 247.90s
2025-06-21 13:24:06,384 - Epoch 12, Train Loss: 2.7255e-04, Val Loss: 3.3157e-04, LR: 1.0000e-04, Time: 247.19s
2025-06-21 13:28:13,631 - Epoch 13, Train Loss: 2.1906e-04, Val Loss: 1.8297e-04, LR: 1.0000e-04, Time: 247.19s
2025-06-21 13:32:50,336 - Epoch 14, Train Loss: 1.8130e-04, Val Loss: 1.1899e-04, LR: 1.0000e-04, Time: 276.62s
2025-06-21 13:36:56,875 - Epoch 15, Train Loss: 1.6510e-04, Val Loss: 1.9011e-04, LR: 1.0000e-04, Time: 246.48s
2025-06-21 13:40:55,602 - Epoch 16, Train Loss: 1.5215e-04, Val Loss: 1.6548e-04, LR: 1.0000e-04, Time: 238.71s
2025-06-21 13:44:54,641 - Epoch 17, Train Loss: 1.4120e-04, Val Loss: 1.6469e-04, LR: 1.0000e-04, Time: 239.02s
2025-06-21 13:48:52,866 - Epoch 18, Train Loss: 1.3561e-04, Val Loss: 1.2219e-04, LR: 1.0000e-04, Time: 238.19s
2025-06-21 13:52:49,187 - Epoch 19, Train Loss: 1.4098e-04, Val Loss: 1.2010e-04, LR: 1.0000e-04, Time: 236.31s
2025-06-21 13:56:46,766 - Epoch 20, Train Loss: 1.2716e-04, Val Loss: 1.2844e-04, LR: 5.0000e-05, Time: 237.56s
2025-06-21 14:00:44,289 - Epoch 21, Train Loss: 1.0942e-04, Val Loss: 1.2907e-04, LR: 5.0000e-05, Time: 237.51s
2025-06-21 14:04:41,261 - Epoch 22, Train Loss: 1.0682e-04, Val Loss: 1.5118e-04, LR: 5.0000e-05, Time: 236.96s
2025-06-21 14:08:37,726 - Epoch 23, Train Loss: 1.0248e-04, Val Loss: 1.6228e-04, LR: 5.0000e-05, Time: 236.45s
2025-06-21 14:12:34,563 - Epoch 24, Train Loss: 1.0241e-04, Val Loss: 1.3230e-04, LR: 5.0000e-05, Time: 236.82s
2025-06-21 14:16:31,587 - Epoch 25, Train Loss: 1.0152e-04, Val Loss: 1.4869e-04, LR: 5.0000e-05, Time: 237.01s
2025-06-21 14:20:31,814 - Epoch 26, Train Loss: 9.9916e-05, Val Loss: 1.4557e-04, LR: 2.5000e-05, Time: 240.21s
2025-06-21 14:24:28,736 - Epoch 27, Train Loss: 9.1271e-05, Val Loss: 1.7579e-04, LR: 2.5000e-05, Time: 236.91s
2025-06-21 14:28:25,267 - Epoch 28, Train Loss: 9.1030e-05, Val Loss: 1.4809e-04, LR: 2.5000e-05, Time: 236.51s
2025-06-21 14:32:21,993 - Epoch 29, Train Loss: 9.0009e-05, Val Loss: 1.4266e-04, LR: 2.5000e-05, Time: 236.71s
2025-06-21 14:36:20,468 - Epoch 30, Train Loss: 8.9270e-05, Val Loss: 1.6134e-04, LR: 2.5000e-05, Time: 238.46s
2025-06-21 14:40:17,660 - Epoch 31, Train Loss: 8.9029e-05, Val Loss: 1.6669e-04, LR: 2.5000e-05, Time: 237.18s
2025-06-21 14:44:16,530 - Epoch 32, Train Loss: 8.8500e-05, Val Loss: 1.6182e-04, LR: 1.2500e-05, Time: 238.87s
2025-06-21 14:48:13,946 - Epoch 33, Train Loss: 8.4343e-05, Val Loss: 1.5690e-04, LR: 1.2500e-05, Time: 237.40s
2025-06-21 14:52:12,095 - Epoch 34, Train Loss: 8.3282e-05, Val Loss: 1.5525e-04, LR: 1.2500e-05, Time: 238.13s
2025-06-21 14:52:12,111 - Early stopping at epoch 34
2025-06-21 14:52:24,505 - [Joint training best model predictions] RMSE: 1.5943e-02, MAE: 1.1633e-02, R2: 0.9641
2025-06-21 14:52:24,505 - ==== Incremental EWC Training Phase ====
2025-06-21 14:53:26,016 - Base train IDs: ['03', '05', '07', '27']
2025-06-21 14:53:26,016 - Base train size: 92079
2025-06-21 14:53:26,016 - Base val IDs: ['01']
2025-06-21 14:53:26,016 - Base val size: 28612
2025-06-21 14:53:26,016 - Update1 train IDs: ['21', '23', '25']
2025-06-21 14:53:26,016 - Update1 train size: 65674
2025-06-21 14:53:26,016 - Update1 val IDs: ['19']
2025-06-21 14:53:26,016 - Update1 val size: 23120
2025-06-21 14:53:26,016 - Update2 train IDs: ['09', '11', '15', '29']
2025-06-21 14:53:26,016 - Update2 train size: 47891
2025-06-21 14:53:26,016 - Update2 val IDs: ['13']
2025-06-21 14:53:26,016 - Update2 val size: 6445
2025-06-21 14:53:30,721 - Test cell ID: 17
2025-06-21 14:53:30,721 - Test size: 22872
2025-06-21 14:53:30,721 - Test base size: 11139
2025-06-21 14:53:30,721 - Test update1 size: 6312
2025-06-21 14:53:30,721 - Test update2 size: 5421
2025-06-21 14:53:30,848 - [Scaler after fit] center_=[ 3.31975183  0.         27.55116667]
2025-06-21 14:53:30,864 - [Scaler after fit] scale_ =[0.20016217 1.86108033 1.05333333]
2025-06-21 14:53:30,864 - Resampling and scaling complete with RobustScaler
2025-06-21 14:53:31,007 - [task0] Training...
2025-06-21 14:53:31,007 - [task0] Using ewc_lambda=0
2025-06-21 14:55:03,554 - Epoch 1, Train Loss: 2.5271e-02, Val Loss: 4.2301e-04, LR: 1.0000e-04, Time: 92.53s
2025-06-21 14:56:50,317 - Epoch 2, Train Loss: 5.9483e-03, Val Loss: 5.5062e-04, LR: 1.0000e-04, Time: 106.70s
2025-06-21 14:58:36,273 - Epoch 3, Train Loss: 4.2044e-03, Val Loss: 4.0463e-04, LR: 1.0000e-04, Time: 105.94s
2025-06-21 15:00:23,235 - Epoch 4, Train Loss: 3.2205e-03, Val Loss: 8.6426e-04, LR: 1.0000e-04, Time: 106.93s
2025-06-21 15:02:09,308 - Epoch 5, Train Loss: 2.5048e-03, Val Loss: 4.0464e-04, LR: 1.0000e-04, Time: 106.06s
2025-06-21 15:03:55,463 - Epoch 6, Train Loss: 1.9047e-03, Val Loss: 3.9692e-04, LR: 1.0000e-04, Time: 106.14s
2025-06-21 15:05:42,303 - Epoch 7, Train Loss: 1.4357e-03, Val Loss: 4.2171e-04, LR: 1.0000e-04, Time: 106.81s
2025-06-21 15:07:28,756 - Epoch 8, Train Loss: 1.0837e-03, Val Loss: 4.0485e-04, LR: 1.0000e-04, Time: 106.44s
2025-06-21 15:09:14,625 - Epoch 9, Train Loss: 8.3309e-04, Val Loss: 4.2635e-04, LR: 1.0000e-04, Time: 105.85s
2025-06-21 15:11:01,305 - Epoch 10, Train Loss: 6.6162e-04, Val Loss: 4.1430e-04, LR: 1.0000e-04, Time: 106.68s
2025-06-21 15:12:47,548 - Epoch 11, Train Loss: 5.6013e-04, Val Loss: 4.2218e-04, LR: 1.0000e-04, Time: 106.23s
2025-06-21 15:14:33,854 - Epoch 12, Train Loss: 5.0534e-04, Val Loss: 4.2213e-04, LR: 5.0000e-05, Time: 106.31s
2025-06-21 15:16:19,342 - Epoch 13, Train Loss: 4.7761e-04, Val Loss: 3.9866e-04, LR: 5.0000e-05, Time: 105.47s
2025-06-21 15:18:05,992 - Epoch 14, Train Loss: 4.6276e-04, Val Loss: 4.4840e-04, LR: 5.0000e-05, Time: 106.64s
2025-06-21 15:19:55,929 - Epoch 15, Train Loss: 4.3777e-04, Val Loss: 5.0329e-04, LR: 5.0000e-05, Time: 109.89s
2025-06-21 15:21:47,031 - Epoch 16, Train Loss: 3.8355e-04, Val Loss: 4.3865e-04, LR: 5.0000e-05, Time: 111.09s
2025-06-21 15:23:38,315 - Epoch 17, Train Loss: 3.3721e-04, Val Loss: 6.3843e-04, LR: 5.0000e-05, Time: 111.27s
2025-06-21 15:25:30,735 - Epoch 18, Train Loss: 3.3828e-04, Val Loss: 7.1899e-04, LR: 2.5000e-05, Time: 112.40s
2025-06-21 15:27:25,552 - Epoch 19, Train Loss: 2.5932e-04, Val Loss: 5.9387e-04, LR: 2.5000e-05, Time: 114.78s
2025-06-21 15:29:16,435 - Epoch 20, Train Loss: 2.3893e-04, Val Loss: 6.2671e-04, LR: 2.5000e-05, Time: 110.85s
2025-06-21 15:31:03,708 - Epoch 21, Train Loss: 2.4115e-04, Val Loss: 6.1156e-04, LR: 2.5000e-05, Time: 107.26s
2025-06-21 15:32:50,859 - Epoch 22, Train Loss: 2.2298e-04, Val Loss: 7.0063e-04, LR: 2.5000e-05, Time: 107.14s
2025-06-21 15:34:38,082 - Epoch 23, Train Loss: 2.2991e-04, Val Loss: 4.5485e-04, LR: 2.5000e-05, Time: 107.21s
2025-06-21 15:36:24,569 - Epoch 24, Train Loss: 2.1821e-04, Val Loss: 5.3074e-04, LR: 1.2500e-05, Time: 106.47s
2025-06-21 15:38:13,343 - Epoch 25, Train Loss: 2.0372e-04, Val Loss: 6.9789e-04, LR: 1.2500e-05, Time: 108.76s
2025-06-21 15:40:01,036 - Epoch 26, Train Loss: 2.0176e-04, Val Loss: 6.5710e-04, LR: 1.2500e-05, Time: 107.68s
2025-06-21 15:40:01,059 - Early stopping at epoch 26
2025-06-21 15:40:01,764 - [task0] Training completed.
2025-06-21 15:40:01,764 - [task0] Consolidating EWC...
2025-06-21 15:41:32,585 - [task0] Consolidation done.
2025-06-21 15:41:32,585 - [task0] Baseline evaluation on own task task0 ...
2025-06-21 15:41:38,648 - [task0 Baseline on task0] RMSE: 5.0867e-02, MAE: 4.3939e-02
2025-06-21 15:41:38,648 - [task0] Baseline testing completed.
2025-06-21 15:41:38,648 - [task0] ACC (-MAE): -4.3939e-02
2025-06-21 15:41:38,648 - [task0] Evaluating BEST checkpoint...
2025-06-21 15:41:49,594 - [task0 FORWARD on test] RMSE: 9.3715e-02, MAE: 7.4205e-02, R2: -0.2406
2025-06-21 15:41:49,598 - [task0] Forward testing completed.
2025-06-21 15:41:49,598 - [task1] Loading best checkpoint from previous task task0...
2025-06-21 15:41:52,248 - [task1 Pre-FWT baseline] RMSE: 6.5445e-02, MAE: 5.5583e-02
2025-06-21 15:41:52,248 - [task1] Training...
2025-06-21 15:41:52,248 - [task1] Using ewc_lambda=0
2025-06-21 15:43:10,392 - Epoch 1, Train Loss: 3.0794e-03, Val Loss: 2.5559e-03, LR: 1.0000e-04, Time: 78.14s
2025-06-21 15:44:28,222 - Epoch 2, Train Loss: 2.2969e-03, Val Loss: 2.8098e-03, LR: 1.0000e-04, Time: 77.77s
2025-06-21 15:45:46,068 - Epoch 3, Train Loss: 1.7491e-03, Val Loss: 1.8206e-03, LR: 1.0000e-04, Time: 77.81s
2025-06-21 15:47:04,280 - Epoch 4, Train Loss: 1.4581e-03, Val Loss: 1.6951e-03, LR: 1.0000e-04, Time: 78.16s
2025-06-21 15:48:22,153 - Epoch 5, Train Loss: 1.2085e-03, Val Loss: 1.0164e-03, LR: 1.0000e-04, Time: 77.81s
2025-06-21 15:49:39,857 - Epoch 6, Train Loss: 1.5213e-03, Val Loss: 2.1055e-03, LR: 1.0000e-04, Time: 77.67s
2025-06-21 15:50:58,008 - Epoch 7, Train Loss: 1.0896e-03, Val Loss: 1.4094e-03, LR: 1.0000e-04, Time: 78.12s
2025-06-21 15:52:17,992 - Epoch 8, Train Loss: 7.6394e-04, Val Loss: 2.2670e-03, LR: 1.0000e-04, Time: 79.97s
2025-06-21 15:53:36,425 - Epoch 9, Train Loss: 7.5909e-04, Val Loss: 2.9597e-03, LR: 1.0000e-04, Time: 78.40s
2025-06-21 15:54:54,519 - Epoch 10, Train Loss: 6.8107e-04, Val Loss: 3.3159e-03, LR: 1.0000e-04, Time: 78.08s
2025-06-21 15:56:13,138 - Epoch 11, Train Loss: 6.6064e-04, Val Loss: 4.3547e-03, LR: 5.0000e-05, Time: 78.60s
2025-06-21 15:57:31,661 - Epoch 12, Train Loss: 5.6303e-04, Val Loss: 4.5300e-03, LR: 5.0000e-05, Time: 78.49s
2025-06-21 15:58:49,925 - Epoch 13, Train Loss: 4.9891e-04, Val Loss: 4.2677e-03, LR: 5.0000e-05, Time: 78.23s
2025-06-21 16:00:08,320 - Epoch 14, Train Loss: 4.6759e-04, Val Loss: 4.2085e-03, LR: 5.0000e-05, Time: 78.36s
2025-06-21 16:01:26,511 - Epoch 15, Train Loss: 4.3829e-04, Val Loss: 5.4459e-03, LR: 5.0000e-05, Time: 78.17s
2025-06-21 16:02:47,235 - Epoch 16, Train Loss: 4.0044e-04, Val Loss: 4.5475e-03, LR: 5.0000e-05, Time: 80.71s
2025-06-21 16:04:05,398 - Epoch 17, Train Loss: 3.5531e-04, Val Loss: 5.3910e-03, LR: 2.5000e-05, Time: 78.12s
2025-06-21 16:05:24,245 - Epoch 18, Train Loss: 3.0137e-04, Val Loss: 5.3230e-03, LR: 2.5000e-05, Time: 78.82s
2025-06-21 16:06:43,779 - Epoch 19, Train Loss: 2.7771e-04, Val Loss: 5.1298e-03, LR: 2.5000e-05, Time: 79.51s
2025-06-21 16:08:01,880 - Epoch 20, Train Loss: 2.5673e-04, Val Loss: 4.8051e-03, LR: 2.5000e-05, Time: 78.08s
2025-06-21 16:09:20,095 - Epoch 21, Train Loss: 2.4665e-04, Val Loss: 4.9347e-03, LR: 2.5000e-05, Time: 78.20s
2025-06-21 16:10:38,672 - Epoch 22, Train Loss: 2.4595e-04, Val Loss: 5.3087e-03, LR: 2.5000e-05, Time: 78.56s
2025-06-21 16:11:57,069 - Epoch 23, Train Loss: 2.2587e-04, Val Loss: 5.4663e-03, LR: 1.2500e-05, Time: 78.38s
2025-06-21 16:13:15,740 - Epoch 24, Train Loss: 2.0970e-04, Val Loss: 5.0769e-03, LR: 1.2500e-05, Time: 78.64s
2025-06-21 16:14:33,889 - Epoch 25, Train Loss: 2.1141e-04, Val Loss: 5.2119e-03, LR: 1.2500e-05, Time: 78.13s
2025-06-21 16:14:33,905 - Early stopping at epoch 25
2025-06-21 16:14:34,169 - [task1] Training completed.
2025-06-21 16:14:34,169 - [task1] Consolidating EWC...
2025-06-21 16:15:39,626 - [task1] Consolidation done.
2025-06-21 16:15:39,628 - [task1] Baseline evaluation on own task task1 ...
2025-06-21 16:15:42,934 - [task1 Baseline on task1] RMSE: 7.2680e-02, MAE: 6.9175e-02
2025-06-21 16:15:42,934 - [task1] Baseline testing completed.
2025-06-21 16:15:42,937 - [task1] Backward testing on previous task task0...
2025-06-21 16:15:48,252 - [task1 BACKWARD on task0] RMSE: 2.6210e-02, MAE: 2.1755e-02
2025-06-21 16:15:48,252 - [task1] ΔMAE on task0: -2.2184e-02
2025-06-21 16:15:48,252 - [task1] ACC (-MAE): -4.5465e-02
2025-06-21 16:15:48,252 - [task1] BWT: -2.2184e-02
2025-06-21 16:15:48,252 - [task1] FWT: -1.3592e-02
2025-06-21 16:15:48,252 - [task1] Evaluating BEST checkpoint...
2025-06-21 16:16:00,841 - [task1 FORWARD on test] RMSE: 7.6950e-02, MAE: 5.9155e-02, R2: 0.1636
2025-06-21 16:16:00,841 - [task1] Forward testing completed.
2025-06-21 16:16:00,841 - [task2] Loading best checkpoint from previous task task1...
2025-06-21 16:16:03,101 - [task2 Pre-FWT baseline] RMSE: 1.3737e-01, MAE: 1.3191e-01
2025-06-21 16:16:03,101 - [task2] Training...
2025-06-21 16:16:03,101 - [task2] Using ewc_lambda=0
2025-06-21 16:16:54,083 - Epoch 1, Train Loss: 2.9370e-03, Val Loss: 1.9731e-03, LR: 1.0000e-04, Time: 50.98s
2025-06-21 16:17:46,739 - Epoch 2, Train Loss: 1.6634e-03, Val Loss: 1.7490e-03, LR: 1.0000e-04, Time: 52.53s
2025-06-21 16:18:41,458 - Epoch 3, Train Loss: 1.5812e-03, Val Loss: 1.1137e-03, LR: 1.0000e-04, Time: 54.61s
2025-06-21 16:19:33,596 - Epoch 4, Train Loss: 1.2914e-03, Val Loss: 2.2322e-03, LR: 1.0000e-04, Time: 52.09s
2025-06-21 16:20:30,262 - Epoch 5, Train Loss: 1.4309e-03, Val Loss: 1.3669e-03, LR: 1.0000e-04, Time: 56.63s
2025-06-21 16:21:22,137 - Epoch 6, Train Loss: 1.1443e-03, Val Loss: 1.0942e-03, LR: 1.0000e-04, Time: 51.84s
2025-06-21 16:22:14,606 - Epoch 7, Train Loss: 1.0112e-03, Val Loss: 1.1272e-03, LR: 1.0000e-04, Time: 52.39s
2025-06-21 16:23:06,955 - Epoch 8, Train Loss: 1.1038e-03, Val Loss: 1.0309e-03, LR: 1.0000e-04, Time: 52.32s
2025-06-21 16:23:59,698 - Epoch 9, Train Loss: 9.6174e-04, Val Loss: 1.1727e-03, LR: 1.0000e-04, Time: 52.60s
2025-06-21 16:24:51,755 - Epoch 10, Train Loss: 1.0141e-03, Val Loss: 9.0511e-04, LR: 1.0000e-04, Time: 52.04s
2025-06-21 16:25:43,898 - Epoch 11, Train Loss: 7.9281e-04, Val Loss: 7.5795e-04, LR: 1.0000e-04, Time: 52.08s
2025-06-21 16:26:35,925 - Epoch 12, Train Loss: 7.8254e-04, Val Loss: 1.0785e-03, LR: 1.0000e-04, Time: 51.96s
2025-06-21 16:27:28,099 - Epoch 13, Train Loss: 7.2368e-04, Val Loss: 1.1449e-03, LR: 1.0000e-04, Time: 52.14s
2025-06-21 16:28:20,587 - Epoch 14, Train Loss: 7.0842e-04, Val Loss: 1.0649e-03, LR: 1.0000e-04, Time: 52.46s
2025-06-21 16:29:12,915 - Epoch 15, Train Loss: 7.0082e-04, Val Loss: 8.8728e-04, LR: 1.0000e-04, Time: 52.31s
2025-06-21 16:30:04,957 - Epoch 16, Train Loss: 5.9533e-04, Val Loss: 9.4199e-04, LR: 1.0000e-04, Time: 52.01s
2025-06-21 16:30:57,601 - Epoch 17, Train Loss: 6.7055e-04, Val Loss: 9.7567e-04, LR: 5.0000e-05, Time: 52.60s
2025-06-21 16:31:49,793 - Epoch 18, Train Loss: 5.1314e-04, Val Loss: 7.7208e-04, LR: 5.0000e-05, Time: 52.16s
2025-06-21 16:32:42,095 - Epoch 19, Train Loss: 4.8882e-04, Val Loss: 1.1693e-03, LR: 5.0000e-05, Time: 52.29s
2025-06-21 16:33:34,342 - Epoch 20, Train Loss: 4.6027e-04, Val Loss: 1.0247e-03, LR: 5.0000e-05, Time: 52.22s
2025-06-21 16:34:26,697 - Epoch 21, Train Loss: 5.0461e-04, Val Loss: 7.2545e-04, LR: 5.0000e-05, Time: 52.34s
2025-06-21 16:35:19,162 - Epoch 22, Train Loss: 5.5147e-04, Val Loss: 6.9529e-04, LR: 5.0000e-05, Time: 52.41s
2025-06-21 16:36:11,484 - Epoch 23, Train Loss: 4.3034e-04, Val Loss: 7.8555e-04, LR: 5.0000e-05, Time: 52.27s
2025-06-21 16:37:03,656 - Epoch 24, Train Loss: 4.2037e-04, Val Loss: 9.9844e-04, LR: 5.0000e-05, Time: 52.12s
2025-06-21 16:37:56,353 - Epoch 25, Train Loss: 4.3877e-04, Val Loss: 6.2619e-04, LR: 5.0000e-05, Time: 52.67s
2025-06-21 16:38:48,649 - Epoch 26, Train Loss: 3.8658e-04, Val Loss: 6.3044e-04, LR: 5.0000e-05, Time: 52.25s
2025-06-21 16:39:42,050 - Epoch 27, Train Loss: 3.5913e-04, Val Loss: 4.9294e-04, LR: 5.0000e-05, Time: 53.38s
2025-06-21 16:40:34,630 - Epoch 28, Train Loss: 3.6800e-04, Val Loss: 5.1995e-04, LR: 5.0000e-05, Time: 52.51s
2025-06-21 16:41:27,026 - Epoch 29, Train Loss: 3.5628e-04, Val Loss: 4.3485e-04, LR: 5.0000e-05, Time: 52.36s
2025-06-21 16:42:20,384 - Epoch 30, Train Loss: 3.6600e-04, Val Loss: 6.1843e-04, LR: 5.0000e-05, Time: 53.33s
2025-06-21 16:43:12,574 - Epoch 31, Train Loss: 3.3797e-04, Val Loss: 4.6611e-04, LR: 5.0000e-05, Time: 52.16s
2025-06-21 16:44:05,310 - Epoch 32, Train Loss: 3.2158e-04, Val Loss: 5.9344e-04, LR: 5.0000e-05, Time: 52.70s
2025-06-21 16:44:59,039 - Epoch 33, Train Loss: 3.4463e-04, Val Loss: 5.1808e-04, LR: 5.0000e-05, Time: 53.67s
2025-06-21 16:45:51,607 - Epoch 34, Train Loss: 3.2700e-04, Val Loss: 5.3421e-04, LR: 5.0000e-05, Time: 52.54s
2025-06-21 16:46:44,288 - Epoch 35, Train Loss: 3.2340e-04, Val Loss: 4.7962e-04, LR: 2.5000e-05, Time: 52.65s
2025-06-21 16:47:36,503 - Epoch 36, Train Loss: 2.8554e-04, Val Loss: 5.4422e-04, LR: 2.5000e-05, Time: 52.18s
2025-06-21 16:48:28,732 - Epoch 37, Train Loss: 2.9142e-04, Val Loss: 5.0930e-04, LR: 2.5000e-05, Time: 52.20s
2025-06-21 16:49:21,034 - Epoch 38, Train Loss: 2.8587e-04, Val Loss: 4.8402e-04, LR: 2.5000e-05, Time: 52.27s
2025-06-21 16:50:13,503 - Epoch 39, Train Loss: 2.7371e-04, Val Loss: 5.1123e-04, LR: 2.5000e-05, Time: 52.44s
2025-06-21 16:51:06,202 - Epoch 40, Train Loss: 2.7669e-04, Val Loss: 6.1299e-04, LR: 2.5000e-05, Time: 52.67s
2025-06-21 16:51:58,682 - Epoch 41, Train Loss: 2.7335e-04, Val Loss: 7.2005e-04, LR: 1.2500e-05, Time: 52.45s
2025-06-21 16:52:56,785 - Epoch 42, Train Loss: 2.6154e-04, Val Loss: 4.7814e-04, LR: 1.2500e-05, Time: 58.06s
2025-06-21 16:53:51,083 - Epoch 43, Train Loss: 2.6006e-04, Val Loss: 4.2677e-04, LR: 1.2500e-05, Time: 54.27s
2025-06-21 16:54:44,554 - Epoch 44, Train Loss: 2.5207e-04, Val Loss: 4.3664e-04, LR: 1.2500e-05, Time: 53.41s
2025-06-21 16:55:37,083 - Epoch 45, Train Loss: 2.5338e-04, Val Loss: 5.0261e-04, LR: 1.2500e-05, Time: 52.50s
2025-06-21 16:56:29,729 - Epoch 46, Train Loss: 2.5278e-04, Val Loss: 4.4642e-04, LR: 1.2500e-05, Time: 52.61s
2025-06-21 16:57:22,391 - Epoch 47, Train Loss: 2.5783e-04, Val Loss: 4.0877e-04, LR: 1.2500e-05, Time: 52.61s
2025-06-21 16:58:15,477 - Epoch 48, Train Loss: 2.4765e-04, Val Loss: 5.2433e-04, LR: 1.2500e-05, Time: 53.04s
2025-06-21 16:59:09,058 - Epoch 49, Train Loss: 2.4497e-04, Val Loss: 4.4554e-04, LR: 1.2500e-05, Time: 53.55s
2025-06-21 17:00:01,453 - Epoch 50, Train Loss: 2.4731e-04, Val Loss: 4.7402e-04, LR: 1.2500e-05, Time: 52.36s
2025-06-21 17:00:54,928 - Epoch 51, Train Loss: 2.5013e-04, Val Loss: 4.6149e-04, LR: 1.2500e-05, Time: 53.44s
2025-06-21 17:01:47,942 - Epoch 52, Train Loss: 2.4460e-04, Val Loss: 4.2652e-04, LR: 1.2500e-05, Time: 52.97s
2025-06-21 17:02:40,657 - Epoch 53, Train Loss: 2.4428e-04, Val Loss: 4.4419e-04, LR: 6.2500e-06, Time: 52.68s
2025-06-21 17:03:33,177 - Epoch 54, Train Loss: 2.3917e-04, Val Loss: 4.2139e-04, LR: 6.2500e-06, Time: 52.47s
2025-06-21 17:04:26,129 - Epoch 55, Train Loss: 2.3975e-04, Val Loss: 4.5708e-04, LR: 6.2500e-06, Time: 52.90s
2025-06-21 17:05:19,005 - Epoch 56, Train Loss: 2.3815e-04, Val Loss: 4.3611e-04, LR: 6.2500e-06, Time: 52.84s
2025-06-21 17:06:11,513 - Epoch 57, Train Loss: 2.3918e-04, Val Loss: 4.6873e-04, LR: 6.2500e-06, Time: 52.48s
2025-06-21 17:07:04,423 - Epoch 58, Train Loss: 2.3968e-04, Val Loss: 3.9216e-04, LR: 6.2500e-06, Time: 52.88s
2025-06-21 17:07:57,749 - Epoch 59, Train Loss: 2.4078e-04, Val Loss: 4.2375e-04, LR: 6.2500e-06, Time: 53.26s
2025-06-21 17:08:50,759 - Epoch 60, Train Loss: 2.3352e-04, Val Loss: 3.8906e-04, LR: 6.2500e-06, Time: 52.98s
2025-06-21 17:09:43,457 - Epoch 61, Train Loss: 2.3679e-04, Val Loss: 4.1324e-04, LR: 6.2500e-06, Time: 52.63s
2025-06-21 17:10:36,045 - Epoch 62, Train Loss: 2.3309e-04, Val Loss: 4.3082e-04, LR: 6.2500e-06, Time: 52.57s
2025-06-21 17:11:28,689 - Epoch 63, Train Loss: 2.3632e-04, Val Loss: 3.7708e-04, LR: 6.2500e-06, Time: 52.60s
2025-06-21 17:12:21,757 - Epoch 64, Train Loss: 2.3557e-04, Val Loss: 3.8399e-04, LR: 6.2500e-06, Time: 53.00s
2025-06-21 17:13:14,553 - Epoch 65, Train Loss: 2.3480e-04, Val Loss: 3.9849e-04, LR: 6.2500e-06, Time: 52.76s
2025-06-21 17:14:07,319 - Epoch 66, Train Loss: 2.3401e-04, Val Loss: 3.8492e-04, LR: 6.2500e-06, Time: 52.73s
2025-06-21 17:14:59,681 - Epoch 67, Train Loss: 2.3206e-04, Val Loss: 4.0057e-04, LR: 6.2500e-06, Time: 52.35s
2025-06-21 17:15:52,894 - Epoch 68, Train Loss: 2.3168e-04, Val Loss: 4.0757e-04, LR: 6.2500e-06, Time: 53.18s
2025-06-21 17:16:46,151 - Epoch 69, Train Loss: 2.3371e-04, Val Loss: 3.8365e-04, LR: 3.1250e-06, Time: 53.21s
2025-06-21 17:17:40,110 - Epoch 70, Train Loss: 2.2995e-04, Val Loss: 4.0668e-04, LR: 3.1250e-06, Time: 53.93s
2025-06-21 17:18:37,410 - Epoch 71, Train Loss: 2.3034e-04, Val Loss: 4.0377e-04, LR: 3.1250e-06, Time: 57.27s
2025-06-21 17:19:30,830 - Epoch 72, Train Loss: 2.3182e-04, Val Loss: 3.8422e-04, LR: 3.1250e-06, Time: 53.39s
2025-06-21 17:20:25,876 - Epoch 73, Train Loss: 2.2754e-04, Val Loss: 3.9575e-04, LR: 3.1250e-06, Time: 54.98s
2025-06-21 17:21:20,656 - Epoch 74, Train Loss: 2.2835e-04, Val Loss: 3.8873e-04, LR: 3.1250e-06, Time: 54.75s
2025-06-21 17:22:17,737 - Epoch 75, Train Loss: 2.3028e-04, Val Loss: 3.9042e-04, LR: 1.5625e-06, Time: 56.99s
2025-06-21 17:23:13,034 - Epoch 76, Train Loss: 2.2602e-04, Val Loss: 3.8717e-04, LR: 1.5625e-06, Time: 55.27s
2025-06-21 17:24:08,413 - Epoch 77, Train Loss: 2.2551e-04, Val Loss: 4.1362e-04, LR: 1.5625e-06, Time: 55.32s
2025-06-21 17:25:04,276 - Epoch 78, Train Loss: 2.2858e-04, Val Loss: 3.9782e-04, LR: 1.5625e-06, Time: 55.82s
2025-06-21 17:26:00,320 - Epoch 79, Train Loss: 2.2427e-04, Val Loss: 4.1117e-04, LR: 1.5625e-06, Time: 56.01s
2025-06-21 17:26:57,697 - Epoch 80, Train Loss: 2.2711e-04, Val Loss: 3.9736e-04, LR: 1.5625e-06, Time: 57.31s
2025-06-21 17:27:50,957 - Epoch 81, Train Loss: 2.2550e-04, Val Loss: 3.9757e-04, LR: 7.8125e-07, Time: 53.20s
2025-06-21 17:28:44,641 - Epoch 82, Train Loss: 2.2658e-04, Val Loss: 4.0006e-04, LR: 7.8125e-07, Time: 53.65s
2025-06-21 17:29:37,647 - Epoch 83, Train Loss: 2.2711e-04, Val Loss: 4.0586e-04, LR: 7.8125e-07, Time: 52.97s
2025-06-21 17:29:37,694 - Early stopping at epoch 83
2025-06-21 17:29:38,225 - [task2] Training completed.
2025-06-21 17:29:38,225 - [task2] Consolidating EWC...
2025-06-21 17:30:32,726 - [task2] Consolidation done.
2025-06-21 17:30:32,726 - [task2] Baseline evaluation on own task task2 ...
2025-06-21 17:30:35,622 - [task2 Baseline on task2] RMSE: 8.7757e-02, MAE: 8.6200e-02
2025-06-21 17:30:35,622 - [task2] Baseline testing completed.
2025-06-21 17:30:35,622 - [task2] Backward testing on previous task task0...
2025-06-21 17:30:40,944 - [task2 BACKWARD on task0] RMSE: 8.8801e-02, MAE: 8.6597e-02
2025-06-21 17:30:40,944 - [task2] Backward testing on previous task task1...
2025-06-21 17:30:44,174 - [task2 BACKWARD on task1] RMSE: 5.9600e-02, MAE: 5.4809e-02
2025-06-21 17:30:44,174 - [task2] ΔMAE on task0: +4.2657e-02
2025-06-21 17:30:44,174 - [task2] ΔMAE on task1: -1.4365e-02
2025-06-21 17:30:44,174 - [task2] ACC (-MAE): -7.5869e-02
2025-06-21 17:30:44,174 - [task2] BWT: +1.4146e-02
2025-06-21 17:30:44,174 - [task2] FWT: +4.5713e-02
2025-06-21 17:30:44,174 - [task2] Evaluating BEST checkpoint...
2025-06-21 17:30:55,165 - [task2 FORWARD on test] RMSE: 8.0145e-02, MAE: 7.5885e-02, R2: 0.0927
2025-06-21 17:30:55,165 - [task2] Forward testing completed.
2025-06-21 17:30:55,173 - Saved ACC/BWT/FWT history to E:\00_Thesis\04_NNs\model\naive_fine_tuning\incremental\continual_metrics.csv
2025-06-21 17:30:55,284 - ==== All tasks completed ====
