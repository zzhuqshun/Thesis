2025-08-03 20:46:02,325 - ==== Experiment Setup ====
2025-08-03 20:46:02,337 - Mode: incremental
2025-08-03 20:46:02,354 - Method: Adapter Fine-tuning
2025-08-03 20:46:02,370 - Number of tasks: 3
2025-08-03 20:46:02,384 - Random seed: 42
2025-08-03 20:46:02,398 - Adapter size: 64
2025-08-03 20:46:02,413 - Freeze backbone: True
2025-08-03 20:46:02,431 - Base directory: /beegfs/home/users/z/zzhuqshun/Thesis/06_adapter/adapter_tuning
2025-08-03 20:46:02,444 - ==== Incremental Training (Adapter Fine-tuning) ====
2025-08-03 20:46:02,538 - Number of tasks: 3
2025-08-03 20:47:34,757 - Incremental training - Task 0 Train IDs: ['03', '27', '05', '21', '11'], size: 107395
2025-08-03 20:47:34,774 - Incremental training - Task 0 Val IDs: ['01'], size: 20028
2025-08-03 20:47:34,790 - Incremental training - Test Task 0 size: 8584
2025-08-03 20:47:34,813 - Incremental training - Task 1 Train IDs: ['09', '29', '25'], size: 41175
2025-08-03 20:47:34,825 - Incremental training - Task 1 Val IDs: ['19'], size: 16183
2025-08-03 20:47:34,844 - Incremental training - Test Task 1 size: 6937
2025-08-03 20:47:34,851 - Incremental training - Task 2 Train IDs: ['15', '07', '23'], size: 57074
2025-08-03 20:47:34,865 - Incremental training - Task 2 Val IDs: ['13'], size: 4511
2025-08-03 20:47:34,879 - Incremental training - Test Task 2 size: 1934
2025-08-03 20:47:34,918 -   (Scaler) Scaler centers: [ 3.3374245   0.101279   27.50083333]
2025-08-03 20:47:34,948 -   (Scaler) Scaler scales: [0.18253608 1.77971742 1.05683333]
2025-08-03 20:47:35,928 - Initialized base LSTM model
2025-08-03 20:47:35,948 - --- task0 ---
2025-08-03 20:47:36,259 - Loading pre-trained Task 0 model from: task0_best.pt
2025-08-03 20:47:36,431 - Successfully loaded Task 0 model, skipping Task 0 training
2025-08-03 20:47:36,445 - --- task1 ---
2025-08-03 20:47:36,679 - Converting to adapter mode after Task 0...
2025-08-03 20:47:36,695 - Backbone LSTM frozen
2025-08-03 20:47:36,708 - Adapter initialized with size 64
2025-08-03 20:47:36,723 - Converted to adapter with size 64, backbone frozen: True
2025-08-03 20:47:36,769 - Training adapter with 16576 parameters
2025-08-03 20:55:59,839 - Epoch 0 train=4.6357e-03 val=4.3822e-04 lr=1.00e-04 time=44.02s
2025-08-03 20:56:49,142 - Epoch 1 train=3.5306e-03 val=7.1692e-04 lr=1.00e-04 time=44.47s
2025-08-03 20:57:35,947 - Epoch 2 train=3.2978e-03 val=8.0681e-04 lr=1.00e-04 time=42.14s
2025-08-03 20:58:23,338 - Epoch 3 train=3.1800e-03 val=8.1179e-04 lr=1.00e-04 time=42.72s
2025-08-03 20:59:10,824 - Epoch 4 train=3.0905e-03 val=7.7388e-04 lr=1.00e-04 time=42.81s
2025-08-03 20:59:58,070 - Epoch 5 train=3.0494e-03 val=6.7547e-04 lr=1.00e-04 time=42.57s
2025-08-03 21:00:45,057 - Epoch 6 train=3.0101e-03 val=6.1828e-04 lr=1.00e-04 time=42.31s
2025-08-03 21:01:29,280 - Epoch 7 train=2.9664e-03 val=6.5462e-04 lr=5.00e-05 time=39.55s
2025-08-03 21:02:11,076 - Epoch 8 train=2.9734e-03 val=6.1107e-04 lr=5.00e-05 time=37.13s
2025-08-03 21:02:49,693 - Epoch 9 train=2.9698e-03 val=6.1610e-04 lr=5.00e-05 time=33.96s
2025-08-03 21:03:17,386 - Epoch 10 train=2.9626e-03 val=5.5966e-04 lr=5.00e-05 time=23.04s
2025-08-03 21:03:43,771 - Epoch 11 train=2.9519e-03 val=6.2831e-04 lr=5.00e-05 time=21.74s
2025-08-03 21:04:07,360 - Epoch 12 train=2.9510e-03 val=5.8038e-04 lr=5.00e-05 time=18.95s
2025-08-03 21:04:29,306 - Epoch 13 train=2.9249e-03 val=6.7924e-04 lr=2.50e-05 time=17.30s
2025-08-03 21:04:51,494 - Epoch 14 train=2.9259e-03 val=5.5965e-04 lr=2.50e-05 time=16.79s
2025-08-03 21:05:12,859 - Epoch 15 train=2.9091e-03 val=5.5365e-04 lr=2.50e-05 time=16.72s
2025-08-03 21:05:34,395 - Epoch 16 train=2.9240e-03 val=5.7012e-04 lr=2.50e-05 time=16.90s
2025-08-03 21:05:55,853 - Epoch 17 train=2.9176e-03 val=6.2700e-04 lr=2.50e-05 time=16.79s
2025-08-03 21:06:17,267 - Epoch 18 train=2.9250e-03 val=5.6824e-04 lr=2.50e-05 time=16.77s
2025-08-03 21:06:39,486 - Epoch 19 train=2.9138e-03 val=5.5018e-04 lr=1.25e-05 time=17.57s
2025-08-03 21:07:01,124 - Epoch 20 train=2.9198e-03 val=5.9566e-04 lr=1.25e-05 time=17.00s
2025-08-03 21:07:01,126 - Early stopping at epoch 20
2025-08-03 21:07:04,979 - Task 1 completed.
2025-08-03 21:07:04,980 - --- task2 ---
2025-08-03 21:07:05,150 - Training adapter with 16576 parameters
2025-08-03 21:07:29,805 - Epoch 0 train=3.2598e-03 val=6.3468e-03 lr=1.00e-04 time=23.50s
2025-08-03 21:07:54,625 - Epoch 1 train=2.6950e-03 val=5.0486e-03 lr=1.00e-04 time=23.59s
2025-08-03 21:08:22,047 - Epoch 2 train=2.4367e-03 val=4.9065e-03 lr=1.00e-04 time=26.25s
2025-08-03 21:08:52,671 - Epoch 3 train=2.3762e-03 val=4.8885e-03 lr=1.00e-04 time=29.45s
2025-08-03 21:09:20,010 - Epoch 4 train=2.3433e-03 val=4.1690e-03 lr=1.00e-04 time=26.16s
2025-08-03 21:09:46,816 - Epoch 5 train=2.3014e-03 val=3.9244e-03 lr=1.00e-04 time=25.63s
2025-08-03 21:10:17,072 - Epoch 6 train=2.3039e-03 val=3.6920e-03 lr=1.00e-04 time=29.08s
2025-08-03 21:10:59,451 - Epoch 7 train=2.2575e-03 val=3.8457e-03 lr=1.00e-04 time=41.19s
2025-08-03 21:11:28,470 - Epoch 8 train=2.2631e-03 val=4.0214e-03 lr=1.00e-04 time=27.86s
2025-08-03 21:12:02,330 - Epoch 9 train=2.2643e-03 val=4.5430e-03 lr=1.00e-04 time=32.70s
2025-08-03 21:12:30,662 - Epoch 10 train=2.2420e-03 val=4.3560e-03 lr=1.00e-04 time=27.17s
2025-08-03 21:12:58,143 - Epoch 11 train=2.2324e-03 val=4.2111e-03 lr=1.00e-04 time=26.32s
2025-08-03 21:13:28,600 - Epoch 12 train=2.2238e-03 val=3.2953e-03 lr=1.00e-04 time=29.30s
2025-08-03 21:13:56,064 - Epoch 13 train=2.2066e-03 val=4.0254e-03 lr=1.00e-04 time=26.28s
2025-08-03 21:14:23,634 - Epoch 14 train=2.2044e-03 val=3.4806e-03 lr=1.00e-04 time=26.41s
2025-08-03 21:14:50,779 - Epoch 15 train=2.2008e-03 val=3.9172e-03 lr=1.00e-04 time=25.98s
2025-08-03 21:15:17,920 - Epoch 16 train=2.1860e-03 val=3.7692e-03 lr=1.00e-04 time=25.98s
2025-08-03 21:15:45,158 - Epoch 17 train=2.1832e-03 val=4.0585e-03 lr=1.00e-04 time=26.08s
2025-08-03 21:16:12,730 - Epoch 18 train=2.1807e-03 val=3.6536e-03 lr=1.00e-04 time=26.41s
2025-08-03 21:16:40,295 - Epoch 19 train=2.1473e-03 val=3.8294e-03 lr=5.00e-05 time=26.36s
2025-08-03 21:17:07,831 - Epoch 20 train=2.1468e-03 val=3.6885e-03 lr=5.00e-05 time=26.38s
2025-08-03 21:17:35,231 - Epoch 21 train=2.1634e-03 val=3.5752e-03 lr=5.00e-05 time=26.24s
2025-08-03 21:18:02,596 - Epoch 22 train=2.1428e-03 val=3.5055e-03 lr=5.00e-05 time=26.21s
2025-08-03 21:18:30,016 - Epoch 23 train=2.1461e-03 val=3.7514e-03 lr=5.00e-05 time=26.26s
2025-08-03 21:18:58,118 - Epoch 24 train=2.1502e-03 val=3.5427e-03 lr=5.00e-05 time=26.94s
2025-08-03 21:19:25,703 - Epoch 25 train=2.1463e-03 val=3.4439e-03 lr=2.50e-05 time=26.43s
2025-08-03 21:19:53,233 - Epoch 26 train=2.1271e-03 val=3.4895e-03 lr=2.50e-05 time=26.37s
2025-08-03 21:20:20,859 - Epoch 27 train=2.1311e-03 val=3.3445e-03 lr=2.50e-05 time=26.47s
2025-08-03 21:20:48,442 - Epoch 28 train=2.1371e-03 val=3.6087e-03 lr=2.50e-05 time=26.42s
2025-08-03 21:21:15,954 - Epoch 29 train=2.1279e-03 val=3.4481e-03 lr=2.50e-05 time=26.36s
2025-08-03 21:21:44,933 - Epoch 30 train=2.1228e-03 val=3.2014e-03 lr=2.50e-05 time=27.79s
2025-08-03 21:22:12,331 - Epoch 31 train=2.1301e-03 val=3.5859e-03 lr=2.50e-05 time=26.21s
2025-08-03 21:22:39,704 - Epoch 32 train=2.1212e-03 val=3.3696e-03 lr=2.50e-05 time=26.21s
2025-08-03 21:23:06,807 - Epoch 33 train=2.1370e-03 val=3.4673e-03 lr=2.50e-05 time=25.95s
2025-08-03 21:23:34,150 - Epoch 34 train=2.1153e-03 val=3.6389e-03 lr=2.50e-05 time=26.18s
2025-08-03 21:24:02,034 - Epoch 35 train=2.1198e-03 val=3.7263e-03 lr=2.50e-05 time=26.73s
2025-08-03 21:24:29,344 - Epoch 36 train=2.1287e-03 val=3.3314e-03 lr=2.50e-05 time=26.16s
2025-08-03 21:24:56,684 - Epoch 37 train=2.1152e-03 val=3.4716e-03 lr=1.25e-05 time=26.18s
2025-08-03 21:25:23,822 - Epoch 38 train=2.1349e-03 val=3.6225e-03 lr=1.25e-05 time=25.98s
2025-08-03 21:25:52,711 - Epoch 39 train=2.1171e-03 val=3.4206e-03 lr=1.25e-05 time=27.73s
2025-08-03 21:26:24,196 - Epoch 40 train=2.1055e-03 val=3.4805e-03 lr=1.25e-05 time=30.21s
2025-08-03 21:26:51,601 - Epoch 41 train=2.1317e-03 val=3.5589e-03 lr=1.25e-05 time=26.25s
2025-08-03 21:27:19,014 - Epoch 42 train=2.1014e-03 val=3.2371e-03 lr=1.25e-05 time=26.25s
2025-08-03 21:27:46,545 - Epoch 43 train=2.1042e-03 val=3.2905e-03 lr=6.25e-06 time=26.37s
2025-08-03 21:28:14,178 - Epoch 44 train=2.1057e-03 val=3.3972e-03 lr=6.25e-06 time=26.48s
2025-08-03 21:28:41,967 - Epoch 45 train=2.1158e-03 val=3.4864e-03 lr=6.25e-06 time=26.63s
2025-08-03 21:29:09,464 - Epoch 46 train=2.1098e-03 val=3.5056e-03 lr=6.25e-06 time=26.34s
2025-08-03 21:29:37,008 - Epoch 47 train=2.1081e-03 val=3.4426e-03 lr=6.25e-06 time=26.39s
2025-08-03 21:30:04,475 - Epoch 48 train=2.0874e-03 val=3.4457e-03 lr=6.25e-06 time=26.31s
2025-08-03 21:30:31,978 - Epoch 49 train=2.1177e-03 val=3.4285e-03 lr=3.13e-06 time=26.35s
2025-08-03 21:30:59,441 - Epoch 50 train=2.0933e-03 val=3.3627e-03 lr=3.13e-06 time=26.30s
2025-08-03 21:30:59,444 - Early stopping at epoch 50
2025-08-03 21:31:02,031 - Task 2 completed.
2025-08-03 21:31:02,032 - ==== Incremental Training Complete ====
2025-08-03 21:31:02,034 - ==== Starting Comprehensive Evaluation ====
2025-08-03 21:31:02,193 - Evaluating model trained after task 0...
2025-08-03 21:31:14,338 -   Task 0 -> Test Task 0: MAE=2.7923e-02, R2=-29.2707
2025-08-03 21:31:16,123 -   Task 0 -> Test Task 1: MAE=3.5453e-02, R2=-2.1284
2025-08-03 21:31:16,478 -   Task 0 -> Test Task 2: MAE=7.2164e-01, R2=-980.0900
2025-08-03 21:31:16,481 - Evaluating model trained after task 1...
2025-08-03 21:31:16,496 - Backbone LSTM frozen
2025-08-03 21:31:16,499 - Adapter initialized with size 64
2025-08-03 21:31:29,261 -   Task 1 -> Test Task 0: MAE=1.1588e-02, R2=-5.3310
2025-08-03 21:31:31,124 -   Task 1 -> Test Task 1: MAE=1.7349e-02, R2=0.0022
2025-08-03 21:31:31,493 -   Task 1 -> Test Task 2: MAE=5.4530e-02, R2=-5.3377
2025-08-03 21:31:31,494 - Evaluating model trained after task 2...
2025-08-03 21:31:31,510 - Backbone LSTM frozen
2025-08-03 21:31:31,511 - Adapter initialized with size 64
2025-08-03 21:31:44,128 -   Task 2 -> Test Task 0: MAE=1.4539e-02, R2=-8.8256
2025-08-03 21:31:45,991 -   Task 2 -> Test Task 1: MAE=2.4706e-02, R2=-0.8426
2025-08-03 21:31:46,361 -   Task 2 -> Test Task 2: MAE=1.1814e-01, R2=-20.9370
2025-08-03 21:31:46,364 - ==== Computing Continual Learning Metrics ====
2025-08-03 21:31:46,366 - Computing random initialization baselines...
2025-08-03 21:31:48,646 -   Baseline Task 0: R=-0.9732
2025-08-03 21:31:50,415 -   Baseline Task 1: R=-0.9253
2025-08-03 21:31:50,767 -   Baseline Task 2: R=-0.6923
2025-08-03 21:31:50,770 - ==== Continual Learning Results ====
2025-08-03 21:31:50,774 - BWT (Backward Transfer): 0.0030 (positive = backward gain)
2025-08-03 21:31:50,775 - FWT (Forward Transfer): 0.7638 (positive = beneficial transfer)
2025-08-03 21:31:50,776 - ACC (Average Accuracy): -0.0525
2025-08-03 21:31:50,778 - ==== Performance Matrix R[i][j] ====
2025-08-03 21:31:50,781 - Rows: trained after task i, Columns: evaluated on task j
2025-08-03 21:31:50,784 -        Task 0 Task 1 Task 2
2025-08-03 21:31:50,788 - Task 0: -0.0279 -0.0355 -0.7216
2025-08-03 21:31:50,790 - Task 1: -0.0116 -0.0173 -0.0545
2025-08-03 21:31:50,792 - Task 2: -0.0145 -0.0247 -0.1181
2025-08-03 21:31:50,862 - ==== Evaluation Complete ====
2025-08-03 21:31:50,865 - All results saved to: /beegfs/home/users/z/zzhuqshun/Thesis/06_adapter/adapter_tuning/incremental_training/metrics
2025-08-03 21:31:50,871 - ==== Final Summary ====
2025-08-03 21:31:50,874 - Continual Learning Metrics:
2025-08-03 21:31:50,876 -   BWT: 0.0030
2025-08-03 21:31:50,880 -   FWT: 0.7638
2025-08-03 21:31:50,882 -   ACC: -0.0525
2025-08-03 21:31:50,886 -   num_tasks: 3.0000
2025-08-03 21:31:50,890 - ==== Experiment Complete ====
