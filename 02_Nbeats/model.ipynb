{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install darts\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm \n",
    "from darts import TimeSeries\n",
    "from darts.models import NBEATSModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import mape, r2_score\n",
    "from darts import concatenate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read data\n",
    "data = pd.read_parquet(r\"..\\01_Datenaufbereitung\\Output\\Calculated\\df_15.parquet\")\n",
    "data['Absolute_Time[yyyy-mm-dd hh:mm:ss]'] = pd.to_datetime(data['Absolute_Time[yyyy-mm-dd hh:mm:ss]'])\n",
    "data = data[['Absolute_Time[yyyy-mm-dd hh:mm:ss]', 'Current[A]', 'Voltage[V]', 'Temperature[°C]', 'SOH_ZHU']]\n",
    "\n",
    "## Resample to hourly\n",
    "data.set_index('Absolute_Time[yyyy-mm-dd hh:mm:ss]', inplace=True)\n",
    "data_hourly = data.resample('h').mean().reset_index()\n",
    "\n",
    "## Fill missing values\n",
    "data_hourly.interpolate(method='linear', inplace=True)\n",
    "data_hourly['SOH_ZHU'] = data_hourly['SOH_ZHU'].fillna(1)\n",
    "data_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data to time series\n",
    "target_series = TimeSeries.from_dataframe(data_hourly, 'Absolute_Time[yyyy-mm-dd hh:mm:ss]', 'SOH_ZHU')\n",
    "covariates = TimeSeries.from_dataframe(data_hourly, 'Absolute_Time[yyyy-mm-dd hh:mm:ss]', ['Current[A]', 'Voltage[V]', 'Temperature[°C]'])\n",
    "\n",
    "## Time align\n",
    "target_series, covariates = target_series.slice_intersect(covariates), covariates.slice_intersect(target_series)\n",
    "\n",
    "## Covariates normalization\n",
    "scaler = Scaler()\n",
    "## Don't scale SOH\n",
    "covariates_scaled = scaler.fit_transform(covariates)\n",
    "\n",
    "## Data split\n",
    "train_series, val_series = target_series.split_after(0.8)\n",
    "cov_train, cov_val = covariates_scaled.split_after(0.8)\n",
    "plt.figure(figsize=(8, 5))\n",
    "train_series.plot(label=\"training\")\n",
    "val_series.plot(label=\"validation\")\n",
    "plt.title(\"SOH Over Time (hourly)\")\n",
    "plt.xlabel(\"Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model definition\n",
    "model_name = \"NBeats\"\n",
    "model = NBEATSModel(\n",
    "    input_chunk_length=24,\n",
    "    output_chunk_length=6,\n",
    "    random_state=42,\n",
    "    save_checkpoints=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(series=train_series, past_covariates=cov_train, \n",
    "          val_series=val_series, val_past_covariates=cov_val, epochs=200, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nbeats = NBEATSModel.load_from_checkpoint('in24_out6')\n",
    "pred_series = model_nbeats.historical_forecasts(start = train_series.end_time() - pd.Timedelta(hours=1),  \n",
    "                                   series = target_series,\n",
    "                                   past_covariates = covariates_scaled,\n",
    "                                   forecast_horizon=1,\n",
    "                                   stride=1,\n",
    "                                   last_points_only=False, \n",
    "                                   retrain=False\n",
    "                                   )\n",
    "\n",
    "pred_series = concatenate(pred_series) \n",
    "\n",
    "plt.figure(figsize=(8, 5)) \n",
    "train_series.plot(label=\"train\")\n",
    "val_series.plot(label=\"true\")\n",
    "pred_series.plot(label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'input_chunk_length': [12, 24], # Half day or full day\n",
    "    'output_chunk_length': [1, 3, 6, 12], # One Hour or more\n",
    "    'batch_size': [16, 32, 64], # Training speed\n",
    "    'num_blocks': [2, 3], # Depth and nonliniarity\n",
    "    'num_stacks': [2, 3] # Different nonlinear mode \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_nbeats(param_grid, train_series, val_series, cov_train=None, cov_val=None):\n",
    "    best_params = None\n",
    "    best_score = float(\"inf\")\n",
    "\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "    for params in tqdm(param_combinations, desc=\"Grid Search Progress\"):\n",
    "        model = NBEATSModel(\n",
    "            input_chunk_length=params['input_chunk_length'],\n",
    "            output_chunk_length=params['output_chunk_length'],\n",
    "            batch_size=params['batch_size'],\n",
    "            num_blocks=params['num_blocks'],\n",
    "            num_stacks=params['num_stacks'],\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Training\n",
    "        model.fit(series=train_series, past_covariates=cov_train, epochs=200)\n",
    "\n",
    "        # Time align\n",
    "        required_start_time = train_series.start_time() - pd.Timedelta(hours=params['input_chunk_length']) \n",
    "        if cov_train.start_time() > required_start_time:\n",
    "            cov_train = covariates_scaled.slice(required_start_time, cov_train.end_time())\n",
    "        if cov_val.start_time() > required_start_time:\n",
    "            cov_val = covariates_scaled.slice(required_start_time, cov_val.end_time())\n",
    "\n",
    "        # Predict\n",
    "        pred_series = model.predict(len(val_series), series=train_series, past_covariates=cov_val)\n",
    "        score = mean_absolute_error(val_series.values(), pred_series.values())\n",
    "\n",
    "        print(f\"Params: {params} - MAE: {score}\")\n",
    "\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "\n",
    "    print(f\"Best Params: {best_params} with MAE: {best_score}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "best_params, best_score = grid_search_nbeats(param_grid, train_series, val_series, cov_train=cov_train, cov_val=cov_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
