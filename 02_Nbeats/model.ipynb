{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install darts\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from darts import TimeSeries\n",
    "from darts.models import NBEATSModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read data\n",
    "data = pd.read_parquet(r\"..\\01_Datenaufbereitung\\Output\\Calculated\\df_15.parquet\")\n",
    "data['Absolute_Time[yyyy-mm-dd hh:mm:ss]'] = pd.to_datetime(data['Absolute_Time[yyyy-mm-dd hh:mm:ss]'])\n",
    "data = data[['Absolute_Time[yyyy-mm-dd hh:mm:ss]', 'Current[A]', 'Voltage[V]', 'Temperature[°C]', 'SOH_ZHU']]\n",
    "\n",
    "## Resample to hourly\n",
    "data.set_index('Absolute_Time[yyyy-mm-dd hh:mm:ss]', inplace=True)\n",
    "data_hourly = data.resample('h').mean().reset_index()\n",
    "\n",
    "## Fill missing values\n",
    "data_hourly.interpolate(method='linear', inplace=True)\n",
    "data_hourly['SOH_ZHU'] = data_hourly['SOH_ZHU'].fillna(1)\n",
    "data_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data to time series\n",
    "target_series = TimeSeries.from_dataframe(data_hourly, 'Absolute_Time[yyyy-mm-dd hh:mm:ss]', 'SOH_ZHU')\n",
    "covariates = TimeSeries.from_dataframe(data_hourly, 'Absolute_Time[yyyy-mm-dd hh:mm:ss]', ['Current[A]', 'Voltage[V]', 'Temperature[°C]'])\n",
    "\n",
    "## Time align\n",
    "target_series, covariates = target_series.slice_intersect(covariates), covariates.slice_intersect(target_series)\n",
    "\n",
    "## Covariates normalization\n",
    "scaler = Scaler() # Scale data [min,max] to [0,1]\n",
    "## Don't scale SOH\n",
    "covariates_scaled = scaler.fit_transform(covariates)\n",
    "\n",
    "## Data split\n",
    "train_series, val_series = target_series.split_after(0.8)\n",
    "cov_train, cov_val = covariates_scaled.split_after(0.8)\n",
    "\n",
    "# Time align\n",
    "required_start_time = train_series.start_time() - pd.Timedelta(hours=12) \n",
    "if cov_train.start_time() > required_start_time:\n",
    "    cov_train = covariates_scaled.slice(required_start_time, cov_train.end_time())\n",
    "if cov_val.start_time() > required_start_time:\n",
    "    cov_val = covariates_scaled.slice(required_start_time, cov_val.end_time())\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "train_series.plot(label=\"training\")\n",
    "val_series.plot(label=\"validation\")\n",
    "plt.title(\"SOH Over Time (hourly)\")\n",
    "plt.xlabel(\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna objective function\n",
    "def objective(trial):\n",
    "    # Define hyperparameter search space\n",
    "    input_chunk_length = trial.suggest_int(\"input_chunk_length\", 12, 24)\n",
    "    output_chunk_length = trial.suggest_int(\"output_chunk_length\", 1, 12)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 2, 3)\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 2, 3)\n",
    "\n",
    "    # Define and train model\n",
    "    model = NBEATSModel(\n",
    "        input_chunk_length=input_chunk_length,\n",
    "        output_chunk_length=output_chunk_length,\n",
    "        batch_size=batch_size,\n",
    "        num_blocks=num_blocks,\n",
    "        num_stacks=num_stacks,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(series=train_series, past_covariates=cov_train, epochs=100)  \n",
    "    \n",
    "    # Predict and compute MAE as evaluation metric\n",
    "    pred_series = model.predict(len(val_series), series=train_series, past_covariates=cov_val)\n",
    "    score = mean_absolute_error(val_series.values(), pred_series.values())\n",
    "    \n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna call with progress bar\n",
    "n_trials = 50  # Set the number of trials\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)  \n",
    "\n",
    "# Best trial\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value (MAE): {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = trial.params\n",
    "best_model = NBEATSModel(\n",
    "    input_chunk_length=best_params[\"input_chunk_length\"],\n",
    "    output_chunk_length=best_params[\"output_chunk_length\"],\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    num_blocks=best_params[\"num_blocks\"],\n",
    "    num_stacks=best_params[\"num_stacks\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_model.fit(series=train_series, past_covariates=cov_train, epochs=200)\n",
    "best_model.save_model(\"best_nbeats_model.pth\")\n",
    "print(\"Best model saved as 'best_nbeats_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'input_chunk_length': [12, 24], # Half day or full day\n",
    "#     'output_chunk_length': [1, 3, 6, 12], # One Hour or more\n",
    "#     'batch_size': [16, 32, 64], # Training speed\n",
    "#     'num_blocks': [2, 3], # Depth and nonliniarity\n",
    "#     'num_stacks': [2, 3] # Different nonlinear mode \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grid_search_nbeats(param_grid, train_series, val_series, cov_train=None, cov_val=None):\n",
    "#     best_params = None\n",
    "#     best_score = float(\"inf\")\n",
    "#     best_model = None \n",
    "\n",
    "#     keys, values = zip(*param_grid.items())\n",
    "#     param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "#     for params in tqdm(param_combinations, desc=\"Grid Search Progress\"):\n",
    "#         model = NBEATSModel(\n",
    "#             input_chunk_length=params['input_chunk_length'],\n",
    "#             output_chunk_length=params['output_chunk_length'],\n",
    "#             batch_size=params['batch_size'],\n",
    "#             num_blocks=params['num_blocks'],\n",
    "#             num_stacks=params['num_stacks'],\n",
    "#             random_state=42\n",
    "#         )\n",
    "\n",
    "#         # Training\n",
    "#         model.fit(series=train_series, past_covariates=cov_train, epochs=200)\n",
    "\n",
    "#         # Predict\n",
    "#         pred_series = model.predict(len(val_series), series=train_series, past_covariates=cov_val)\n",
    "#         score = mean_absolute_error(val_series.values(), pred_series.values())\n",
    "\n",
    "#         print(f\"Params: {params} - MAE: {score}\")\n",
    "\n",
    "#         if score < best_score:\n",
    "#             best_score = score\n",
    "#             best_params = params\n",
    "#             best_model = model\n",
    "#     if best_model is not None:\n",
    "#         best_model.save_model(\"best_nbeats_model.pth\")\n",
    "#         print(\"Best model saved as 'best_nbeats_model.pth'\")\n",
    "        \n",
    "#     print(f\"Best Params: {best_params} with MAE: {best_score}\")\n",
    "#     return best_params, best_score\n",
    "\n",
    "# best_params, best_score = grid_search_nbeats(param_grid, train_series, val_series, cov_train=cov_train, cov_val=cov_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
