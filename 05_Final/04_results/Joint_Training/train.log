2025-06-23 10:19:30,197 - ==== Regular LSTM Training Phase ====
2025-06-23 10:20:49,658 - Base train IDs: ['03', '05', '07', '09', '11', '15', '21', '23', '25', '27', '29']
2025-06-23 10:20:49,659 - Base train size: 205644
2025-06-23 10:20:49,660 - Base val IDs: ['01', '19', '13']
2025-06-23 10:20:49,663 - Base val size: 58177
2025-06-23 10:20:49,664 - Update1 train IDs: []
2025-06-23 10:20:49,665 - Update1 train size: 0
2025-06-23 10:20:49,667 - Update1 val IDs: []
2025-06-23 10:20:49,668 - Update1 val size: 0
2025-06-23 10:20:49,669 - Update2 train IDs: []
2025-06-23 10:20:49,671 - Update2 train size: 0
2025-06-23 10:20:49,672 - Update2 val IDs: []
2025-06-23 10:20:49,673 - Update2 val size: 0
2025-06-23 10:20:56,208 - Test cell ID: 17
2025-06-23 10:20:56,210 - Test size: 22872
2025-06-23 10:20:56,211 - Test base size: 11139
2025-06-23 10:20:56,212 - Test update1 size: 6312
2025-06-23 10:20:56,213 - Test update2 size: 5421
2025-06-23 10:20:56,249 - [Scaler after fit] center_=[ 3.342422    0.17992967 27.75      ]
2025-06-23 10:20:56,250 - [Scaler after fit] scale_ =[0.18428363 1.77955483 1.81783333]
2025-06-23 10:20:56,251 - Resampling and scaling complete with RobustScaler
2025-06-23 10:24:21,149 - Epoch 1, Train Loss: 2.2723e-02, Val Loss: 2.2427e-03, LR: 1.0000e-04, Time: 176.11s
2025-06-23 10:27:16,797 - Epoch 2, Train Loss: 6.2867e-03, Val Loss: 1.1379e-03, LR: 1.0000e-04, Time: 175.53s
2025-06-23 10:30:10,692 - Epoch 3, Train Loss: 3.6614e-03, Val Loss: 1.2391e-03, LR: 1.0000e-04, Time: 173.79s
2025-06-23 10:33:05,456 - Epoch 4, Train Loss: 2.0000e-03, Val Loss: 1.2032e-03, LR: 1.0000e-04, Time: 174.70s
2025-06-23 10:35:59,240 - Epoch 5, Train Loss: 1.1192e-03, Val Loss: 5.6654e-04, LR: 1.0000e-04, Time: 173.71s
2025-06-23 10:39:00,400 - Epoch 6, Train Loss: 5.9559e-04, Val Loss: 8.9163e-04, LR: 1.0000e-04, Time: 181.05s
2025-06-23 10:41:57,857 - Epoch 7, Train Loss: 4.0951e-04, Val Loss: 5.7827e-04, LR: 1.0000e-04, Time: 177.41s
2025-06-23 10:44:50,725 - Epoch 8, Train Loss: 3.1060e-04, Val Loss: 3.5550e-04, LR: 1.0000e-04, Time: 172.80s
2025-06-23 10:48:40,030 - Epoch 9, Train Loss: 2.3761e-04, Val Loss: 4.8509e-04, LR: 1.0000e-04, Time: 229.16s
2025-06-23 10:52:34,351 - Epoch 10, Train Loss: 2.0217e-04, Val Loss: 3.0042e-04, LR: 1.0000e-04, Time: 234.19s
2025-06-23 10:56:39,766 - Epoch 11, Train Loss: 1.8876e-04, Val Loss: 3.5375e-04, LR: 1.0000e-04, Time: 245.25s
2025-06-23 10:59:55,618 - Epoch 12, Train Loss: 1.6527e-04, Val Loss: 2.6464e-04, LR: 1.0000e-04, Time: 195.69s
2025-06-23 11:02:49,300 - Epoch 13, Train Loss: 1.4900e-04, Val Loss: 2.8292e-04, LR: 1.0000e-04, Time: 173.55s
2025-06-23 11:05:43,119 - Epoch 14, Train Loss: 2.1938e-04, Val Loss: 3.0634e-04, LR: 1.0000e-04, Time: 173.76s
2025-06-23 11:08:37,946 - Epoch 15, Train Loss: 1.3704e-04, Val Loss: 3.6347e-04, LR: 1.0000e-04, Time: 174.74s
2025-06-23 11:11:32,432 - Epoch 16, Train Loss: 1.3580e-04, Val Loss: 3.0101e-04, LR: 1.0000e-04, Time: 174.42s
2025-06-23 11:14:26,760 - Epoch 17, Train Loss: 1.3260e-04, Val Loss: 3.0864e-04, LR: 1.0000e-04, Time: 174.25s
2025-06-23 11:17:18,616 - Epoch 18, Train Loss: 1.2779e-04, Val Loss: 2.7150e-04, LR: 5.0000e-05, Time: 171.75s
2025-06-23 11:20:12,792 - Epoch 19, Train Loss: 1.0744e-04, Val Loss: 3.5201e-04, LR: 5.0000e-05, Time: 174.07s
2025-06-23 11:23:03,967 - Epoch 20, Train Loss: 1.0336e-04, Val Loss: 3.4272e-04, LR: 5.0000e-05, Time: 171.10s
2025-06-23 11:26:52,237 - Epoch 21, Train Loss: 1.0237e-04, Val Loss: 3.9322e-04, LR: 5.0000e-05, Time: 228.17s
2025-06-23 11:31:13,202 - Epoch 22, Train Loss: 1.0328e-04, Val Loss: 3.8363e-04, LR: 5.0000e-05, Time: 260.85s
2025-06-23 11:35:33,862 - Epoch 23, Train Loss: 9.9646e-05, Val Loss: 4.8348e-04, LR: 5.0000e-05, Time: 260.54s
2025-06-23 11:39:44,958 - Epoch 24, Train Loss: 9.8422e-05, Val Loss: 4.9786e-04, LR: 2.5000e-05, Time: 250.95s
2025-06-23 11:42:37,727 - Epoch 25, Train Loss: 9.1085e-05, Val Loss: 4.0165e-04, LR: 2.5000e-05, Time: 172.70s
2025-06-23 11:45:32,502 - Epoch 26, Train Loss: 9.0751e-05, Val Loss: 4.5738e-04, LR: 2.5000e-05, Time: 174.70s
2025-06-23 11:48:26,896 - Epoch 27, Train Loss: 8.9891e-05, Val Loss: 4.5964e-04, LR: 2.5000e-05, Time: 174.33s
2025-06-23 11:51:22,308 - Epoch 28, Train Loss: 9.0781e-05, Val Loss: 4.7109e-04, LR: 2.5000e-05, Time: 175.37s
2025-06-23 11:54:15,678 - Epoch 29, Train Loss: 8.7675e-05, Val Loss: 5.2180e-04, LR: 2.5000e-05, Time: 173.28s
2025-06-23 11:57:09,174 - Epoch 30, Train Loss: 8.7188e-05, Val Loss: 4.4292e-04, LR: 1.2500e-05, Time: 173.44s
2025-06-23 12:00:00,180 - Epoch 31, Train Loss: 8.4346e-05, Val Loss: 5.1190e-04, LR: 1.2500e-05, Time: 170.95s
2025-06-23 12:02:51,507 - Epoch 32, Train Loss: 8.3343e-05, Val Loss: 4.7098e-04, LR: 1.2500e-05, Time: 171.28s
2025-06-23 12:02:51,568 - Early stopping at epoch 32
2025-06-23 12:03:01,709 - [Joint training best model predictions] RMSE: 7.2272e-03, MAE: 5.6535e-03, R2: 0.9926
